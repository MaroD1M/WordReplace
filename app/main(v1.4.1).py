# å¯¼å…¥æ ‡å‡†åº“
import os
import sys
import tempfile
from tempfile import NamedTemporaryFile
import warnings
import shutil
import json
import io
import zipfile
import re
import unicodedata
import copy
from datetime import datetime
import hashlib
import base64

# å¯¼å…¥ç¬¬ä¸‰æ–¹åº“
import streamlit as st
import pandas as pd
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple, Set
from collections import defaultdict
from decimal import Decimal, ROUND_HALF_UP

# é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯
VERSION = "v1.4.1"

# é…ç½®å¸¸é‡
PAGE_SIZE = 10
WIDGET_HEIGHT = 300
PREVIEW_ROWS = 30
MAX_FILENAME_LENGTH = 200
MAX_WORD_FILE_SIZE = 50 * 1024 * 1024
MAX_EXCEL_FILE_SIZE = 50 * 1024 * 1024
CACHE_DIR = ".replace_cache"
HISTORY_FILE = ".replace_history.json"
MAX_HISTORY_ITEMS = 20

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

# ç¯å¢ƒå˜é‡
os.environ["STREAMLIT_VERSION"] = "1.51.0"
os.environ["STREAMLIT_SERVER_HEADLESS"] = "true"
os.environ["STREAMLIT_BROWSER_GATHER_USAGE_STATS"] = "false"

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# å…¨å±€æ ·å¼ä¼˜åŒ–
st.markdown("""
<style>
    /* ä¸»å®¹å™¨ä¼˜åŒ– */
    .main {
        padding: 0rem 1rem;
    }

    .stContainer {
        padding: 1rem;
        margin-bottom: 1rem;
        border-radius: 8px;
        background-color: #ffffff;
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        border-radius: 6px;
        font-weight: 500;
        padding: 0.5rem 1rem;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }

    /* è¾“å…¥æ¡†æ ·å¼ */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea,
    .stSelectbox > div > div > select,
    .stNumberInput > div > div > input {
        border-radius: 6px;
        border: 1px solid #e0e0e0;
    }

    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus,
    .stSelectbox > div > div > select:focus,
    .stNumberInput > div > div > input:focus {
        border-color: #1f77b4;
        box-shadow: 0 0 0 3px rgba(31, 119, 180, 0.1);
    }

    /* æ ‡é¢˜æ ·å¼ */
    h1 {
        padding-bottom: 1rem;
        border-bottom: 3px solid #1f77b4;
    }

    h2 {
        margin-top: 1.5rem;
        margin-bottom: 1rem;
        color: #1f77b4;
    }

    h3 {
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        color: #333;
    }

    .stSubheader {
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #e0e0e0;
    }

    /* å±•å¼€å™¨æ ·å¼ */
    .streamlit-expander {
        margin-bottom: 1rem;
        border-radius: 6px;
    }

    /* æ•°æ®æ¡†æ ·å¼ */
    div[data-testid="stDataFrame"] {
        border-radius: 6px;
        border: 1px solid #e0e0e0;
    }

    /* æŒ‡æ ‡å¡æ ·å¼ */
    .stMetric {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 6px;
        border-left: 4px solid #1f77b4;
    }

    /* è¡Œé¡¹ç›®æ ·å¼ */
    .data-row-item {
        padding: 10px;
        border-radius: 6px;
        transition: background-color 0.2s;
        cursor: pointer;
    }

    .data-row-item:hover {
        background-color: #f0f2f6;
    }

    /* ä¿¡æ¯æ¡†æ ·å¼ */
    .stats-box {
        background-color: #f0f9ff;
        border-left: 4px solid #0ea5e9;
        padding: 12px;
        border-radius: 6px;
        margin: 8px 0;
    }

    .success-box {
        background-color: #f0fdf4;
        border-left: 4px solid #22c55e;
        padding: 12px;
        border-radius: 6px;
        margin: 8px 0;
    }

    .warning-box {
        background-color: #fffbeb;
        border-left: 4px solid #f59e0b;
        padding: 12px;
        border-radius: 6px;
        margin: 8px 0;
    }

    .error-box {
        background-color: #fef2f2;
        border-left: 4px solid #ef4444;
        padding: 12px;
        border-radius: 6px;
        margin: 8px 0;
    }

    /* åˆ†éš”çº¿ä¼˜åŒ– */
    hr {
        margin: 2rem 0 !important;
        border: none;
        border-top: 2px solid #e0e0e0;
    }

    /* æ ‡ç­¾é¡µæ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }

    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-top: 10px;
        border-radius: 6px 6px 0 0;
    }

    /* æ— çº¿ç”µæŒ‰é’®å’Œå¤é€‰æ¡† */
    .stRadio > label,
    .stCheckbox > label {
        margin-bottom: 0.5rem;
    }

    /* æ–‡ä»¶ä¸Šä¼ å™¨æ ·å¼ */
    .stFileUploader {
        border-radius: 6px;
    }

    /* å¯¹é½ä¼˜åŒ– */
    .element-container {
        margin-bottom: 1rem;
    }

    /* åˆ—é—´è·ä¼˜åŒ– */
    .stColumn {
        gap: 1rem;
    }

    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main {
            padding: 0 0.5rem;
        }

        .stContainer {
            padding: 0.5rem;
        }
    }
</style>
""", unsafe_allow_html=True)


# ---------------------- æ•°æ®ç»“æ„ä¸åˆå§‹åŒ– ----------------------

@dataclass
class ReplacedFile:
    """å­˜å‚¨æ›¿æ¢åçš„æ–‡ä»¶æ•°æ®ç»“æ„"""
    filename: str
    data: io.BytesIO
    row_idx: int
    log: str


@dataclass
class HistoryRecord:
    """å†å²è®°å½•æ•°æ®ç»“æ„"""
    timestamp: str
    word_file: str
    excel_file: str
    rules_count: int
    files_generated: int
    status: str


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self):
        self.cache_dir = CACHE_DIR
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)

    def save_rules(self, rules: List[Tuple[str, str]], filename: str):
        """ä¿å­˜è§„åˆ™åˆ°ç¼“å­˜"""
        try:
            rules_data = [{"keyword": old, "excel_column": col} for old, col in rules]
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(rules_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")

    def load_rules(self, filename: str) -> List[Tuple[str, str]]:
        """åŠ è½½ç¼“å­˜çš„è§„åˆ™"""
        try:
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    rules_data = json.load(f)
                    return [(r["keyword"], r["excel_column"]) for r in rules_data]
        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")
        return []

    def get_cached_rules_list(self) -> List[str]:
        """è·å–æ‰€æœ‰ç¼“å­˜çš„è§„åˆ™æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_dir):
                files = [f.replace('.json', '') for f in os.listdir(self.cache_dir) if f.endswith('.json')]
                return sorted(files, reverse=True)
        except:
            pass
        return []


class HistoryManager:
    """å†å²è®°å½•ç®¡ç†å™¨"""

    def __init__(self):
        self.history_file = HISTORY_FILE

    def add_record(self, record: HistoryRecord):
        """æ·»åŠ å†å²è®°å½•"""
        try:
            history = self.load_history()
            history.insert(0, {
                "timestamp": record.timestamp,
                "word_file": record.word_file,
                "excel_file": record.excel_file,
                "rules_count": record.rules_count,
                "files_generated": record.files_generated,
                "status": record.status
            })
            history = history[:MAX_HISTORY_ITEMS]
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜å†å²è®°å½•å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")

    def load_history(self) -> List[Dict]:
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return []

    def clear_history(self):
        """æ¸…é™¤å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                os.remove(self.history_file)
                st.success("âœ… å†å²è®°å½•å·²æ¸…é™¤", icon="âœ…")
        except Exception as e:
            st.error(f"âŒ æ¸…é™¤å†å²è®°å½•å¤±è´¥ï¼š{str(e)}", icon="âŒ")


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    required_states = {
        "replace_rules": [],
        "replaced_files": [],
        "replace_log": [],
        "is_replacing": False,
        "replace_params": {},
        "replace_scope": "æ›¿æ¢å®Œæ•´å…³é”®è¯",
        "export_mode_radio": "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰",
        "show_statistics": False,
        "undo_stack": [],
    }

    for key, default in required_states.items():
        if key not in st.session_state:
            st.session_state[key] = default


init_session_state()


# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------

def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬"""
    if not isinstance(text, str):
        return ""
    text = text.strip()
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r'[\u00A0\u2002-\u200B]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text


def clean_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åéæ³•å­—ç¬¦"""
    return re.sub(r'[\\/:*?"<>|]', "_", str(filename))


def generate_safe_filename(
        excel_row: pd.Series,
        file_name_col: str,
        file_prefix: str = "",
        file_suffix: str = "",
        row_idx: int = 0,
        max_length: int = MAX_FILENAME_LENGTH
) -> str:
    """å®‰å…¨ç”Ÿæˆæ–‡ä»¶å"""
    try:
        if file_name_col and file_name_col in excel_row.index:
            base_name = clean_text(str(excel_row[file_name_col]))
        else:
            base_name = f"æ›¿æ¢ç»“æœ_{row_idx + 1}"

        if not base_name or base_name.isspace():
            base_name = f"æ›¿æ¢ç»“æœ_{row_idx + 1}"

        if file_prefix and file_suffix:
            filename = f"{file_prefix}{base_name}{file_suffix}.docx"
        elif file_prefix:
            filename = f"{file_prefix}{base_name}.docx"
        elif file_suffix:
            filename = f"{base_name}{file_suffix}.docx"
        else:
            filename = f"{base_name}.docx"

        filename = clean_filename(filename)

        filename_bytes = filename.encode('utf-8')
        if len(filename_bytes) > max_length:
            suffix_len = len(f"{file_prefix}{file_suffix}.docx".encode('utf-8'))
            max_base_bytes = max_length - suffix_len - 10

            truncated_base = base_name
            while len(f"{file_prefix}{truncated_base}{file_suffix}.docx".encode('utf-8')) > max_length:
                truncated_base = truncated_base[:-1]

            if file_prefix and file_suffix:
                filename = f"{file_prefix}{truncated_base}{file_suffix}.docx"
            elif file_prefix:
                filename = f"{file_prefix}{truncated_base}.docx"
            elif file_suffix:
                filename = f"{truncated_base}{file_suffix}.docx"
            else:
                filename = f"{truncated_base}.docx"

            filename = clean_filename(filename)

        return filename

    except Exception as e:
        return f"æ›¿æ¢ç»“æœ_{row_idx + 1}.docx"


def precompute_replace_patterns(
        replace_rules: List[Tuple[str, str]],
        excel_row: pd.Series
) -> List[Tuple[str, str, str, str]]:
    """é¢„è®¡ç®—æ›¿æ¢æ¨¡å¼"""
    replace_patterns = []

    for old_text, col_name in replace_rules:
        if col_name in excel_row.index:
            replacement = str(excel_row[col_name]).strip()
        else:
            replacement = ""

        cleaned_text = clean_text(old_text)

        if not cleaned_text:
            continue

        if st.session_state.replace_scope == "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹":
            if cleaned_text.startswith("ã€") and cleaned_text.endswith("ã€‘"):
                new_format = f"ã€{replacement}ã€‘"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ï¼ˆ") and cleaned_text.endswith("ï¼‰"):
                new_format = f"ï¼ˆ{replacement}ï¼‰"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("(") and cleaned_text.endswith(")"):
                new_format = f"({replacement})"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ã€”") and cleaned_text.endswith("ã€•"):
                new_format = f"ã€”{replacement}ã€•"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            else:
                replace_patterns.append((old_text, col_name, cleaned_text, replacement))
        else:
            replace_patterns.append((old_text, col_name, cleaned_text, replacement))

    return replace_patterns


def process_paragraph(
        paragraph,
        replace_patterns: List[Tuple[str, str, str, str]],
        cleaned_para: str = None
) -> Dict:
    """å¤„ç†æ®µè½æ›¿æ¢"""
    para_text = paragraph.text
    if cleaned_para is None:
        cleaned_para = clean_text(para_text)
    replace_count = defaultdict(int)

    if not para_text or not replace_patterns:
        return replace_count

    has_keyword = False

    for old_text, col_name, format_keyword, replacement in replace_patterns:
        if format_keyword and format_keyword in cleaned_para:
            has_keyword = True
            break

    if has_keyword:
        new_text = para_text
        for old_text, col_name, format_keyword, replacement in replace_patterns:
            if format_keyword and format_keyword in cleaned_para:
                count = new_text.count(format_keyword)
                if count > 0:
                    new_text = new_text.replace(format_keyword, replacement)
                    replace_count[(old_text, col_name)] += count

        if len(paragraph.runs) > 0:
            paragraph.runs[0].text = new_text
            for i in range(1, len(paragraph.runs)):
                paragraph.runs[i].text = ''

    return replace_count


def replace_word_with_format(
        word_file: st.runtime.uploaded_file_manager.UploadedFile,
        excel_row: pd.Series,
        replace_rules: List[Tuple[str, str]]
) -> Tuple[io.BytesIO, str]:
    """æ›¿æ¢Wordæ–‡ä»¶"""
    replace_count = defaultdict(int)

    try:
        file_size = len(word_file.getvalue())
        if file_size > MAX_WORD_FILE_SIZE:
            raise ValueError(f"Wordæ–‡ä»¶è¿‡å¤§ï¼š{file_size / 1024 / 1024:.2f}MB > {MAX_WORD_FILE_SIZE / 1024 / 1024:.2f}MB")

        doc = Document(io.BytesIO(word_file.getvalue()))

        replace_patterns = precompute_replace_patterns(replace_rules, excel_row)

        if not replace_patterns:
            output_file = io.BytesIO()
            doc.save(output_file)
            output_file.seek(0)
            return output_file, "âš  æœªè®¾ç½®æœ‰æ•ˆçš„æ›¿æ¢è§„åˆ™"

        for paragraph in doc.paragraphs:
            para_count = process_paragraph(paragraph, replace_patterns)
            for key, count in para_count.items():
                replace_count[key] += count

        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        para_count = process_paragraph(paragraph, replace_patterns)
                        for key, count in para_count.items():
                            replace_count[key] += count

        output_file = io.BytesIO()
        doc.save(output_file)
        output_file.seek(0)

        if replace_count:
            log_lines = []
            for (old, col_name), count in replace_count.items():
                try:
                    replacement_value = excel_row[col_name]
                except:
                    replacement_value = "N/A"
                log_lines.append(f"âœ“ {old} â†’ {replacement_value} ({count}æ¬¡)")
            replace_log = "\n".join(log_lines)
        else:
            replace_log = "âš  æœªæ‰¾åˆ°éœ€è¦æ›¿æ¢çš„å…³é”®å­—"

        return output_file, replace_log

    except Exception as e:
        import traceback
        error_log = f"âŒ æ›¿æ¢å¤±è´¥ï¼š{str(e)}"
        return io.BytesIO(), error_log


def merge_word_documents(
        replaced_files: List[ReplacedFile]
) -> io.BytesIO:
    """åˆå¹¶Wordæ–‡æ¡£ï¼ˆä¿ç•™æ ¼å¼ï¼‰"""
    if not replaced_files:
        raise ValueError("æ²¡æœ‰è¦åˆå¹¶çš„æ–‡ä»¶")

    try:
        if len(replaced_files) == 0:
            raise ValueError("æ›¿æ¢æ–‡ä»¶åˆ—è¡¨ä¸ºç©º")

        try:
            main_doc = Document(io.BytesIO(replaced_files[0].data.getvalue()))
        except Exception as e:
            raise ValueError(f"æ— æ³•åŠ è½½ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼š{str(e)}")

        main_body = main_doc._body._element

        for idx in range(1, len(replaced_files)):
            try:
                file = replaced_files[idx]

                if not file.data or len(file.data.getvalue()) == 0:
                    st.warning(f"âš ï¸ æ–‡ä»¶ {file.filename} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡", icon="âš ï¸")
                    continue

                sub_doc = Document(io.BytesIO(file.data.getvalue()))
                sub_body = sub_doc._body._element

                page_break_para = OxmlElement('w:p')
                page_break_pPr = OxmlElement('w:pPr')

                page_break_element = OxmlElement('w:pageBreakBefore')
                page_break_element.set(qn('w:val'), '1')

                page_break_pPr.append(page_break_element)
                page_break_para.append(page_break_pPr)
                main_body.append(page_break_para)

                for element in sub_body:
                    main_body.append(copy.deepcopy(element))

            except Exception as e:
                st.warning(f"âš ï¸ å¤„ç†æ–‡ä»¶ {file.filename} å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")
                continue

        output = io.BytesIO()
        main_doc.save(output)
        output.seek(0)
        return output

    except Exception as e:
        st.error(f"âŒ åˆå¹¶æ–‡æ¡£å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        raise


def get_replace_params(
        word_file: Optional[st.runtime.uploaded_file_manager.UploadedFile],
        excel_df: Optional[pd.DataFrame],
        start_row: int,
        end_row: int,
        file_name_col: str,
        file_prefix: str,
        file_suffix: str
) -> Dict:
    """è·å–æ›¿æ¢å‚æ•°"""
    return {
        "word_filename": word_file.name if word_file else "",
        "word_size": len(word_file.getvalue()) if word_file else 0,
        "excel_rows": len(excel_df) if excel_df is not None else 0,
        "start_row": start_row,
        "end_row": end_row,
        "file_name_col": file_name_col,
        "file_prefix": file_prefix,
        "file_suffix": file_suffix,
        "rule_count": len(st.session_state.replace_rules),
        "rule_hash": hash(tuple(st.session_state.replace_rules))
    }


def fix_float_precision(x: str, column_name: Optional[str] = None) -> str:
    """ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦"""
    if not x or not isinstance(x, str):
        return x

    x = x.strip()

    if not x:
        return ""

    try:
        if x.replace('.', '', 1).replace('-', '', 1).isdigit():
            pass
        else:
            return x
    except:
        return x

    float_pattern = r'^\s*[-+]?\d*\.?\d+\s*$'
    if not re.match(float_pattern, x):
        return x

    try:
        dec_value = Decimal(x)

        if dec_value.as_tuple().exponent >= 0:
            return str(int(dec_value))

        float_val = float(dec_value)
        float_str = str(float_val)

        if column_name and ("åˆè®¡" in column_name or "total" in column_name.lower()):
            for dec_places in range(2, 7):
                try:
                    quantized = dec_value.quantize(
                        Decimal('1.' + '0' * dec_places),
                        rounding=ROUND_HALF_UP
                    )

                    if abs(quantized - dec_value) < 1e-9:
                        result = format(quantized, f'.{dec_places}f')
                        return result.rstrip('0').rstrip('.')
                except:
                    continue

        if '999999' in float_str or '000000' in float_str:
            if '.' in x:
                orig_dec_part = x.split('.')[1]
                orig_dec_places = len(orig_dec_part.rstrip('0'))

                if orig_dec_places > 0:
                    try:
                        quantized = dec_value.quantize(
                            Decimal('1.' + '0' * orig_dec_places),
                            rounding=ROUND_HALF_UP
                        )
                        result = format(quantized, f'.{orig_dec_places}f')
                        return result.rstrip('0').rstrip('.')
                    except:
                        pass

            for dec_places in range(1, 10):
                try:
                    formatted = format(float_val, f'.{dec_places}f')
                    if abs(float(formatted) - float_val) < 1e-9:
                        return formatted.rstrip('0').rstrip('.')
                except:
                    continue

        return x
    except:
        return x


def clean_excel_types(df: pd.DataFrame) -> pd.DataFrame:
    """æ¸…ç†Excelæ•°æ®ç±»å‹"""
    df_clean = df.copy()

    for col in df_clean.columns:
        try:
            col_name = str(col)
            if col_name != col:
                df_clean = df_clean.rename(columns={col: col_name})
                col = col_name

            df_clean[col] = df_clean[col].fillna("")
            df_clean[col] = df_clean[col].astype(str).str.strip()

            df_clean[col] = df_clean[col].apply(lambda x: fix_float_precision(x, col))

        except Exception as e:
            try:
                df_clean[col] = df_clean[col].astype(str).str.strip()
            except:
                pass

    return df_clean


def get_file_hash(file_data: bytes) -> str:
    """è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
    return hashlib.md5(file_data).hexdigest()[:8]


def export_statistics_to_csv(replaced_files: List[ReplacedFile]) -> str:
    """å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°CSV"""
    try:
        data = []
        for idx, file in enumerate(replaced_files, 1):
            data.append({
                "åºå·": idx,
                "æ–‡ä»¶å": file.filename,
                "Excelè¡Œå·": file.row_idx + 1,
                "æ›¿æ¢æ—¥å¿—": file.log.replace("\n", "; ")
            })

        df = pd.DataFrame(data)
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        return csv_buffer.getvalue()
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºç»Ÿè®¡å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        return ""


def get_keyword_statistics(replace_rules: List[Tuple[str, str]],
                           replaced_files: List[ReplacedFile]) -> Dict:
    """è·å–å…³é”®å­—æ›¿æ¢ç»Ÿè®¡"""
    stats = {}
    for keyword, _ in replace_rules:
        stats[keyword] = 0

    for file in replaced_files:
        for keyword, _ in replace_rules:
            if f"âœ“ {keyword}" in file.log:
                pattern = f"âœ“ {re.escape(keyword)}.*?\((\d+)æ¬¡\)"
                matches = re.findall(pattern, file.log)
                if matches:
                    stats[keyword] += int(matches[0])

    return stats


# åˆ›å»ºç¼“å­˜å’Œå†å²ç®¡ç†å™¨
cache_manager = CacheManager()
history_manager = HistoryManager()

# ---------------------- é¡µé¢æ ‡é¢˜ä¸ç®€ä»‹ ----------------------
col_title1, col_title2 = st.columns([8, 2])
with col_title1:
    st.title("ğŸ“‹ Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·")
with col_title2:
    st.markdown(f"<div style='text-align: right; padding-top: 10px;'><small>v{VERSION}</small></div>",
                unsafe_allow_html=True)

st.markdown("""
å¿«é€Ÿå®ç°Wordæ¨¡æ¿ä¸Excelæ•°æ®çš„æ‰¹é‡æ›¿æ¢ï¼Œæ”¯æŒè¡¨æ ¼å†…æ–‡å­—æ›¿æ¢ï¼Œä¿ç•™åŸæ ¼å¼ï¼Œæ“ä½œç®€å•é«˜æ•ˆã€‚

**âœ¨ æ ¸å¿ƒåŠŸèƒ½ï¼š** æ‰¹é‡æ›¿æ¢ | æ ¼å¼ä¿ç•™ | æ–‡æ¡£åˆå¹¶ | è§„åˆ™ç®¡ç† | ç»Ÿè®¡åˆ†æ
""", unsafe_allow_html=True)

# åˆ›å»ºæ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs(["ğŸš€ å¿«é€Ÿå¼€å§‹", "ğŸ“š è§„åˆ™ç®¡ç†", "ğŸ’¾ ä¸‹è½½ç»“æœ", "âš™ï¸ å·¥å…·è®¾ç½®"])

with tab1:
    st.markdown("### æ›¿æ¢å·¥ä½œæµç¨‹")

    # ==================== ç¬¬ä¸€æ­¥ï¼šæ–‡ä»¶ä¸Šä¼  ====================
    st.subheader("ğŸ“¤ æ­¥éª¤1ï¼šä¸Šä¼ æ–‡ä»¶")

    col_upload1, col_upload2 = st.columns([1, 1], gap="medium")

    with col_upload1:
        st.markdown("**Word æ¨¡æ¿æ–‡ä»¶**")
        word_file = st.file_uploader(
            "é€‰æ‹©Wordæ–‡ä»¶",
            type=["docx"],
            key="word",
            help="ä»…æ”¯æŒ.docxæ ¼å¼"
        )
        if word_file:
            file_size_mb = len(word_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_WORD_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ æ–‡ä»¶è¿‡å¤§ï¼š{file_size_mb:.2f}MB", icon="âŒ")
                word_file = None
            else:
                file_hash = get_file_hash(word_file.getvalue())
                st.markdown(f"""
                <div class='success-box'>
                <strong>âœ… æ–‡ä»¶å·²ä¸Šä¼ </strong><br>
                ğŸ“„ {word_file.name}<br>
                ğŸ“Š å¤§å°ï¼š{file_size_mb:.2f}MB<br>
                ğŸ” å“ˆå¸Œï¼š{file_hash}
                </div>
                """, unsafe_allow_html=True)

    with col_upload2:
        st.markdown("**Excel æ•°æ®æ–‡ä»¶**")
        excel_file = st.file_uploader(
            "é€‰æ‹©Excelæ–‡ä»¶",
            type=["xlsx", "xls"],
            key="excel",
            help="æ”¯æŒ.xlsx/.xlsæ ¼å¼"
        )
        if excel_file:
            file_size_mb = len(excel_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_EXCEL_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ æ–‡ä»¶è¿‡å¤§ï¼š{file_size_mb:.2f}MB", icon="âŒ")
                excel_file = None
            else:
                file_hash = get_file_hash(excel_file.getvalue())
                st.markdown(f"""
                <div class='success-box'>
                <strong>âœ… æ–‡ä»¶å·²ä¸Šä¼ </strong><br>
                ğŸ“„ {excel_file.name}<br>
                ğŸ“Š å¤§å°ï¼š{file_size_mb:.2f}MB<br>
                ğŸ” å“ˆå¸Œï¼š{file_hash}
                </div>
                """, unsafe_allow_html=True)

    st.markdown("---")

    # ==================== ç¬¬äºŒæ­¥ï¼šæ–‡æ¡£é¢„è§ˆ ====================
    st.subheader("ğŸ‘€ æ­¥éª¤2ï¼šé¢„è§ˆæ–‡æ¡£å†…å®¹")

    col_preview1, col_preview2 = st.columns([1, 1], gap="medium")

    excel_df = None
    excel_cols = []

    with col_preview1:
        st.markdown("**Word æ–‡æ¡£é¢„è§ˆ**")
        if word_file:
            try:
                doc = Document(io.BytesIO(word_file.getvalue()))
                word_html = "<div style='height: 250px; overflow-y: auto; padding: 12px; border: 1px solid #e0e0e0; border-radius: 6px; font-size: 13px; line-height: 1.6; background-color: #f9f9f9;'>"

                para_count = 0
                max_para_preview = 100

                for paragraph in doc.paragraphs:
                    if para_count >= max_para_preview:
                        word_html += "<p style='color: #999;'><em>...ï¼ˆè¿˜æœ‰æ›´å¤šå†…å®¹ï¼‰</em></p>"
                        break

                    if paragraph.text.strip():
                        para_html = "<p style='margin: 4px 0;'>"
                        for run in paragraph.runs:
                            style = ""
                            if run.bold:
                                style += "font-weight: bold;"
                            if run.italic:
                                style += "font-style: italic;"
                            try:
                                if run.font.color and run.font.color.rgb:
                                    style += f"color: #{run.font.color.rgb:06X}; "
                            except:
                                pass
                            para_html += f"<span style='{style}'>{run.text}</span>" if style else run.text
                        para_html += "</p>"
                        word_html += para_html
                        para_count += 1

                table_count = 0
                max_table_preview = 3

                for table_idx, table in enumerate(doc.tables):
                    if table_count >= max_table_preview:
                        word_html += f"<p style='color: #999;'><em>...ï¼ˆè¿˜æœ‰{len(doc.tables) - table_count}ä¸ªè¡¨æ ¼ï¼‰</em></p>"
                        break

                    word_html += f"<div style='margin: 8px 0; font-weight: bold; color: #1f77b4;'>ğŸ“Š è¡¨æ ¼{table_idx + 1}ï¼š</div>"
                    word_html += "<table border='1' style='border-collapse: collapse; width: 100%; border: 1px solid #ccc; font-size: 12px;'>"

                    for row_idx, row in enumerate(table.rows):
                        if row_idx >= 15:
                            word_html += "<tr><td colspan='100%' style='text-align:center; color:#999;'>...</td></tr>"
                            break

                        word_html += "<tr>"
                        for cell in row.cells:
                            cell_html = "<td style='padding: 6px; vertical-align: top; font-size: 11px;'>"
                            for para in cell.paragraphs:
                                for run in para.runs:
                                    cell_html += run.text
                            cell_html += "</td>"
                            word_html += cell_html
                        word_html += "</tr>"
                    word_html += "</table>"
                    table_count += 1

                word_html += "</div>"

                st.components.v1.html(word_html, height=280)
                st.caption("ğŸ’¡ æŒ‰Ctrl+Cå¤åˆ¶éœ€è¦æ›¿æ¢çš„å…³é”®å­—")

            except Exception as e:
                st.error(f"âŒ é¢„è§ˆå¤±è´¥ï¼š{str(e)}", icon="âŒ")
        else:
            st.info("ğŸ“ è¯·å…ˆä¸Šä¼ Wordæ–‡ä»¶", icon="â„¹ï¸")

    with col_preview2:
        st.markdown("**Excel æ•°æ®é¢„è§ˆ**")
        if excel_file:
            try:
                with NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_excel:
                    temp_excel.write(excel_file.getvalue())
                    excel_path = temp_excel.name

                try:
                    with pd.ExcelFile(excel_path, engine="openpyxl") as excel_wb:
                        sheet_names = excel_wb.sheet_names
                        selected_sheet = sheet_names[0]
                        st.caption(f"ğŸ“‹ å·¥ä½œè¡¨ï¼š**{selected_sheet}**")

                        excel_df = pd.read_excel(
                            excel_wb,
                            sheet_name=selected_sheet,
                            dtype=str,
                            keep_default_na=False,
                            na_values=[]
                        )

                        if excel_df.empty:
                            st.warning("âš ï¸ Excelè¡¨æ ¼ä¸ºç©º", icon="âš ï¸")
                        else:
                            excel_df = clean_excel_types(excel_df)
                            excel_cols = excel_df.columns.tolist()

                            preview_df = excel_df.head(PREVIEW_ROWS)
                            st.dataframe(
                                preview_df,
                                width='stretch',
                                height=250,
                                use_container_width=True,
                                hide_index=True
                            )

                            col_stat1, col_stat2, col_stat3 = st.columns(3)
                            with col_stat1:
                                st.metric("ğŸ“Š è¡Œæ•°", len(excel_df))
                            with col_stat2:
                                st.metric("ğŸ“‹ åˆ—æ•°", len(excel_cols))
                            with col_stat3:
                                st.metric("ğŸ’¾ æ–‡ä»¶å¤§å°", f"{len(excel_file.getvalue()) / 1024:.1f}KB")

                finally:
                    try:
                        if os.path.exists(excel_path):
                            os.unlink(excel_path)
                    except:
                        pass

            except Exception as e:
                st.error(f"âŒ è¯»å–å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        else:
            st.info("ğŸ“ è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶", icon="â„¹ï¸")

    st.markdown("---")

    # ==================== ç¬¬ä¸‰æ­¥ï¼šæ›¿æ¢èŒƒå›´ ====================
    st.subheader("âš™ï¸ æ­¥éª¤3ï¼šé…ç½®æ›¿æ¢å‚æ•°")

    col_config1, col_config2, col_config3 = st.columns([1, 1, 1], gap="medium")

    with col_config1:
        st.markdown("**æ–‡ä»¶å‘½åè®¾ç½®**")
        file_name_col = st.selectbox(
            "æ ¸å¿ƒå­—æ®µ",
            options=excel_cols if excel_cols else ["è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶"],
            key="file_name_col",
            disabled=not excel_cols,
            help="ç”¨äºç”Ÿæˆæ–‡ä»¶å"
        )

    with col_config2:
        st.markdown("**æ–‡ä»¶å‰åç¼€**")
        col_prefix, col_suffix = st.columns(2, gap="small")
        with col_prefix:
            file_prefix = st.text_input(
                "å‰ç¼€",
                value="",
                key="file_prefix",
                placeholder="å¯é€‰",
                max_chars=20
            ).strip()
        with col_suffix:
            file_suffix = st.text_input(
                "åç¼€",
                value="",
                key="file_suffix",
                placeholder="å¯é€‰",
                max_chars=20
            ).strip()

    with col_config3:
        st.markdown("**æ›¿æ¢æ•°æ®èŒƒå›´**")
        col_start, col_end = st.columns(2, gap="small")
        with col_start:
            start_row = st.number_input(
                "èµ·å§‹è¡Œ",
                min_value=1,
                max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
                value=1,
                key="start_row",
                disabled=excel_df is None or len(excel_df) == 0
            )
        with col_end:
            end_row = st.number_input(
                "ç»“æŸè¡Œ",
                min_value=1,
                max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
                value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
                key="end_row",
                disabled=excel_df is None or len(excel_df) == 0
            )

    if start_row > end_row:
        st.error("âŒ èµ·å§‹è¡Œä¸èƒ½å¤§äºç»“æŸè¡Œ", icon="âŒ")

    st.markdown("---")

    # ==================== ç¬¬å››æ­¥ï¼šæ‰§è¡Œæ›¿æ¢ ====================
    st.subheader("ğŸš€ æ­¥éª¤4ï¼šæ‰§è¡Œæ‰¹é‡æ›¿æ¢")

    can_replace = word_file and excel_df is not None and len(excel_df) > 0 and len(st.session_state.replace_rules) > 0

    current_params = get_replace_params(
        word_file, excel_df, start_row, end_row, file_name_col, file_prefix, file_suffix
    )

    need_replace = (
            len(st.session_state.replaced_files) == 0 or
            st.session_state.replace_params != current_params
    )

    col_execute1, col_execute2, col_execute3 = st.columns([2, 2, 2], gap="medium")

    with col_execute1:
        replace_btn = st.button(
            "â–¶ï¸ å¼€å§‹æ›¿æ¢",
            key="replace",
            disabled=not can_replace or st.session_state.is_replacing or start_row > end_row,
            type="primary",
            use_container_width=True
        )

    with col_execute2:
        if st.session_state.is_replacing:
            st.info("ğŸ”„ æ›¿æ¢è¿›è¡Œä¸­...", icon="ğŸ”„")
        elif len(st.session_state.replaced_files) > 0 and not need_replace:
            st.success(f"âœ… {len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶å·²ç”Ÿæˆ", icon="âœ…")

    with col_execute3:
        pass

    if replace_btn and not st.session_state.is_replacing:
        st.session_state.is_replacing = True
        st.session_state.replaced_files = []
        st.session_state.replace_log = []

        progress_bar = st.progress(0)
        progress_text = st.empty()

        try:
            actual_end_row = min(end_row, len(excel_df))
            if start_row > actual_end_row:
                st.error("âŒ èµ·å§‹è¡Œè¶…å‡ºæ•°æ®èŒƒå›´", icon="âŒ")
            else:
                total_rows = actual_end_row - start_row + 1

                for idx, row_idx in enumerate(range(start_row - 1, actual_end_row)):
                    try:
                        excel_row = excel_df.iloc[row_idx]

                        replaced_file, replace_log = replace_word_with_format(
                            word_file, excel_row, st.session_state.replace_rules
                        )

                        filename = generate_safe_filename(
                            excel_row,
                            file_name_col if file_name_col != "è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶" else "",
                            file_prefix,
                            file_suffix,
                            row_idx
                        )

                        st.session_state.replaced_files.append(ReplacedFile(
                            filename=filename,
                            data=replaced_file,
                            row_idx=row_idx,
                            log=replace_log
                        ))

                        st.session_state.replace_log.append(f"ã€ç¬¬{row_idx + 1}è¡Œã€‘{replace_log}")

                        progress = (idx + 1) / total_rows
                        progress_bar.progress(progress)
                        progress_text.text(f"å¤„ç†è¿›åº¦ï¼š{idx + 1}/{total_rows}")

                    except Exception as e:
                        st.session_state.replace_log.append(f"ã€ç¬¬{row_idx + 1}è¡Œã€‘âŒ å¤±è´¥ï¼š{str(e)}")
                        continue

                st.session_state.replace_params = current_params
                st.success(f"ğŸ‰ å®Œæˆï¼å…±ç”Ÿæˆ {len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶", icon="âœ…")

                history_record = HistoryRecord(
                    timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    word_file=word_file.name,
                    excel_file=excel_file.name,
                    rules_count=len(st.session_state.replace_rules),
                    files_generated=len(st.session_state.replaced_files),
                    status="success"
                )
                history_manager.add_record(history_record)

        except Exception as e:
            st.error(f"âŒ é”™è¯¯ï¼š{str(e)}", icon="âŒ")
            history_record = HistoryRecord(
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                word_file=word_file.name if word_file else "N/A",
                excel_file=excel_file.name if excel_file else "N/A",
                rules_count=len(st.session_state.replace_rules),
                files_generated=0,
                status="failed"
            )
            history_manager.add_record(history_record)
        finally:
            st.session_state.is_replacing = False
            progress_bar.empty()
            progress_text.empty()

    # æ˜¾ç¤ºæ›¿æ¢æ—¥å¿—
    if st.session_state.replace_log:
        st.markdown("---")
        with st.expander("ğŸ“ æ›¿æ¢æ—¥å¿—", expanded=False):
            log_content = "\n".join(st.session_state.replace_log)
            st.text_area(
                "æ—¥å¿—å†…å®¹",
                value=log_content,
                height=200,
                key="log_area",
                disabled=True,
                label_visibility="collapsed"
            )

    # æœªæ»¡è¶³æ¡ä»¶æç¤º
    if not can_replace:
        st.markdown("---")
        st.info("ğŸ’¡ éœ€è¦ï¼š1ï¸âƒ£ Wordæ–‡ä»¶ 2ï¸âƒ£ Excelæ–‡ä»¶ 3ï¸âƒ£ æ›¿æ¢è§„åˆ™", icon="â„¹ï¸")

# ==================== æ ‡ç­¾é¡µ2ï¼šè§„åˆ™ç®¡ç† ====================
with tab2:
    st.subheader("ğŸ“‹ æ›¿æ¢è§„åˆ™ç®¡ç†")

    # æ›¿æ¢èŒƒå›´é€‰æ‹©
    st.markdown("### æ›¿æ¢èŒƒå›´é€‰æ‹©")
    col_scope1, col_scope2 = st.columns(2, gap="medium")
    with col_scope1:
        st.radio(
            "æ›¿æ¢æ¨¡å¼",
            options=["æ›¿æ¢å®Œæ•´å…³é”®è¯", "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹"],
            key="replace_scope",
            index=0,
            horizontal=False,
            help="å®Œæ•´å…³é”®è¯ï¼šç²¾ç¡®æ›¿æ¢\næ‹¬å·å†…å®¹ï¼šä¿ç•™æ‹¬å·ç»“æ„"
        )

    with col_scope2:
        st.markdown("**æ¨¡å¼è¯´æ˜**")
        if st.session_state.replace_scope == "æ›¿æ¢å®Œæ•´å…³é”®è¯":
            st.markdown("""
            âœ“ ç›´æ¥æ›¿æ¢æ•´ä¸ªå…³é”®è¯

            **ç¤ºä¾‹ï¼š**
            - ã€å¼ ä¸‰ã€‘â†’ ã€æå››ã€‘
            - ï¼ˆ2024å¹´ï¼‰â†’ ï¼ˆ2025å¹´ï¼‰
            """)
        else:
            st.markdown("""
            âœ“ ä¿ç•™æ‹¬å·ï¼Œåªæ›¿æ¢å†…å®¹

            **ç¤ºä¾‹ï¼š**
            - ã€å¼ ä¸‰ã€‘â†’ ã€æå››ã€‘
            - ï¼ˆå¼ ä¸‰ï¼‰â†’ ï¼ˆæå››ï¼‰
            """)

    st.markdown("---")

    # è§„åˆ™å¯¼å…¥å¯¼å‡ºç¼“å­˜
    st.markdown("### è§„åˆ™å¯¼å…¥/å¯¼å‡º/ç¼“å­˜")

    col_imp1, col_imp2, col_imp3 = st.columns([1, 1, 1], gap="medium")

    with col_imp1:
        st.markdown("**å¯¼å…¥è§„åˆ™**")
        import_rules = st.file_uploader(
            "ä¸Šä¼ JSONæ–‡ä»¶",
            type=["json"],
            key="import_rules",
            help="å¯¼å…¥ä¿å­˜çš„è§„åˆ™"
        )

        if import_rules:
            try:
                rules_data = json.load(import_rules)

                if not isinstance(rules_data, list):
                    st.error("âŒ JSONæ ¼å¼é”™è¯¯ï¼šåº”ä¸ºæ•°ç»„", icon="âŒ")
                else:
                    valid_rules = []
                    for rule in rules_data:
                        if isinstance(rule, dict) and "keyword" in rule and "excel_column" in rule:
                            keyword = str(rule["keyword"]).strip()
                            excel_col = str(rule["excel_column"]).strip()
                            if keyword and excel_col:
                                valid_rules.append((keyword, excel_col))

                    st.session_state.undo_stack.append(st.session_state.replace_rules.copy())

                    for rule in valid_rules:
                        if rule not in st.session_state.replace_rules:
                            st.session_state.replace_rules.append(rule)

                    st.success(f"âœ… å¯¼å…¥ {len(valid_rules)} æ¡è§„åˆ™", icon="âœ…")
                    st.rerun()
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSONé”™è¯¯ï¼š{str(e)}", icon="âŒ")
            except Exception as e:
                st.error(f"âŒ å¯¼å…¥å¤±è´¥ï¼š{str(e)}", icon="âŒ")

    with col_imp2:
        st.markdown("**å¯¼å‡ºè§„åˆ™**")
        if st.session_state.replace_rules:
            rules_data = [
                {"keyword": old, "excel_column": col}
                for old, col in st.session_state.replace_rules
            ]
            rules_json = json.dumps(rules_data, ensure_ascii=False, indent=2)

            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºJSON",
                data=rules_json,
                file_name="rules.json",
                mime="application/json",
                key="export_rules",
                use_container_width=True
            )
        else:
            st.info("ğŸ“ æ— è§„åˆ™å¯å¯¼å‡º", icon="â„¹ï¸")

    with col_imp3:
        st.markdown("**ç¼“å­˜è§„åˆ™**")
        if st.session_state.replace_rules:
            if st.button("ğŸ’¾ ä¿å­˜åˆ°ç¼“å­˜", key="save_cache", use_container_width=True):
                cache_name = f"rules_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                cache_manager.save_rules(st.session_state.replace_rules, cache_name)
                st.success("âœ… å·²ä¿å­˜", icon="âœ…")
        else:
            st.info("ğŸ“ æ— è§„åˆ™å¯ä¿å­˜", icon="â„¹ï¸")

    st.markdown("---")

    # å¿«é€ŸåŠ è½½ç¼“å­˜
    st.markdown("### å¿«é€ŸåŠ è½½ç¼“å­˜")
    cached_rules = cache_manager.get_cached_rules_list()

    if cached_rules:
        col_load1, col_load2, col_load3 = st.columns([2, 1, 1], gap="medium")
        with col_load1:
            selected_cache = st.selectbox(
                "é€‰æ‹©ç¼“å­˜",
                options=cached_rules,
                key="select_cache",
                label_visibility="collapsed"
            )
        with col_load2:
            if st.button("ğŸ“‚ åŠ è½½", key="load_cache", use_container_width=True):
                loaded_rules = cache_manager.load_rules(selected_cache)
                if loaded_rules:
                    st.session_state.replace_rules = loaded_rules
                    st.success(f"âœ… åŠ è½½ {len(loaded_rules)} æ¡è§„åˆ™", icon="âœ…")
                    st.rerun()
        with col_load3:
            if st.button("ğŸ—‘ï¸ åˆ é™¤", key="delete_cache", use_container_width=True):
                try:
                    cache_file = os.path.join(cache_manager.cache_dir, f"{selected_cache}.json")
                    if os.path.exists(cache_file):
                        os.remove(cache_file)
                        st.success("âœ… å·²åˆ é™¤", icon="âœ…")
                        st.rerun()
                except Exception as e:
                    st.error(f"âŒ åˆ é™¤å¤±è´¥ï¼š{str(e)}", icon="âŒ")
    else:
        st.info("ğŸ“ æš‚æ— ç¼“å­˜è§„åˆ™", icon="â„¹ï¸")

    st.markdown("---")

    # è§„åˆ™æ·»åŠ 
    st.markdown("### æ·»åŠ æ–°è§„åˆ™")
    col_add1, col_add2, col_add3 = st.columns([2, 2, 1], gap="medium")

    with col_add1:
        keyword_input = st.text_input(
            "å…³é”®å­—",
            placeholder="å¦‚ï¼šã€å§“åã€‘",
            key="keyword_input",
            help="ä»Wordæ–‡æ¡£å¤åˆ¶"
        )

    with col_add2:
        if excel_cols:
            column_select = st.selectbox(
                "Excelåˆ—",
                options=excel_cols,
                key="column_select"
            )
        else:
            st.info("è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶", icon="â„¹ï¸")
            column_select = None

    with col_add3:
        add_rule_btn = st.button(
            "â• æ·»åŠ ",
            key="add_rule",
            type="primary",
            disabled=not (keyword_input and keyword_input.strip() and column_select),
            use_container_width=True
        )

    if add_rule_btn and column_select:
        rule = (keyword_input.strip(), column_select)
        if rule in st.session_state.replace_rules:
            st.warning("âš ï¸ è§„åˆ™å·²å­˜åœ¨", icon="âš ï¸")
        else:
            st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
            st.session_state.replace_rules.append(rule)
            st.success("âœ… è§„åˆ™å·²æ·»åŠ ", icon="âœ…")
            st.rerun()

    st.markdown("---")

    # è§„åˆ™åˆ—è¡¨
    st.markdown("### å½“å‰è§„åˆ™åˆ—è¡¨")

    if st.session_state.replace_rules:
        col_action1, col_action2, col_action3 = st.columns([1, 1, 1], gap="medium")

        with col_action1:
            if st.session_state.undo_stack:
                if st.button("â†¶ æ’¤é”€", key="undo", use_container_width=True):
                    st.session_state.replace_rules = st.session_state.undo_stack.pop()
                    st.success("âœ… å·²æ’¤é”€", icon="âœ…")
                    st.rerun()

        with col_action2:
            pass

        with col_action3:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰", key="clear_rules", type="secondary", use_container_width=True):
                st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                st.session_state.replace_rules.clear()
                st.session_state.replaced_files = []
                st.success("âœ… å·²æ¸…ç©º", icon="âœ…")
                st.rerun()

        # è§„åˆ™è¡¨æ ¼æ˜¾ç¤º
        rule_data = []
        for idx, (old, col) in enumerate(st.session_state.replace_rules, 1):
            rule_data.append({
                "åºå·": idx,
                "å…³é”®å­—": old,
                "Excelåˆ—": col,
                "æ“ä½œ": f"âŒ {idx}"  # å ä½ç¬¦
            })

        rule_df = pd.DataFrame(rule_data)
        st.dataframe(rule_df, use_container_width=True, hide_index=True)

        # åˆ é™¤æŒ‰é’®ï¼ˆå•ç‹¬æ”¾åœ¨ä¸‹æ–¹ï¼‰
        st.markdown("**åˆ é™¤è§„åˆ™**")
        col_del1, col_del2, col_del3 = st.columns(3, gap="small")

        rules_to_delete = len(st.session_state.replace_rules)
        if rules_to_delete <= 3:
            for idx in range(rules_to_delete):
                with st.columns([1, 1, 1])[idx]:
                    if st.button(f"åˆ é™¤è§„åˆ™ {idx + 1}", key=f"delete_{idx}", use_container_width=True):
                        st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                        st.session_state.replace_rules.pop(idx)
                        st.session_state.replaced_files = []
                        st.success(f"âœ… å·²åˆ é™¤è§„åˆ™ {idx + 1}", icon="âœ…")
                        st.rerun()
        else:
            # è¶…è¿‡3ä¸ªè§„åˆ™ï¼Œç”¨å¯æ»šåŠ¨çš„å®¹å™¨
            with st.container(height=200, border=True):
                for idx in range(rules_to_delete):
                    if st.button(f"åˆ é™¤è§„åˆ™ {idx + 1}", key=f"delete_{idx}", use_container_width=True):
                        st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                        st.session_state.replace_rules.pop(idx)
                        st.session_state.replaced_files = []
                        st.success(f"âœ… å·²åˆ é™¤è§„åˆ™ {idx + 1}", icon="âœ…")
                        st.rerun()
    else:
        st.info("ğŸ“ æš‚æ— è§„åˆ™ï¼Œè¯·æ·»åŠ è§„åˆ™åå¼€å§‹æ›¿æ¢", icon="â„¹ï¸")

# ==================== æ ‡ç­¾é¡µ3ï¼šä¸‹è½½ç»“æœ ====================
with tab3:
    st.subheader("ğŸ’¾ ä¸‹è½½æ›¿æ¢ç»“æœ")

    if len(st.session_state.replaced_files) > 0:

        # å¯¼å‡ºé€‰é¡¹
        st.markdown("### å¯¼å‡ºæ–¹å¼é€‰æ‹©")
        export_mode = st.radio(
            "é€‰æ‹©å¯¼å‡ºæ–¹å¼",
            options=["ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰", "åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£"],
            key="export_mode_radio",
            horizontal=True,
            help="ZIPï¼šä¸‹è½½æ‰€æœ‰æ–‡ä»¶ | åˆå¹¶ï¼šä¸€ä¸ªæ–‡æ¡£åŒ…å«æ‰€æœ‰å†…å®¹"
        )

        st.markdown("---")

        # ç»Ÿè®¡ä¿¡æ¯
        st.markdown("### æ›¿æ¢ç»Ÿè®¡")

        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4, gap="medium")

        with col_stat1:
            st.metric("ğŸ“„ ç”Ÿæˆæ–‡ä»¶æ•°", len(st.session_state.replaced_files))

        with col_stat2:
            st.metric("ğŸ“‹ æ›¿æ¢è§„åˆ™æ•°", len(st.session_state.replace_rules))

        with col_stat3:
            success_count = len([f for f in st.session_state.replaced_files
                                 if f.data and len(f.data.getvalue()) > 0])
            st.metric("âœ… æˆåŠŸæ–‡ä»¶æ•°", success_count)

        with col_stat4:
            st.metric("â±ï¸ ç”Ÿæˆæ—¶é—´", datetime.now().strftime("%H:%M:%S"))

        # å…³é”®å­—ç»Ÿè®¡
        st.markdown("---")
        st.markdown("### å…³é”®å­—æ›¿æ¢ç»Ÿè®¡")

        keyword_stats = get_keyword_statistics(st.session_state.replace_rules,
                                               st.session_state.replaced_files)
        if keyword_stats and any(v > 0 for v in keyword_stats.values()):
            stat_data = [
                {"å…³é”®å­—": k, "æ€»æ›¿æ¢æ¬¡æ•°": v}
                for k, v in keyword_stats.items() if v > 0
            ]
            if stat_data:
                stat_df = pd.DataFrame(stat_data)
                st.dataframe(stat_df, use_container_width=True, hide_index=True)

                # å¯¼å‡ºç»Ÿè®¡
                if st.button("ğŸ“Š å¯¼å‡ºç»Ÿè®¡åˆ°CSV", key="export_stats", use_container_width=True):
                    csv_data = export_statistics_to_csv(st.session_state.replaced_files)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ç»Ÿè®¡CSV",
                        data=csv_data,
                        file_name="ç»Ÿè®¡æ•°æ®.csv",
                        mime="text/csv",
                        key="download_stats",
                        use_container_width=True
                    )

        st.markdown("---")
        st.markdown("### æ‰¹é‡å¯¼å‡º")

        # å¯¼å‡ºæŒ‰é’®
        if export_mode == "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰":
            try:
                valid_files = [f for f in st.session_state.replaced_files
                               if f.data and len(f.data.getvalue()) > 0]

                if not valid_files:
                    st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶", icon="âŒ")
                else:
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        for file in valid_files:
                            zipf.writestr(file.filename, file.data.getvalue())

                    zip_buffer.seek(0)
                    zip_filename = f"æ‰¹é‡æ›¿æ¢_{len(valid_files)}ä¸ªæ–‡ä»¶.zip"

                    st.download_button(
                        label=f"ğŸ“¦ ä¸‹è½½ZIP - {len(valid_files)} ä¸ªæ–‡ä»¶",
                        data=zip_buffer,
                        file_name=zip_filename,
                        mime="application/zip",
                        key="download_all_zip",
                        use_container_width=True,
                        type="primary"
                    )
            except Exception as e:
                st.error(f"âŒ åˆ›å»ºZIPå¤±è´¥ï¼š{str(e)}", icon="âŒ")
        else:
            valid_files = [f for f in st.session_state.replaced_files
                           if f.data and len(f.data.getvalue()) > 0]

            if not valid_files:
                st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶", icon="âŒ")
            else:
                try:
                    merged_data = merge_word_documents(valid_files)
                    merged_filename = "åˆå¹¶ç»“æœ.docx"

                    st.download_button(
                        label=f"ğŸ“‹ ä¸‹è½½åˆå¹¶æ–‡æ¡£ - {len(valid_files)} ä¸ªæ–‡ä»¶",
                        data=merged_data,
                        file_name=merged_filename,
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_merged",
                        use_container_width=True,
                        type="primary"
                    )
                except Exception as e:
                    st.error(f"âŒ åˆå¹¶å¤±è´¥ï¼š{str(e)}", icon="âŒ")

        st.markdown("---")
        st.markdown("### æ–‡ä»¶åˆ—è¡¨")

        # åˆ†é¡µæ˜¾ç¤º
        total_pages = (len(st.session_state.replaced_files) + PAGE_SIZE - 1) // PAGE_SIZE

        col_page_col = st.columns([4])[0]
        with col_page_col:
            current_page = st.number_input(
                "é¡µç ",
                min_value=1,
                max_value=total_pages,
                value=1,
                key="current_page"
            )

        start_idx = (current_page - 1) * PAGE_SIZE
        end_idx = min(start_idx + PAGE_SIZE, len(st.session_state.replaced_files))
        current_files = st.session_state.replaced_files[start_idx:end_idx]

        st.caption(f"ç¬¬ {current_page}/{total_pages} é¡µï¼ˆå…± {len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶ï¼‰")

        # æ–‡ä»¶åˆ—è¡¨
        for idx, file in enumerate(current_files, start=start_idx + 1):
            is_valid = file.data and len(file.data.getvalue()) > 0
            status_icon = "âœ…" if is_valid else "âŒ"

            col_info, col_log, col_download = st.columns([3, 2, 1], gap="medium")

            with col_info:
                st.markdown(f"**{status_icon} {idx}. {file.filename}**")
                st.caption(f"Excelè¡Œå·ï¼š#{file.row_idx + 1}")

            with col_log:
                with st.expander("ğŸ“‹ æŸ¥çœ‹æ—¥å¿—", expanded=False):
                    st.code(file.log, language="text")

            with col_download:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½",
                    data=file.data,
                    file_name=file.filename,
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    key=f"download_{idx}",
                    disabled=not is_valid,
                    use_container_width=True
                )

            st.divider()

    else:
        st.info("ğŸ“ æš‚æ— ç”Ÿæˆçš„æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œæ›¿æ¢", icon="â„¹ï¸")

# ==================== æ ‡ç­¾é¡µ4ï¼šå·¥å…·è®¾ç½® ====================
with tab4:
    st.subheader("âš™ï¸ å·¥å…·è®¾ç½®ä¸å¸®åŠ©")

    # æ“ä½œå†å²
    st.markdown("### ğŸ“œ æ“ä½œå†å²è®°å½•")
    history = history_manager.load_history()

    if history:
        col_hist1, col_hist2 = st.columns([4, 1], gap="medium")
        with col_hist1:
            st.markdown(f"**æœ€è¿‘ {len(history)} æ¬¡æ“ä½œ**")
        with col_hist2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²", key="clear_history", use_container_width=True):
                history_manager.clear_history()
                st.rerun()

        # å†å²è®°å½•è¡¨æ ¼
        history_data = []
        for i, record in enumerate(history[:20], 1):
            status_emoji = "âœ…" if record["status"] == "success" else "âŒ"
            history_data.append({
                "åºå·": i,
                "æ—¶é—´": record["timestamp"],
                "Wordæ–‡ä»¶": record["word_file"][:20] + "..." if len(record["word_file"]) > 20 else record["word_file"],
                "Excelæ–‡ä»¶": record["excel_file"][:20] + "..." if len(record["excel_file"]) > 20 else record[
                    "excel_file"],
                "è§„åˆ™æ•°": record["rules_count"],
                "ç”Ÿæˆæ–‡ä»¶": record["files_generated"],
                "çŠ¶æ€": status_emoji
            })

        history_df = pd.DataFrame(history_data)
        st.dataframe(history_df, use_container_width=True, hide_index=True)
    else:
        st.info("ğŸ“ æš‚æ— æ“ä½œå†å²", icon="â„¹ï¸")

    st.markdown("---")

    # å…³äºå·¥å…·
    st.markdown("### â„¹ï¸ å…³äºæ­¤å·¥å…·")

    col_about1, col_about2 = st.columns([2, 2], gap="medium")

    with col_about1:
        st.markdown(f"""
        **Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·**

        ç‰ˆæœ¬ï¼š{VERSION}

        **åŠŸèƒ½ç‰¹æ€§ï¼š**
        âœ… æ‰¹é‡æ›¿æ¢
        âœ… æ ¼å¼ä¿ç•™
        âœ… æ–‡æ¡£åˆå¹¶
        âœ… è§„åˆ™ç®¡ç†
        âœ… ç»Ÿè®¡åˆ†æ
        âœ… å†å²è®°å½•
        """)

    with col_about2:
        st.markdown("""
        **å¿«é€ŸæŒ‡å—ï¼š**

        1. ä¸Šä¼ Wordå’ŒExcelæ–‡ä»¶
        2. é¢„è§ˆå†…å®¹ï¼Œå¤åˆ¶å…³é”®å­—
        3. æ·»åŠ æ›¿æ¢è§„åˆ™
        4. æ‰§è¡Œæ‰¹é‡æ›¿æ¢
        5. ä¸‹è½½ç»“æœæ–‡ä»¶

        **æ”¯æŒçš„æ ¼å¼ï¼š**
        â€¢ Wordï¼š.docx
        â€¢ Excelï¼š.xlsx/.xls
        â€¢ æ‹¬å·ï¼šã€ã€‘ï¼ˆï¼‰()ã€”ã€•
        """)

    st.markdown("---")

    # å¸¸è§é—®é¢˜
    st.markdown("### â“ å¸¸è§é—®é¢˜")

    with st.expander("1ï¸âƒ£ æ”¯æŒ.docæ ¼å¼å—ï¼Ÿ"):
        st.markdown("""
        ä¸æ”¯æŒ.docæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º.docxã€‚

        **è½¬æ¢æ–¹æ³•ï¼š**
        1. ç”¨Wordæ‰“å¼€.docæ–‡ä»¶
        2. å¦å­˜ä¸º â†’ Wordæ–‡æ¡£(.docx)
        3. é‡æ–°ä¸Šä¼ 
        """)

    with st.expander("2ï¸âƒ£ æ€æ ·ä¿æŒåŸæ–‡æ¡£æ ¼å¼ï¼Ÿ"):
        st.markdown("""
        æœ¬å·¥å…·è‡ªåŠ¨ä¿ç•™ï¼š
        â€¢ æ®µè½æ ¼å¼
        â€¢ å­—ä½“æ ·å¼
        â€¢ è¡¨æ ¼ç»“æ„
        â€¢ é¢œè‰²ç­‰

        åªæ›¿æ¢æ–‡æœ¬å†…å®¹ï¼Œä¸å½±å“å…¶ä»–æ ¼å¼ã€‚
        """)

    with st.expander("3ï¸âƒ£ å¦‚ä½•åˆå¹¶å¤šä¸ªæ–‡æ¡£ï¼Ÿ"):
        st.markdown("""
        1. è®¾ç½®æ›¿æ¢è§„åˆ™å¹¶æ‰§è¡Œæ›¿æ¢
        2. åœ¨"ä¸‹è½½ç»“æœ"é€‰æ‹©"åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£"
        3. ç‚¹å‡»"ä¸‹è½½åˆå¹¶æ–‡æ¡£"

        ä¼šè‡ªåŠ¨åœ¨æ¯ä¸ªæ–‡æ¡£é—´æ’å…¥åˆ†é¡µç¬¦ã€‚
        """)

    with st.expander("4ï¸âƒ£ èƒ½å¦å¤„ç†å¤§æ•°æ®ï¼Ÿ"):
        st.markdown("""
        **é™åˆ¶è¯´æ˜ï¼š**
        â€¢ Wordæ–‡ä»¶ï¼šæœ€å¤§50MB
        â€¢ Excelæ–‡ä»¶ï¼šæœ€å¤§50MB
        â€¢ è¡Œæ•°ï¼šå»ºè®®<1000è¡Œ

        å¤§æ•°æ®å»ºè®®åˆ†æ‰¹å¤„ç†ã€‚
        """)

    with st.expander("5ï¸âƒ£ è§„åˆ™å¦‚ä½•ä¿å­˜ï¼Ÿ"):
        st.markdown("""
        **ä¸¤ç§ä¿å­˜æ–¹å¼ï¼š**

        1. **å¯¼å‡ºJSON**
           - ä¸‹è½½è§„åˆ™æ–‡ä»¶
           - å¯åœ¨å…¶ä»–ç”µè„‘å¯¼å…¥

        2. **ä¿å­˜ç¼“å­˜**
           - å¿«é€Ÿä¿å­˜
           - æœ¬åœ°å¿«é€ŸåŠ è½½
        """)

    st.markdown("---")

    # æ›´æ–°æ—¥å¿—
    st.markdown("### ğŸ“ æ›´æ–°æ—¥å¿—")

    st.markdown("""
    **v1.4.1** â­ æœ€æ–°
    - å®Œå…¨é‡æ„å¸ƒå±€ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒ
    - æ•´åˆåŠŸèƒ½åˆ°æ ‡ç­¾é¡µ
    - ä¼˜åŒ–ä¾§æ ä¿¡æ¯å±•ç¤º
    - æ”¹è¿›å“åº”å¼è®¾è®¡

    **v1.4.0**
    - æ–°å¢å¿«é€ŸåŠ è½½ç¼“å­˜è§„åˆ™
    - æ–°å¢æ“ä½œå†å²è®°å½•
    - æ–°å¢å…³é”®å­—æ›¿æ¢ç»Ÿè®¡
    - æ–°å¢å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°CSV
    - æ–°å¢è§„åˆ™æ’¤é”€åŠŸèƒ½

    **v1.3.2**
    - ä¿®å¤å¤šä¸ªbug
    - ä¼˜åŒ–åˆå¹¶æ–‡æ¡£æ ¼å¼ä¿ç•™

    **v1.3.0**
    - æ·»åŠ åˆå¹¶æ–‡æ¡£åŠŸèƒ½

    **v1.0.0**
    - åˆå§‹ç‰ˆæœ¬
    """)

    st.markdown("---")

    st.markdown("""
    <div style='text-align: center; padding: 20px; color: #666;'>
    <p>Â© 2024 Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·</p>
    <p>è®©æ‰¹é‡æ›¿æ¢å˜å¾—ç®€å•é«˜æ•ˆ</p>
    </div>
    """, unsafe_allow_html=True)