import os
import sys
import tempfile
from tempfile import NamedTemporaryFile
import warnings
import shutil
import json
import io
import zipfile
import re
import unicodedata
import copy
from datetime import datetime
import hashlib

# æ•°æ®å¤„ç†åº“
import streamlit as st
import pandas as pd

# Wordå¤„ç†åº“
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.oxml import OxmlElement
from docx.oxml.ns import qn

# æ•°æ®ç»“æ„å’Œç±»å‹æç¤º
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple, Set
from collections import defaultdict
from decimal import Decimal, ROUND_HALF_UP

# ==================== é…ç½®å’Œå¸¸é‡ ====================

# é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯
VERSION = "v1.5.1"

# é¡µé¢é…ç½®å¸¸é‡
PAGE_SIZE = 10  # æ¯é¡µæ˜¾ç¤ºçš„æ–‡ä»¶æ•°
WIDGET_HEIGHT = 250  # ç»„ä»¶é«˜åº¦
PREVIEW_ROWS = 20  # æ•°æ®é¢„è§ˆè¡Œæ•°
MAX_FILENAME_LENGTH = 200  # æœ€å¤§æ–‡ä»¶åé•¿åº¦
MAX_WORD_FILE_SIZE = 50 * 1024 * 1024  # æœ€å¤§Wordæ–‡ä»¶å¤§å°ï¼š50MB
MAX_EXCEL_FILE_SIZE = 50 * 1024 * 1024  # æœ€å¤§Excelæ–‡ä»¶å¤§å°ï¼š50MB
CACHE_DIR = ".replace_cache"  # ç¼“å­˜ç›®å½•
HISTORY_FILE = ".replace_history.json"  # å†å²è®°å½•æ–‡ä»¶
MAX_HISTORY_ITEMS = 30  # æœ€å¤šä¿å­˜å†å²è®°å½•æ•°

# è¿‡æ»¤è­¦å‘Šæ¶ˆæ¯
warnings.filterwarnings("ignore", category=UserWarning)

# ç¯å¢ƒå˜é‡é…ç½®
os.environ["STREAMLIT_VERSION"] = "1.51.0"
os.environ["STREAMLIT_SERVER_HEADLESS"] = "true"
os.environ["STREAMLIT_BROWSER_GATHER_USAGE_STATS"] = "false"

# ==================== Streamlité¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== å…¨å±€æ ·å¼ ====================
st.markdown("""
<style>
    /* ===== å…¨å±€é—´è·ä¼˜åŒ– ===== */
    .main {
        padding: 0.5rem 1rem !important;
    }

    [data-testid="stMainBlockContainer"] {
        padding-top: 0.5rem !important;
        padding-bottom: 0.5rem !important;
    }

    /* å—å®¹å™¨ç´§å‡‘ */
    .stContainer {
        padding: 0.75rem !important;
        margin-bottom: 0.5rem !important;
        border-radius: 6px;
        background-color: #ffffff;
    }

    /* åˆ é™¤å…ƒç´ é—´å¤šä½™é—´è· */
    .element-container {
        margin-bottom: 0.3rem !important;
    }

    .stColumn {
        gap: 0.5rem !important;
    }

    /* ===== æŒ‰é’®æ ·å¼ ===== */
    .stButton > button {
        border-radius: 5px;
        font-weight: 500;
        padding: 0.4rem 0.8rem !important;
        font-size: 13px !important;
        margin-bottom: 0.2rem !important;
    }

    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 2px 8px rgba(0,0,0,0.12);
    }

    /* ===== è¾“å…¥æ¡†æ ·å¼ ===== */
    .stTextInput, .stTextArea, .stSelectbox, .stNumberInput {
        margin-bottom: 0.3rem !important;
    }

    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea,
    .stSelectbox > div > div > select,
    .stNumberInput > div > div > input {
        border-radius: 5px;
        border: 1px solid #e0e0e0;
        font-size: 13px;
        padding: 0.5rem !important;
    }

    /* ===== æ ‡é¢˜å’Œæ–‡å­—æ ·å¼ ===== */
    h1 {
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #1f77b4;
        margin-bottom: 0.5rem;
        line-height: 1.2;
    }

    h2 {
        margin-top: 0.5rem;
        margin-bottom: 0.3rem;
        color: #1f77b4;
        font-size: 1.2rem;
    }

    h3 {
        margin-top: 0.3rem;
        margin-bottom: 0.2rem;
        color: #333;
        font-size: 1.05rem;
    }

    .stSubheader {
        margin-bottom: 0.5rem !important;
        padding-bottom: 0.3rem;
        border-bottom: 1.5px solid #e0e0e0;
        font-size: 1.1rem !important;
    }

    /* ===== å±•å¼€å™¨æ ·å¼ ===== */
    .streamlit-expander {
        margin-bottom: 0.3rem !important;
        border-radius: 5px;
    }

    /* ===== æ ‡ç­¾é¡µæ ·å¼ ===== */
    .stTabs [data-baseweb="tab-list"] {
        gap: 1px;
        margin-bottom: 0.5rem;
    }

    .stTabs [data-baseweb="tab"] {
        height: 40px;
        padding-top: 8px;
        border-radius: 5px 5px 0 0;
        font-size: 13px;
    }

    /* ===== æ•°æ®æ¡†æ ·å¼ ===== */
    div[data-testid="stDataFrame"] {
        border-radius: 5px;
        border: 1px solid #e0e0e0;
        font-size: 12px;
    }

    /* ===== æŒ‡æ ‡å¡æ ·å¼ ===== */
    .metric-container {
        background-color: #f8f9fa;
        padding: 0.5rem !important;
        border-radius: 5px;
        border-left: 3px solid #1f77b4;
        margin-bottom: 0.3rem;
    }

    /* ===== ä¿¡æ¯æ¡†æ ·å¼ ===== */
    .stats-box, .success-box, .warning-box, .error-box {
        padding: 0.6rem !important;
        margin: 0.3rem 0 !important;
        border-radius: 5px;
        border-left-width: 3px;
        font-size: 13px;
    }

    .stats-box {
        background-color: #f0f9ff;
        border-left-color: #0ea5e9;
    }

    .success-box {
        background-color: #f0fdf4;
        border-left-color: #22c55e;
    }

    .warning-box {
        background-color: #fffbeb;
        border-left-color: #f59e0b;
    }

    .error-box {
        background-color: #fef2f2;
        border-left-color: #ef4444;
    }

    /* ===== åˆ†éš”çº¿ ===== */
    hr {
        margin: 0.5rem 0 !important;
        border: none;
        border-top: 1px solid #e0e0e0;
    }

    /* ===== æ— çº¿ç”µå’Œå¤é€‰æ¡†æ ·å¼ ===== */
    .stRadio, .stCheckbox {
        margin-bottom: 0.2rem !important;
    }

    .stRadio > label, .stCheckbox > label {
        margin-bottom: 0.2rem !important;
        font-size: 13px;
    }

    /* ===== æ–‡ä»¶ä¸Šä¼ å™¨æ ·å¼ ===== */
    .stFileUploader {
        margin-bottom: 0.3rem !important;
    }

    /* ===== è¿›åº¦æ¡æ ·å¼ ===== */
    .stProgress {
        margin-bottom: 0.3rem !important;
    }

    /* ===== è¡¨æ ¼æ ·å¼ ===== */
    table {
        font-size: 12px !important;
    }

    td, th {
        padding: 0.4rem !important;
    }

    /* ===== Wordé¢„è§ˆåŒºåŸŸæ ·å¼ï¼ˆä¿®å¤é«˜åº¦é—®é¢˜ï¼‰ ===== */
    .word-preview-area {
        height: 280px;
        overflow-y: auto;
        padding: 12px;
        border: 1px solid #e0e0e0;
        border-radius: 6px;
        font-size: 13px;
        line-height: 1.6;
        background-color: #f9f9f9;
        word-break: break-word;
        white-space: pre-wrap;
    }

    /* ===== è§„åˆ™åˆ—è¡¨å®¹å™¨æ ·å¼ ===== */
    .rule-list-container {
        border: 1px solid #e0e0e0;
        border-radius: 6px;
        padding: 8px;
        background-color: #f9f9f9;
        height: 280px;
        overflow-y: auto;
    }

    /* ===== å“åº”å¼è®¾è®¡ ===== */
    @media (max-width: 768px) {
        .main {
            padding: 0.3rem 0.5rem;
        }
        .stContainer {
            padding: 0.5rem;
        }
    }

    /* ===== å¸®åŠ©æç¤ºæ ·å¼ ===== */
    .help-text {
        color: #0ea5e9;
        cursor: help;
        font-weight: bold;
    }

    .help-tooltip {
        background-color: #f0f9ff;
        border-left: 3px solid #0ea5e9;
        padding: 8px;
        border-radius: 4px;
        margin-top: 4px;
        font-size: 12px;
        color: #0c4a6e;
    }
</style>
""", unsafe_allow_html=True)


# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

@dataclass
class ReplacedFile:
    """
    å­˜å‚¨æ›¿æ¢åçš„æ–‡ä»¶æ•°æ®ç»“æ„

    Attributes:
        filename (str): ç”Ÿæˆçš„æ–‡ä»¶å
        data (io.BytesIO): æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®
        row_idx (int): å¯¹åº”Excelè¡Œå·
        log (str): æ›¿æ¢æ—¥å¿—ä¿¡æ¯
        replace_count (int): æ›¿æ¢æ¬¡æ•°
    """
    filename: str
    data: io.BytesIO
    row_idx: int
    log: str
    replace_count: int = 0


@dataclass
class HistoryRecord:
    """
    å†å²è®°å½•æ•°æ®ç»“æ„

    Attributes:
        timestamp (str): æ“ä½œæ—¶é—´
        word_file (str): Wordæ–‡ä»¶å
        excel_file (str): Excelæ–‡ä»¶å
        rules_count (int): è§„åˆ™æ•°é‡
        files_generated (int): ç”Ÿæˆæ–‡ä»¶æ•°
        status (str): æ“ä½œçŠ¶æ€(success/failed)
    """
    timestamp: str
    word_file: str
    excel_file: str
    rules_count: int
    files_generated: int
    status: str


# ==================== ç¼“å­˜ç®¡ç†å™¨ ====================

class CacheManager:
    """
    ç®¡ç†æ›¿æ¢è§„åˆ™çš„ç¼“å­˜
    è´Ÿè´£ä¿å­˜ã€åŠ è½½å’Œåˆ—å‡ºç¼“å­˜çš„è§„åˆ™
    """

    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨ï¼Œåˆ›å»ºç¼“å­˜ç›®å½•"""
        self.cache_dir = CACHE_DIR
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)

    def save_rules(self, rules: List[Tuple[str, str]], filename: str):
        """
        ä¿å­˜è§„åˆ™åˆ°JSONç¼“å­˜æ–‡ä»¶

        Args:
            rules: è§„åˆ™åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(å…³é”®å­—, Excelåˆ—å)çš„å…ƒç»„
            filename: ç¼“å­˜æ–‡ä»¶å
        """
        try:
            rules_data = [{"keyword": old, "excel_column": col} for old, col in rules]
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(rules_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥", icon="âš ï¸")

    def load_rules(self, filename: str) -> List[Tuple[str, str]]:
        """
        ä»ç¼“å­˜æ–‡ä»¶åŠ è½½è§„åˆ™

        Args:
            filename: ç¼“å­˜æ–‡ä»¶å

        Returns:
            è§„åˆ™åˆ—è¡¨
        """
        try:
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    rules_data = json.load(f)
                    return [(r["keyword"], r["excel_column"]) for r in rules_data]
        except:
            pass
        return []

    def get_cached_rules_list(self) -> List[str]:
        """
        è·å–æ‰€æœ‰ç¼“å­˜çš„è§„åˆ™æ–‡ä»¶åˆ—è¡¨

        Returns:
            ç¼“å­˜æ–‡ä»¶ååˆ—è¡¨ï¼ˆæœ€è¿‘10ä¸ªï¼‰
        """
        try:
            if os.path.exists(self.cache_dir):
                files = [f.replace('.json', '') for f in os.listdir(self.cache_dir) if f.endswith('.json')]
                return sorted(files, reverse=True)[:10]
        except:
            pass
        return []


# ==================== å†å²è®°å½•ç®¡ç†å™¨ ====================

class HistoryManager:
    """
    ç®¡ç†æ“ä½œå†å²è®°å½•
    è®°å½•æ¯æ¬¡æ›¿æ¢æ“ä½œçš„ä¿¡æ¯
    """

    def __init__(self):
        """åˆå§‹åŒ–å†å²è®°å½•ç®¡ç†å™¨"""
        self.history_file = HISTORY_FILE

    def add_record(self, record: HistoryRecord):
        """
        æ·»åŠ æ“ä½œè®°å½•åˆ°å†å²

        Args:
            record: HistoryRecordå¯¹è±¡
        """
        try:
            history = self.load_history()
            history.insert(0, {
                "timestamp": record.timestamp,
                "word_file": record.word_file,
                "excel_file": record.excel_file,
                "rules_count": record.rules_count,
                "files_generated": record.files_generated,
                "status": record.status
            })
            history = history[:MAX_HISTORY_ITEMS]
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except:
            pass

    def load_history(self) -> List[Dict]:
        """
        åŠ è½½æ‰€æœ‰å†å²è®°å½•

        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return []

    def clear_history(self):
        """æ¸…é™¤æ‰€æœ‰å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                os.remove(self.history_file)
                st.success("âœ… å†å²å·²æ¸…é™¤", icon="âœ…")
        except:
            pass


# ==================== ä¼šè¯çŠ¶æ€åˆå§‹åŒ– ====================

def init_session_state():
    """
    åˆå§‹åŒ–Streamlitä¼šè¯çŠ¶æ€
    ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„çŠ¶æ€å˜é‡éƒ½å­˜åœ¨
    """
    required_states = {
        "replace_rules": [],  # æ›¿æ¢è§„åˆ™åˆ—è¡¨
        "replaced_files": [],  # æ›¿æ¢åçš„æ–‡ä»¶åˆ—è¡¨
        "replace_log": [],  # æ›¿æ¢æ—¥å¿—
        "is_replacing": False,  # æ˜¯å¦æ­£åœ¨æ›¿æ¢ä¸­
        "replace_params": {},  # æ›¿æ¢å‚æ•°ç¼“å­˜
        "replace_scope": "æ›¿æ¢å®Œæ•´å…³é”®è¯",  # æ›¿æ¢èŒƒå›´æ¨¡å¼
        "export_mode_radio": "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰",  # å¯¼å‡ºæ¨¡å¼
        "undo_stack": [],  # è§„åˆ™æ’¤é”€æ ˆ
        "rule_filter": "",  # è§„åˆ™ç­›é€‰æ–‡æœ¬
        "show_advanced": False,  # æ˜¯å¦æ˜¾ç¤ºé«˜çº§é€‰é¡¹
    }

    for key, default in required_states.items():
        if key not in st.session_state:
            st.session_state[key] = default


# è°ƒç”¨åˆå§‹åŒ–å‡½æ•°
init_session_state()


# ==================== æ ¸å¿ƒå·¥å…·å‡½æ•° ====================

def clean_text(text: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬ï¼šå»é™¤é¦–å°¾ç©ºç™½ã€éšè—å­—ç¬¦ã€ç‰¹æ®Šç©ºæ ¼ï¼Œç»Ÿä¸€æ ¼å¼

    Args:
        text: è¾“å…¥æ–‡æœ¬

    Returns:
        æ¸…ç†åçš„æ–‡æœ¬
    """
    if not isinstance(text, str):
        return ""
    text = text.strip()
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r'[\u00A0\u2002-\u200B]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text


def clean_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦

    Args:
        filename: åŸå§‹æ–‡ä»¶å

    Returns:
        æ¸…ç†åçš„åˆæ³•æ–‡ä»¶å
    """
    return re.sub(r'[\\/:*?"<>|]', "_", str(filename))


def generate_safe_filename(
        excel_row: pd.Series,
        file_name_col: str,
        file_prefix: str = "",
        file_suffix: str = "",
        row_idx: int = 0,
        max_length: int = MAX_FILENAME_LENGTH
) -> str:
    """
    å®‰å…¨ç”Ÿæˆæ–‡ä»¶åï¼Œå¤„ç†è¶…é•¿åç§°å’Œç‰¹æ®Šå­—ç¬¦

    Args:
        excel_row: Excelè¡Œæ•°æ®
        file_name_col: æ–‡ä»¶åæ‰€åœ¨çš„åˆ—å
        file_prefix: æ–‡ä»¶åå‰ç¼€
        file_suffix: æ–‡ä»¶ååç¼€
        row_idx: è¡Œå·ï¼ˆå¤‡ç”¨ï¼‰
        max_length: æœ€å¤§é•¿åº¦

    Returns:
        æ¸…ç†åçš„æ–‡ä»¶å
    """
    try:
        # è·å–åŸºç¡€åç§°
        if file_name_col and file_name_col in excel_row.index:
            base_name = clean_text(str(excel_row[file_name_col]))
        else:
            base_name = f"æ–‡ä»¶_{row_idx + 1}"

        # ç¡®ä¿åŸºç¡€åç§°ä¸ä¸ºç©º
        if not base_name or base_name.isspace():
            base_name = f"æ–‡ä»¶_{row_idx + 1}"

        # æ„å»ºå®Œæ•´æ–‡ä»¶å
        if file_prefix and file_suffix:
            filename = f"{file_prefix}{base_name}{file_suffix}.docx"
        elif file_prefix:
            filename = f"{file_prefix}{base_name}.docx"
        elif file_suffix:
            filename = f"{base_name}{file_suffix}.docx"
        else:
            filename = f"{base_name}.docx"

        # æ¸…ç†éæ³•å­—ç¬¦
        filename = clean_filename(filename)

        # é™åˆ¶é•¿åº¦ï¼ˆWindowsé™åˆ¶255å­—èŠ‚ï¼‰
        filename_bytes = filename.encode('utf-8')
        if len(filename_bytes) > max_length:
            truncated_base = base_name
            while len(f"{file_prefix}{truncated_base}{file_suffix}.docx".encode('utf-8')) > max_length:
                truncated_base = truncated_base[:-1]

            if file_prefix and file_suffix:
                filename = f"{file_prefix}{truncated_base}{file_suffix}.docx"
            elif file_prefix:
                filename = f"{file_prefix}{truncated_base}.docx"
            elif file_suffix:
                filename = f"{truncated_base}{file_suffix}.docx"
            else:
                filename = f"{truncated_base}.docx"

            filename = clean_filename(filename)

        return filename

    except:
        return f"æ–‡ä»¶_{row_idx + 1}.docx"


def precompute_replace_patterns(
        replace_rules: List[Tuple[str, str]],
        excel_row: pd.Series
) -> List[Tuple[str, str, str, str]]:
    """
    é¢„è®¡ç®—æ‰€æœ‰éœ€è¦æ›¿æ¢çš„æ¨¡å¼ï¼Œå‡å°‘é‡å¤è®¡ç®—

    Args:
        replace_rules: æ›¿æ¢è§„åˆ™åˆ—è¡¨
        excel_row: å½“å‰å¤„ç†çš„Excelè¡Œæ•°æ®

    Returns:
        æ›¿æ¢æ¨¡å¼åˆ—è¡¨ï¼š[(åŸå§‹å…³é”®è¯, åˆ—å, æ¸…ç†åå…³é”®è¯, æ›¿æ¢å€¼), ...]
    """
    replace_patterns = []

    for old_text, col_name in replace_rules:
        # è·å–Excelä¸­å¯¹åº”åˆ—çš„æ›¿æ¢å€¼
        if col_name in excel_row.index:
            replacement = str(excel_row[col_name]).strip()
        else:
            replacement = ""

        # æ¸…ç†ç”¨æˆ·è¾“å…¥çš„å…³é”®è¯
        cleaned_text = clean_text(old_text)

        # è·³è¿‡ç©ºå…³é”®è¯
        if not cleaned_text:
            continue

        # æ ¹æ®æ›¿æ¢èŒƒå›´é€‰é¡¹ç”Ÿæˆæ›¿æ¢å€¼
        if st.session_state.replace_scope == "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹":
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¦æ‹¬å·çš„æ ¼å¼ï¼Œåªæ›¿æ¢æ‹¬å·å†…çš„å†…å®¹
            if cleaned_text.startswith("ã€") and cleaned_text.endswith("ã€‘"):
                new_format = f"ã€{replacement}ã€‘"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ï¼ˆ") and cleaned_text.endswith("ï¼‰"):
                new_format = f"ï¼ˆ{replacement}ï¼‰"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("(") and cleaned_text.endswith(")"):
                new_format = f"({replacement})"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ã€”") and cleaned_text.endswith("ã€•"):
                new_format = f"ã€”{replacement}ã€•"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            else:
                replace_patterns.append((old_text, col_name, cleaned_text, replacement))
        else:
            # æ›¿æ¢å®Œæ•´å…³é”®è¯
            replace_patterns.append((old_text, col_name, cleaned_text, replacement))

    return replace_patterns


def process_paragraph(
        paragraph,
        replace_patterns: List[Tuple[str, str, str, str]],
        cleaned_para: str = None
) -> Dict:
    """
    å¤„ç†å•ä¸ªæ®µè½çš„å…³é”®å­—æ›¿æ¢

    Args:
        paragraph: è¦å¤„ç†çš„æ®µè½å¯¹è±¡
        replace_patterns: æ›¿æ¢æ¨¡å¼åˆ—è¡¨
        cleaned_para: é¢„æ¸…ç†çš„æ®µè½æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰

    Returns:
        æ›¿æ¢è®¡æ•°å­—å…¸ï¼š{(åŸå§‹å…³é”®è¯, åˆ—å): æ›¿æ¢æ¬¡æ•°, ...}
    """
    para_text = paragraph.text
    if cleaned_para is None:
        cleaned_para = clean_text(para_text)
    replace_count = defaultdict(int)

    # å¦‚æœæ®µè½ä¸ºç©ºï¼Œç›´æ¥è¿”å›
    if not para_text or not replace_patterns:
        return replace_count

    has_keyword = False

    # æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«ä»»ä½•éœ€è¦æ›¿æ¢çš„å…³é”®å­—ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
    for old_text, col_name, format_keyword, replacement in replace_patterns:
        if format_keyword and format_keyword in cleaned_para:
            has_keyword = True
            break

    if has_keyword:
        # åˆ›å»ºæ–°æ–‡æœ¬å¹¶æ›¿æ¢æ‰€æœ‰å…³é”®å­—
        new_text = para_text
        for old_text, col_name, format_keyword, replacement in replace_patterns:
            if format_keyword and format_keyword in cleaned_para:
                count = new_text.count(format_keyword)
                if count > 0:
                    new_text = new_text.replace(format_keyword, replacement)
                    replace_count[(old_text, col_name)] += count

        # æ›´æ–°æ®µè½æ–‡æœ¬ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªRunçš„æ ¼å¼ï¼‰
        if len(paragraph.runs) > 0:
            paragraph.runs[0].text = new_text
            # æ¸…ç©ºå…¶ä»–Run
            for i in range(1, len(paragraph.runs)):
                paragraph.runs[i].text = ''

    return replace_count


def replace_word_with_format(
        word_file: st.runtime.uploaded_file_manager.UploadedFile,
        excel_row: pd.Series,
        replace_rules: List[Tuple[str, str]]
) -> Tuple[io.BytesIO, str, int]:
    """
    æ›¿æ¢Wordæ–‡ä»¶ä¸­çš„å…³é”®å­—ï¼Œä¿ç•™æ ¼å¼

    Args:
        word_file: ä¸Šä¼ çš„Wordæ–‡ä»¶
        excel_row: å½“å‰Excelè¡Œæ•°æ®
        replace_rules: æ›¿æ¢è§„åˆ™åˆ—è¡¨

    Returns:
        (æ›¿æ¢åçš„æ–‡ä»¶æ•°æ®, æ›¿æ¢æ—¥å¿—, æ›¿æ¢æ€»æ¬¡æ•°)
    """
    replace_count = defaultdict(int)
    total_replace = 0

    try:
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = len(word_file.getvalue())
        if file_size > MAX_WORD_FILE_SIZE:
            raise ValueError(f"æ–‡ä»¶è¿‡å¤§")

        # ä»å†…å­˜åŠ è½½Wordæ–‡æ¡£
        doc = Document(io.BytesIO(word_file.getvalue()))

        # é¢„è®¡ç®—æ›¿æ¢æ¨¡å¼ï¼Œå‡å°‘é‡å¤è®¡ç®—
        replace_patterns = precompute_replace_patterns(replace_rules, excel_row)

        # å¦‚æœæ²¡æœ‰æ›¿æ¢æ¨¡å¼ï¼Œç›´æ¥è¿”å›åŸæ–‡æ¡£
        if not replace_patterns:
            output_file = io.BytesIO()
            doc.save(output_file)
            output_file.seek(0)
            return output_file, "âš  æœªæ‰¾åˆ°åŒ¹é…è§„åˆ™", 0

        # 1. å¤„ç†æ®µè½ä¸­çš„å…³é”®è¯
        for paragraph in doc.paragraphs:
            para_count = process_paragraph(paragraph, replace_patterns)
            for key, count in para_count.items():
                replace_count[key] += count
                total_replace += count

        # 2. å¤„ç†è¡¨æ ¼å†…çš„å…³é”®è¯ï¼ˆæ”¯æŒè¡¨æ ¼å†…æ–‡å­—æ›¿æ¢ï¼‰
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        para_count = process_paragraph(paragraph, replace_patterns)
                        for key, count in para_count.items():
                            replace_count[key] += count
                            total_replace += count

        # ä¿å­˜ä¿®æ”¹åçš„æ–‡æ¡£
        output_file = io.BytesIO()
        doc.save(output_file)
        output_file.seek(0)

        # ç”Ÿæˆæ›¿æ¢æ—¥å¿—
        if replace_count:
            log_lines = [f"âœ“ {old}" for old, _ in replace_count.keys()]
            replace_log = ", ".join(log_lines[:3])
            if len(replace_count) > 3:
                replace_log += f" ç­‰{len(replace_count) - 3}ä¸ª"
        else:
            replace_log = "âš  æ— æ›¿æ¢"

        return output_file, replace_log, total_replace

    except Exception as e:
        return io.BytesIO(), f"âŒ å¤±è´¥", 0


def merge_word_documents(
        replaced_files: List[ReplacedFile]
) -> io.BytesIO:
    """
    åˆå¹¶å¤šä¸ªWordæ–‡æ¡£ä¸ºä¸€ä¸ªï¼ˆä¿ç•™æ‰€æœ‰æ ¼å¼å’Œç»“æ„ï¼‰

    Args:
        replaced_files: æ›¿æ¢åçš„æ–‡ä»¶åˆ—è¡¨

    Returns:
        åˆå¹¶åçš„Wordæ–‡æ¡£æ•°æ®
    """
    if not replaced_files:
        raise ValueError("æ²¡æœ‰æ–‡ä»¶")

    try:
        # åŠ è½½ç¬¬ä¸€ä¸ªæ–‡æ¡£ä½œä¸ºä¸»æ–‡æ¡£
        main_doc = Document(io.BytesIO(replaced_files[0].data.getvalue()))
        main_body = main_doc._body._element

        # é€ä¸ªæ·»åŠ å…¶ä»–æ–‡æ¡£
        for idx in range(1, len(replaced_files)):
            try:
                file = replaced_files[idx]

                # æ£€æŸ¥æ–‡ä»¶æ•°æ®æœ‰æ•ˆæ€§
                if not file.data or len(file.data.getvalue()) == 0:
                    continue

                # åŠ è½½å­æ–‡æ¡£
                sub_doc = Document(io.BytesIO(file.data.getvalue()))
                sub_body = sub_doc._body._element

                # æ·»åŠ åˆ†é¡µç¬¦
                page_break_para = OxmlElement('w:p')
                page_break_pPr = OxmlElement('w:pPr')

                page_break_element = OxmlElement('w:pageBreakBefore')
                page_break_element.set(qn('w:val'), '1')

                page_break_pPr.append(page_break_element)
                page_break_para.append(page_break_pPr)
                main_body.append(page_break_para)

                # æ·±æ‹·è´æ‰€æœ‰å…ƒç´ ä»¥ä¿ç•™æ ¼å¼
                for element in sub_body:
                    main_body.append(copy.deepcopy(element))

            except:
                continue

        # ä¿å­˜åˆå¹¶åçš„æ–‡æ¡£
        output = io.BytesIO()
        main_doc.save(output)
        output.seek(0)
        return output

    except Exception as e:
        raise


def get_replace_params(
        word_file: Optional[st.runtime.uploaded_file_manager.UploadedFile],
        excel_df: Optional[pd.DataFrame],
        start_row: int,
        end_row: int,
        file_name_col: str,
        file_prefix: str,
        file_suffix: str
) -> Dict:
    """
    è·å–æ›¿æ¢å‚æ•°ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°æ›¿æ¢

    Args:
        word_file: ä¸Šä¼ çš„Wordæ–‡ä»¶
        excel_df: Excelæ•°æ®æ¡†
        start_row: èµ·å§‹è¡Œ
        end_row: ç»“æŸè¡Œ
        file_name_col: æ–‡ä»¶ååˆ—
        file_prefix: æ–‡ä»¶å‰ç¼€
        file_suffix: æ–‡ä»¶åç¼€

    Returns:
        æ›¿æ¢å‚æ•°å­—å…¸
    """
    return {
        "word_filename": word_file.name if word_file else "",
        "excel_rows": len(excel_df) if excel_df is not None else 0,
        "start_row": start_row,
        "end_row": end_row,
        "file_name_col": file_name_col,
        "rule_count": len(st.session_state.replace_rules),
        "rule_hash": hash(tuple(st.session_state.replace_rules))
    }


def clean_excel_types(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ¸…ç†Excelæ•°æ®ç±»å‹ï¼Œé¿å…æ··åˆç±»å‹å¯¼è‡´çš„é—®é¢˜

    Args:
        df: è¾“å…¥çš„æ•°æ®æ¡†

    Returns:
        æ¸…ç†åçš„æ•°æ®æ¡†
    """
    df_clean = df.copy()

    for col in df_clean.columns:
        try:
            col_name = str(col)
            if col_name != col:
                df_clean = df_clean.rename(columns={col: col_name})
                col = col_name

            df_clean[col] = df_clean[col].fillna("")
            df_clean[col] = df_clean[col].astype(str).str.strip()

        except:
            try:
                df_clean[col] = df_clean[col].astype(str).str.strip()
            except:
                pass

    return df_clean


def get_file_hash(file_data: bytes) -> str:
    """
    è·å–æ–‡ä»¶å“ˆå¸Œå€¼ï¼ˆç”¨äºéªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼‰

    Args:
        file_data: æ–‡ä»¶äºŒè¿›åˆ¶æ•°æ®

    Returns:
        æ–‡ä»¶å“ˆå¸Œå€¼çš„å‰6ä½
    """
    return hashlib.md5(file_data).hexdigest()[:6]


def export_statistics_to_csv(replaced_files: List[ReplacedFile]) -> str:
    """
    å¯¼å‡ºæ›¿æ¢ç»Ÿè®¡æ•°æ®åˆ°CSVæ ¼å¼

    Args:
        replaced_files: æ›¿æ¢åçš„æ–‡ä»¶åˆ—è¡¨

    Returns:
        CSVæ ¼å¼çš„å­—ç¬¦ä¸²
    """
    try:
        data = []
        for idx, file in enumerate(replaced_files, 1):
            data.append({
                "åºå·": idx,
                "æ–‡ä»¶å": file.filename,
                "è¡Œå·": file.row_idx + 1,
                "æ›¿æ¢æ¬¡æ•°": file.replace_count,
                "çŠ¶æ€": "âœ…" if file.data and len(file.data.getvalue()) > 0 else "âŒ"
            })

        df = pd.DataFrame(data)
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        return csv_buffer.getvalue()
    except:
        return ""


def get_keyword_statistics(replace_rules: List[Tuple[str, str]],
                           replaced_files: List[ReplacedFile]) -> Dict:
    """
    è·å–å…³é”®å­—æ›¿æ¢ç»Ÿè®¡

    Args:
        replace_rules: æ›¿æ¢è§„åˆ™åˆ—è¡¨
        replaced_files: æ›¿æ¢åçš„æ–‡ä»¶åˆ—è¡¨

    Returns:
        å…³é”®å­—ç»Ÿè®¡å­—å…¸
    """
    stats = {}
    for keyword, _ in replace_rules:
        stats[keyword] = 0

    for file in replaced_files:
        for keyword, _ in replace_rules:
            if f"âœ“ {keyword}" in file.log:
                pattern = f"âœ“ {re.escape(keyword)}.*?\((\d+)æ¬¡\)"
                matches = re.findall(pattern, file.log)
                if matches:
                    stats[keyword] += int(matches[0])

    return stats


# ==================== åˆ›å»ºç®¡ç†å™¨å®ä¾‹ ====================
cache_manager = CacheManager()
history_manager = HistoryManager()

# ==================== ä¾§æ  ====================
with st.sidebar:
    st.title("ğŸ“š å¿«é€Ÿå¯¼èˆª")

    # ç»Ÿè®¡ä¿¡æ¯
    if st.session_state.replaced_files:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“„ æ–‡ä»¶æ•°", len(st.session_state.replaced_files), delta=None)
        with col2:
            st.metric("ğŸ“‹ è§„åˆ™æ•°", len(st.session_state.replace_rules), delta=None)

    st.markdown("---")

    # å¿«é€ŸåŠŸèƒ½
    st.subheader("âš¡ å¿«é€ŸåŠŸèƒ½")

    # å¿«é€ŸåŠ è½½ç¼“å­˜è§„åˆ™
    cached = cache_manager.get_cached_rules_list()
    if cached:
        selected = st.selectbox("ğŸ“‚ åŠ è½½è§„åˆ™", ["é€‰æ‹©..."] + cached, key="sidebar_cache")
        if selected and selected != "é€‰æ‹©...":
            if st.button("âœ… åŠ è½½", key="sidebar_load", use_container_width=True):
                loaded = cache_manager.load_rules(selected)
                if loaded:
                    st.session_state.replace_rules = loaded
                    st.success(f"âœ… åŠ è½½{len(loaded)}æ¡", icon="âœ…")
                    st.rerun()

    # å†å²è®°å½•æ˜¾ç¤º
    history = history_manager.load_history()
    if history:
        st.subheader("ğŸ“œ æœ€è¿‘æ“ä½œ")
        for h in history[:3]:
            status = "âœ…" if h["status"] == "success" else "âŒ"
            st.caption(f"{status} {h['timestamp']}\n{h['word_file'][:15]}...")

    st.markdown("---")

    # å·¥å…·æ“ä½œ
    st.subheader("ğŸ”§ å·¥å…·")

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰", key="sidebar_clear", use_container_width=True):
        st.session_state.replace_rules = []
        st.session_state.replaced_files = []
        st.success("âœ… å·²æ¸…ç©º", icon="âœ…")
        st.rerun()

    if history:
        if st.button("ğŸ“œ æ¸…é™¤å†å²", key="sidebar_clear_hist", use_container_width=True):
            history_manager.clear_history()
            st.rerun()

# ==================== ä¸»é¡µé¢ - æ ‡é¢˜ ====================
col_title1, col_title2 = st.columns([8, 2])
with col_title1:
    st.title("ğŸ“‹ Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·")
with col_title2:
    st.markdown(
        f"<div style='text-align: right; padding-top: 5px;'><small style='color: #999;'>v{VERSION}</small></div>",
        unsafe_allow_html=True)

# è¿›åº¦æ˜¾ç¤ºï¼ˆå¦‚æœæœ‰æ›¿æ¢ä»»åŠ¡ï¼‰
if st.session_state.replaced_files and st.session_state.replace_params:
    progress_col, status_col = st.columns([3, 1])
    with progress_col:
        success_count = len([f for f in st.session_state.replaced_files
                             if f.data and len(f.data.getvalue()) > 0])
        total_count = len(st.session_state.replaced_files)
        st.progress(success_count / total_count if total_count > 0 else 0)
    with status_col:
        st.metric("æˆåŠŸç‡", f"{int(success_count / total_count * 100) if total_count > 0 else 0}%")

st.markdown("---")

# ==================== ä¸»å·¥ä½œåŒº ====================
col_main_left, col_main_right = st.columns([2, 1], gap="medium")

# ==================== å·¦ä¾§ï¼šæ–‡ä»¶ä¸Šä¼ å’Œé¢„è§ˆ ====================
with col_main_left:
    st.subheader("ğŸ“¤ æ–‡ä»¶ä¸Šä¼ ")

    # ä¸Šä¼ åŒºåŸŸ
    col_upload1, col_upload2 = st.columns(2, gap="small")

    with col_upload1:
        st.markdown("**Wordæ¨¡æ¿** â„¹ï¸")
        with st.expander("", expanded=False):
            st.markdown("""
            **æ­¥éª¤ï¼š**
            1. ä¸Šä¼ åŒ…å«è¦æ›¿æ¢å†…å®¹çš„Wordæ–‡ä»¶
            2. æ ¼å¼å¿…é¡»æ˜¯.docxï¼ˆä¸æ”¯æŒ.docï¼‰
            3. æœ€å¤§æ–‡ä»¶å¤§å°50MB

            **ç¤ºä¾‹ï¼š**
            åœ¨Wordä¸­æœ‰ã€Œã€å§“åã€‘ã€éœ€è¦æ›¿æ¢ä¸ºExcelä¸­çš„çœŸå®å§“å
            """)

        word_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=["docx"],
            key="word",
            label_visibility="collapsed",
            help="ä»…æ”¯æŒ.docxæ ¼å¼ï¼Œ.docéœ€å…ˆè½¬æ¢"
        )
        if word_file:
            file_size_mb = len(word_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_WORD_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ æ–‡ä»¶è¿‡å¤§", icon="âŒ")
                word_file = None
            else:
                st.caption(f"âœ… {file_size_mb:.1f}MB")

    with col_upload2:
        st.markdown("**Excelæ•°æ®** â„¹ï¸")
        with st.expander("", expanded=False):
            st.markdown("""
            **æ­¥éª¤ï¼š**
            1. ä¸Šä¼ åŒ…å«æ›¿æ¢æ•°æ®çš„Excelæ–‡ä»¶
            2. æ”¯æŒ.xlsxå’Œ.xlsæ ¼å¼
            3. ç¬¬ä¸€è¡Œé€šå¸¸ä¸ºåˆ—æ ‡é¢˜

            **ç¤ºä¾‹ï¼š**
            å§“ååˆ—åŒ…å«è¦æ›¿æ¢çš„çœŸå®å§“å
            """)

        excel_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=["xlsx", "xls"],
            key="excel",
            label_visibility="collapsed",
            help="æ”¯æŒ.xlsx/.xlsæ ¼å¼"
        )
        if excel_file:
            file_size_mb = len(excel_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_EXCEL_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ æ–‡ä»¶è¿‡å¤§", icon="âŒ")
                excel_file = None
            else:
                st.caption(f"âœ… {file_size_mb:.1f}MB")

    st.markdown("---")

    # æ–‡ä»¶é¢„è§ˆ - å¯æŠ˜å 
    with st.expander("ğŸ‘€ æ–‡ä»¶é¢„è§ˆ - ç‚¹å‡»æŸ¥çœ‹/å¤åˆ¶å†…å®¹", expanded=False):
        col_prev1, col_prev2 = st.columns(2, gap="small")

        excel_df = None
        excel_cols = []

        with col_prev1:
            st.markdown("**Wordæ–‡æ¡£å†…å®¹**")
            if word_file:
                try:
                    # è¯»å–Wordæ–‡ä»¶å¹¶ç”ŸæˆHTMLé¢„è§ˆ
                    doc = Document(io.BytesIO(word_file.getvalue()))

                    # æ„å»ºHTML
                    html_content = ""

                    # æ·»åŠ æ®µè½
                    for para in doc.paragraphs[:15]:  # é™åˆ¶æ˜¾ç¤ºæ®µè½æ•°
                        if para.text.strip():
                            text = para.text.replace("<", "&lt;").replace(">", "&gt;")
                            html_content += f"<p style='margin: 4px 0; word-break: break-all;'>{text}</p>"

                    # æ·»åŠ è¡¨æ ¼é¢„è§ˆ
                    for table_idx, table in enumerate(doc.tables[:2]):
                        html_content += f"<p style='margin-top: 8px; font-weight: bold; color: #1f77b4;'>ğŸ“Š è¡¨æ ¼{table_idx + 1}ï¼š</p>"
                        html_content += "<table style='border-collapse: collapse; width: 100%; font-size: 12px;'>"

                        for row_idx, row in enumerate(table.rows[:10]):
                            html_content += "<tr>"
                            for cell in row.cells:
                                cell_text = cell.text.replace("<", "&lt;").replace(">", "&gt;")[:30]
                                html_content += f"<td style='border: 1px solid #ccc; padding: 4px;'>{cell_text}</td>"
                            html_content += "</tr>"

                        html_content += "</table>"

                    # ä½¿ç”¨è‡ªå®šä¹‰HTMLç»„ä»¶æ˜¾ç¤º
                    st.components.v1.html(f"""
                    <div style='height: 280px; overflow-y: auto; padding: 12px; border: 1px solid #e0e0e0; 
                                border-radius: 6px; font-size: 13px; line-height: 1.6; background-color: #f9f9f9;
                                font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif; word-wrap: break-word;'>
                        {html_content}
                    </div>
                    """, height=300)

                    st.caption(f"ğŸ“„ {len(doc.paragraphs)}æ®µè½ï¼Œ{len(doc.tables)}è¡¨æ ¼")
                    st.info("ğŸ’¡ å¯ä»¥åœ¨ä¸Šæ–¹é€‰ä¸­å†…å®¹æŒ‰Ctrl+Cå¤åˆ¶ï¼Œç²˜è´´åˆ°ä¸‹æ–¹å…³é”®å­—è¾“å…¥æ¡†ä¸­", icon="â„¹ï¸")

                except Exception as e:
                    st.error(f"âŒ é¢„è§ˆå¤±è´¥ï¼š{str(e)[:50]}", icon="âŒ")
            else:
                st.info("è¯·ä¸Šä¼ Wordæ–‡ä»¶", icon="â„¹ï¸")

        with col_prev2:
            st.markdown("**Excelæ•°æ®é¢„è§ˆ**")
            if excel_file:
                try:
                    with NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_excel:
                        temp_excel.write(excel_file.getvalue())
                        excel_path = temp_excel.name

                    try:
                        with pd.ExcelFile(excel_path, engine="openpyxl") as excel_wb:
                            sheet_names = excel_wb.sheet_names
                            selected_sheet = sheet_names[0]

                            excel_df = pd.read_excel(
                                excel_wb,
                                sheet_name=selected_sheet,
                                dtype=str,
                                keep_default_na=False,
                                na_values=[]
                            )

                            if excel_df.empty:
                                st.warning("âš ï¸ è¡¨æ ¼ä¸ºç©º", icon="âš ï¸")
                            else:
                                excel_df = clean_excel_types(excel_df)
                                excel_cols = excel_df.columns.tolist()

                                # æ˜¾ç¤ºæ‘˜è¦
                                preview_df = excel_df.head(5)
                                st.dataframe(
                                    preview_df,
                                    use_container_width=True,
                                    hide_index=True,
                                    height=150
                                )

                                col_s1, col_s2 = st.columns(2)
                                with col_s1:
                                    st.metric("è¡Œæ•°", len(excel_df))
                                with col_s2:
                                    st.metric("åˆ—æ•°", len(excel_cols))

                    finally:
                        try:
                            os.unlink(excel_path)
                        except:
                            pass

                except Exception as e:
                    st.error(f"âŒ è¯»å–å¤±è´¥", icon="âŒ")
            else:
                st.info("è¯·ä¸Šä¼ Excelæ–‡ä»¶", icon="â„¹ï¸")

# ==================== å³ä¾§ï¼šè§„åˆ™ç®¡ç† ====================
with col_main_right:
    st.subheader("ğŸ“‹ è§„åˆ™ç®¡ç†")

    # æ›¿æ¢èŒƒå›´ - ç´§å‡‘æ˜¾ç¤º
    st.markdown("**æ›¿æ¢èŒƒå›´** â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("""
        **å®Œæ•´å…³é”®è¯ï¼š** ç›´æ¥æ›¿æ¢æ•´ä¸ªå†…å®¹
        - ã€å¼ ä¸‰ã€‘â†’ã€æå››ã€‘

        **æ‹¬å·å†…å®¹ï¼š** åªæ›¿æ¢æ‹¬å·å†…çš„æ–‡å­—
        - ä¿ç•™æ‹¬å·ç»“æ„ï¼Œåªæ”¹å˜æ‹¬å·é‡Œçš„å†…å®¹
        """)

    replace_scope = st.radio(
        "æ¨¡å¼",
        options=["å®Œæ•´å…³é”®è¯", "æ‹¬å·å†…å®¹"],
        key="replace_scope_compact",
        horizontal=True,
        label_visibility="collapsed"
    )
    st.session_state.replace_scope = ["æ›¿æ¢å®Œæ•´å…³é”®è¯", "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹"][
        ["å®Œæ•´å…³é”®è¯", "æ‹¬å·å†…å®¹"].index(replace_scope)]

    st.markdown("---")

    # è§„åˆ™åˆ—è¡¨ - ç´§å‡‘æ˜¾ç¤º
    st.markdown(f"**è§„åˆ™åˆ—è¡¨** ({len(st.session_state.replace_rules)}) â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("""
        **å¦‚ä½•æ·»åŠ è§„åˆ™ï¼š**
        1. ä»Wordé¢„è§ˆä¸­å¤åˆ¶å…³é”®å­—ï¼ˆå¦‚ã€å§“åã€‘ï¼‰
        2. ç²˜è´´åˆ°ä¸‹æ–¹"å…³é”®å­—"è¾“å…¥æ¡†
        3. é€‰æ‹©Excelå¯¹åº”çš„åˆ—
        4. ç‚¹å‡»"â• æ·»åŠ è§„åˆ™"
        """)

    if st.session_state.replace_rules:
        # è§„åˆ™å¿«é€Ÿæ˜¾ç¤º - é«˜åº¦ç»Ÿä¸€
        with st.container(border=True):
            for idx, (old, col) in enumerate(st.session_state.replace_rules):
                col_del, col_rule = st.columns([0.5, 3], gap="small")
                with col_del:
                    if st.button("âŒ", key=f"del_{idx}", use_container_width=True,
                                 help="åˆ é™¤æ­¤è§„åˆ™"):
                        st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                        st.session_state.replace_rules.pop(idx)
                        st.session_state.replaced_files = []
                        st.rerun()
                with col_rule:
                    st.caption(f"**{old[:12]}** â†’ {col[:12]}")

        # è§„åˆ™æ“ä½œæŒ‰é’®
        col_undo, col_clear = st.columns(2, gap="small")
        with col_undo:
            if st.session_state.undo_stack:
                if st.button("â†¶ æ’¤é”€", key="undo", use_container_width=True, help="æ’¤é”€æœ€åä¸€æ¬¡æ“ä½œ"):
                    st.session_state.replace_rules = st.session_state.undo_stack.pop()
                    st.success("âœ… å·²æ’¤é”€", icon="âœ…")
                    st.rerun()
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", key="clear_rules", use_container_width=True, help="æ¸…ç©ºæ‰€æœ‰è§„åˆ™"):
                st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                st.session_state.replace_rules.clear()
                st.session_state.replaced_files = []
                st.rerun()
    else:
        st.info("ğŸ“ æš‚æ— è§„åˆ™", icon="â„¹ï¸")

    st.markdown("---")

    # æ·»åŠ è§„åˆ™ - ç´§å‡‘
    st.markdown("**æ–°å¢è§„åˆ™** â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("ä»Wordé¢„è§ˆä¸­å¤åˆ¶å…³é”®å­—ç²˜è´´åˆ°ä¸‹é¢")

    new_keyword = st.text_input(
        "å…³é”®å­—",
        placeholder="å¦‚ï¼šã€å§“åã€‘",
        key="new_keyword",
        label_visibility="collapsed",
        help="ä»Wordæ–‡æ¡£ä¸­å¤åˆ¶ï¼Œå¦‚ã€å§“åã€‘ã€ï¼ˆéƒ¨é—¨ï¼‰ç­‰"
    )

    if excel_cols:
        new_column = st.selectbox(
            "åˆ—",
            options=excel_cols,
            key="new_column",
            label_visibility="collapsed",
            help="é€‰æ‹©Excelä¸­å¯¹åº”çš„æ•°æ®åˆ—"
        )
    else:
        new_column = None

    if st.button(
            "â• æ·»åŠ è§„åˆ™",
            key="add_rule",
            type="primary",
            disabled=not (new_keyword and new_column),
            use_container_width=True,
            help="ç‚¹å‡»æ·»åŠ æ›¿æ¢è§„åˆ™"
    ):
        rule = (new_keyword.strip(), new_column)
        if rule in st.session_state.replace_rules:
            st.warning("âš ï¸ è§„åˆ™å·²å­˜åœ¨", icon="âš ï¸")
        else:
            st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
            st.session_state.replace_rules.append(rule)
            st.success("âœ… å·²æ·»åŠ ", icon="âœ…")
            st.rerun()

    st.markdown("---")

    # è§„åˆ™å¯¼å…¥å¯¼å‡º - æŠ˜å æ˜¾ç¤º
    with st.expander("ğŸ’¾ å¯¼å…¥/å¯¼å‡º/ç¼“å­˜", expanded=False):
        # å¯¼å…¥
        import_file = st.file_uploader(
            "å¯¼å…¥JSON",
            type=["json"],
            key="import_rules",
            label_visibility="collapsed",
            help="å¯¼å…¥ä¹‹å‰å¯¼å‡ºçš„è§„åˆ™æ–‡ä»¶"
        )

        if import_file:
            try:
                rules_data = json.load(import_file)
                valid_rules = []
                for rule in rules_data:
                    if isinstance(rule, dict) and "keyword" in rule and "excel_column" in rule:
                        keyword = str(rule["keyword"]).strip()
                        excel_col = str(rule["excel_column"]).strip()
                        if keyword and excel_col:
                            valid_rules.append((keyword, excel_col))

                st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                for rule in valid_rules:
                    if rule not in st.session_state.replace_rules:
                        st.session_state.replace_rules.append(rule)

                st.success(f"âœ… å¯¼å…¥{len(valid_rules)}æ¡", icon="âœ…")
                st.rerun()
            except:
                st.error("âŒ æ ¼å¼é”™è¯¯", icon="âŒ")

        # å¯¼å‡º
        if st.session_state.replace_rules:
            rules_data = [
                {"keyword": old, "excel_column": col}
                for old, col in st.session_state.replace_rules
            ]
            rules_json = json.dumps(rules_data, ensure_ascii=False, indent=2)

            col_exp1, col_exp2 = st.columns(2, gap="small")
            with col_exp1:
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºJSON",
                    data=rules_json,
                    file_name="rules.json",
                    mime="application/json",
                    key="export_rules",
                    use_container_width=True,
                    help="å¯¼å‡ºä¸ºJSONæ–‡ä»¶ï¼Œå¯ä»¥åœ¨å…¶ä»–ç”µè„‘å¯¼å…¥"
                )
            with col_exp2:
                if st.button("ğŸ’¾ ä¿å­˜ç¼“å­˜", key="save_cache", use_container_width=True,
                             help="å¿«é€Ÿä¿å­˜è§„åˆ™åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡è‡ªåŠ¨åŠ è½½"):
                    cache_name = f"rules_{datetime.now().strftime('%m%d_%H%M')}"
                    cache_manager.save_rules(st.session_state.replace_rules, cache_name)
                    st.success("âœ… å·²ä¿å­˜", icon="âœ…")

st.markdown("---")

# ==================== åº•éƒ¨ï¼šæ‰§è¡Œæ›¿æ¢å’Œå‚æ•°é…ç½® ====================
st.subheader("âš™ï¸ æ›¿æ¢å‚æ•°é…ç½®")

col_config1, col_config2, col_config3, col_config4 = st.columns(4, gap="small")

with col_config1:
    st.markdown("**æ ¸å¿ƒå­—æ®µ** â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("é€‰æ‹©Excelä¸­çš„åˆ—ç”¨äºç”Ÿæˆæ–‡ä»¶å")
    file_name_col = st.selectbox(
        "ç”¨äºæ–‡ä»¶å",
        options=excel_cols if excel_cols else ["æœªé€‰æ‹©"],
        key="file_name_col",
        disabled=not excel_cols,
        label_visibility="collapsed",
        help="é€‰æ‹©ç”¨äºæ–‡ä»¶åçš„åˆ—"
    )

with col_config2:
    st.markdown("**èµ·å§‹è¡Œ** â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("ä»ç¬¬å‡ è¡Œå¼€å§‹å¤„ç†ï¼ˆç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ï¼‰")
    start_row = st.number_input(
        "å¼€å§‹",
        min_value=1,
        max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
        value=1,
        key="start_row",
        disabled=excel_df is None or len(excel_df) == 0,
        label_visibility="collapsed",
        help="ä»ç¬¬1è¡Œå¼€å§‹ï¼ˆè·³è¿‡æ ‡é¢˜ï¼‰"
    )

with col_config3:
    st.markdown("**ç»“æŸè¡Œ** â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("å¤„ç†åˆ°ç¬¬å‡ è¡Œï¼ˆåŒ…æ‹¬è¯¥è¡Œï¼‰")
    end_row = st.number_input(
        "ç»“æŸ",
        min_value=1,
        max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
        value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
        key="end_row",
        disabled=excel_df is None or len(excel_df) == 0,
        label_visibility="collapsed",
        help="åˆ°æœ€åä¸€è¡Œ"
    )

with col_config4:
    st.markdown("**æ–‡ä»¶å‰ç¼€** â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("ç»™ç”Ÿæˆçš„æ–‡ä»¶åæ·»åŠ å‰ç¼€ï¼Œå¦‚\"2024-\"")
    file_prefix = st.text_input(
        "å‰ç¼€",
        value="",
        key="file_prefix",
        placeholder="å¯é€‰",
        max_chars=15,
        label_visibility="collapsed",
        help="æ–‡ä»¶åå‰ç¼€"
    ).strip()

if start_row > end_row:
    st.error("âŒ èµ·å§‹è¡Œä¸èƒ½å¤§äºç»“æŸè¡Œ", icon="âŒ")

st.markdown("---")

# ==================== æ‰§è¡Œæ›¿æ¢ ====================
can_replace = word_file and excel_df is not None and len(excel_df) > 0 and len(st.session_state.replace_rules) > 0

current_params = get_replace_params(
    word_file, excel_df, start_row, end_row, file_name_col, file_prefix, ""
)

need_replace = (
        len(st.session_state.replaced_files) == 0 or
        st.session_state.replace_params != current_params
)

col_exec1, col_exec2, col_exec3, col_exec4 = st.columns([2, 1.5, 1.5, 1], gap="small")

with col_exec1:
    replace_btn = st.button(
        "â–¶ï¸ å¼€å§‹æ›¿æ¢",
        key="replace",
        disabled=not can_replace or st.session_state.is_replacing or start_row > end_row,
        type="primary",
        use_container_width=True,
        help="ç‚¹å‡»å¼€å§‹æ‰¹é‡æ›¿æ¢ï¼ˆéœ€è¦æ–‡ä»¶ã€è§„åˆ™å’Œè¡Œæ•°èŒƒå›´ï¼‰"
    )

with col_exec2:
    if st.session_state.is_replacing:
        st.info("ğŸ”„ è¿›è¡Œä¸­", icon="ğŸ”„")
    elif len(st.session_state.replaced_files) > 0 and not need_replace:
        st.success(f"âœ… {len(st.session_state.replaced_files)}ä¸ª", icon="âœ…")

with col_exec3:
    pass

with col_exec4:
    pass

# æ‰§è¡Œæ›¿æ¢é€»è¾‘
if replace_btn and not st.session_state.is_replacing:
    st.session_state.is_replacing = True
    st.session_state.replaced_files = []
    st.session_state.replace_log = []

    progress_bar = st.progress(0)
    progress_text = st.empty()

    try:
        actual_end_row = min(end_row, len(excel_df))
        if start_row > actual_end_row:
            st.error("âŒ è¡Œå·è¶…å‡ºèŒƒå›´", icon="âŒ")
        else:
            total_rows = actual_end_row - start_row + 1

            # éå†Excelæ¯ä¸€è¡Œè¿›è¡Œæ›¿æ¢
            for idx, row_idx in enumerate(range(start_row - 1, actual_end_row)):
                try:
                    excel_row = excel_df.iloc[row_idx]

                    # è°ƒç”¨æ›¿æ¢å‡½æ•°
                    replaced_file, replace_log, replace_cnt = replace_word_with_format(
                        word_file, excel_row, st.session_state.replace_rules
                    )

                    # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                    filename = generate_safe_filename(
                        excel_row,
                        file_name_col if file_name_col != "æœªé€‰æ‹©" else "",
                        file_prefix,
                        "",
                        row_idx
                    )

                    # ä¿å­˜æ›¿æ¢åçš„æ–‡ä»¶
                    st.session_state.replaced_files.append(ReplacedFile(
                        filename=filename,
                        data=replaced_file,
                        row_idx=row_idx,
                        log=replace_log,
                        replace_count=replace_cnt
                    ))

                    st.session_state.replace_log.append(f"ã€{row_idx + 1}ã€‘{replace_log}")

                    # æ›´æ–°è¿›åº¦æ¡
                    progress = (idx + 1) / total_rows
                    progress_bar.progress(progress)
                    progress_text.text(f"{idx + 1}/{total_rows}")

                except Exception as e:
                    st.session_state.replace_log.append(f"ã€{row_idx + 1}ã€‘âŒ å¤±è´¥")
                    continue

            # æ›¿æ¢å®Œæˆï¼Œè®°å½•å‚æ•°å’Œå†å²
            st.session_state.replace_params = current_params
            st.success(f"ğŸ‰ å®Œæˆï¼{len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶", icon="âœ…")

            history_record = HistoryRecord(
                timestamp=datetime.now().strftime("%m-%d %H:%M"),
                word_file=word_file.name[:20],
                excel_file=excel_file.name[:20],
                rules_count=len(st.session_state.replace_rules),
                files_generated=len(st.session_state.replaced_files),
                status="success"
            )
            history_manager.add_record(history_record)

    except Exception as e:
        st.error(f"âŒ å‡ºé”™", icon="âŒ")
    finally:
        st.session_state.is_replacing = False
        progress_bar.empty()
        progress_text.empty()

st.markdown("---")

# ==================== ä¸‹è½½ç»“æœåŒº ====================
if len(st.session_state.replaced_files) > 0:
    st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("""
        **ä¸¤ç§å¯¼å‡ºæ–¹å¼ï¼š**
        1. **ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPï¼‰** - ä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°ä¸€ä¸ªZIPå‹ç¼©åŒ…
        2. **åˆå¹¶æ–‡æ¡£** - å°†æ‰€æœ‰æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªWordæ–‡æ¡£ï¼Œæ¯ä¸ªæ–‡æ¡£ä¸€é¡µ
        """)

    # é€‰é¡¹å¡ï¼šå¯¼å‡ºæ–¹å¼
    col_export_opt1, col_export_opt2, col_export_opt3 = st.columns([2, 2, 2], gap="small")

    with col_export_opt1:
        st.markdown("**å¯¼å‡ºæ–¹å¼**")

    export_mode = st.radio(
        "æ–¹å¼",
        options=["ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPï¼‰", "åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£"],
        key="export_mode_radio",
        horizontal=True,
        label_visibility="collapsed",
        help="é€‰æ‹©å¯¼å‡ºæ–¹å¼"
    )

    st.markdown("---")

    # ç»Ÿè®¡ä¿¡æ¯ - ç´§å‡‘æ˜¾ç¤º
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4, gap="small")

    with col_stat1:
        st.metric("ğŸ“„ æ€»æ•°", len(st.session_state.replaced_files))

    with col_stat2:
        success_count = len([f for f in st.session_state.replaced_files
                             if f.data and len(f.data.getvalue()) > 0])
        st.metric("âœ… æˆåŠŸ", success_count)

    with col_stat3:
        total_replace = sum(f.replace_count for f in st.session_state.replaced_files)
        st.metric("ğŸ”„ æ›¿æ¢æ¬¡", total_replace)

    with col_stat4:
        st.metric("ğŸ“‹ è§„åˆ™æ•°", len(st.session_state.replace_rules))

    st.markdown("---")

    # å¯¼å‡ºæŒ‰é’®
    col_down1, col_down2, col_down3 = st.columns(3, gap="small")

    with col_down1:
        if export_mode == "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPï¼‰":
            try:
                valid_files = [f for f in st.session_state.replaced_files
                               if f.data and len(f.data.getvalue()) > 0]

                if valid_files:
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        for file in valid_files:
                            zipf.writestr(file.filename, file.data.getvalue())

                    zip_buffer.seek(0)
                    zip_filename = f"æ‰¹é‡æ›¿æ¢_{len(valid_files)}ä¸ª.zip"

                    st.download_button(
                        label=f"ğŸ“¦ ä¸‹è½½ZIPï¼ˆ{len(valid_files)}ä¸ªï¼‰",
                        data=zip_buffer,
                        file_name=zip_filename,
                        mime="application/zip",
                        key="download_all_zip",
                        use_container_width=True,
                        type="primary"
                    )
            except:
                st.error("âŒ åˆ›å»ºZIPå¤±è´¥", icon="âŒ")
        else:
            valid_files = [f for f in st.session_state.replaced_files
                           if f.data and len(f.data.getvalue()) > 0]

            if valid_files:
                try:
                    merged_data = merge_word_documents(valid_files)

                    st.download_button(
                        label=f"ğŸ“‹ ä¸‹è½½åˆå¹¶æ–‡æ¡£ï¼ˆ{len(valid_files)}ä¸ªï¼‰",
                        data=merged_data,
                        file_name="åˆå¹¶ç»“æœ.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_merged",
                        use_container_width=True,
                        type="primary"
                    )
                except:
                    st.error("âŒ åˆå¹¶å¤±è´¥", icon="âŒ")

    with col_down2:
        # å¯¼å‡ºç»Ÿè®¡
        if st.button("ğŸ“Š å¯¼å‡ºç»Ÿè®¡", key="export_stats", use_container_width=True, help="å¯¼å‡ºæ›¿æ¢ç»Ÿè®¡æ•°æ®ä¸ºCSV"):
            csv_data = export_statistics_to_csv(st.session_state.replaced_files)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSVç»Ÿè®¡",
                data=csv_data,
                file_name="ç»Ÿè®¡.csv",
                mime="text/csv",
                key="download_stats",
                use_container_width=True
            )

    with col_down3:
        # æ—¥å¿—å¯¼å‡º
        if st.session_state.replace_log:
            log_text = "\n".join(st.session_state.replace_log)
            st.download_button(
                label="ğŸ“ å¯¼å‡ºæ—¥å¿—",
                data=log_text,
                file_name="æ›¿æ¢æ—¥å¿—.txt",
                mime="text/plain",
                key="download_log",
                use_container_width=True,
                help="å¯¼å‡ºè¯¦ç»†çš„æ›¿æ¢æ“ä½œæ—¥å¿—"
            )

    st.markdown("---")

    # æ–‡ä»¶åˆ—è¡¨ - ç´§å‡‘æ˜¾ç¤º
    st.markdown(f"**æ–‡ä»¶åˆ—è¡¨** ({len(st.session_state.replaced_files)}) â„¹ï¸")
    with st.expander("", expanded=False):
        st.markdown("ä¸‹æ–¹æ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶ï¼Œå¯ä»¥å•ä¸ªä¸‹è½½æˆ–æŸ¥çœ‹è¯¦ç»†æ—¥å¿—")

    # åˆ†é¡µ
    total_pages = (len(st.session_state.replaced_files) + PAGE_SIZE - 1) // PAGE_SIZE

    col_page1, col_page2, col_page3 = st.columns([2, 1, 2])

    with col_page2:
        current_page = st.number_input(
            "é¡µ",
            min_value=1,
            max_value=total_pages,
            value=1,
            key="current_page",
            label_visibility="collapsed",
            help=f"å…±{total_pages}é¡µ"
        )

    start_idx = (current_page - 1) * PAGE_SIZE
    end_idx = min(start_idx + PAGE_SIZE, len(st.session_state.replaced_files))
    current_files = st.session_state.replaced_files[start_idx:end_idx]

    st.caption(f"ç¬¬ {current_page}/{total_pages} é¡µ")

    # æ–‡ä»¶è¡¨æ ¼æ˜¾ç¤º
    file_data = []
    for idx, file in enumerate(current_files, start=start_idx + 1):
        is_valid = file.data and len(file.data.getvalue()) > 0
        status = "âœ…" if is_valid else "âŒ"
        file_data.append({
            "çŠ¶æ€": status,
            "åºå·": idx,
            "æ–‡ä»¶å": file.filename[:25] + "..." if len(file.filename) > 25 else file.filename,
            "è¡Œå·": file.row_idx + 1,
            "æ›¿æ¢": file.replace_count
        })

    if file_data:
        file_df = pd.DataFrame(file_data)
        st.dataframe(file_df, use_container_width=True, hide_index=True)

    # å•ä¸ªæ–‡ä»¶ä¸‹è½½ - ä¿®å¤æ–‡æœ¬æç¤º
    st.markdown("**å•ä¸ªæ–‡ä»¶ä¸‹è½½**")

    for idx, file in enumerate(current_files, start=start_idx + 1):
        is_valid = file.data and len(file.data.getvalue()) > 0

        col_name, col_log, col_download = st.columns([2, 1, 1], gap="small")

        with col_name:
            st.caption(f"#{idx} {file.filename}")

        with col_log:
            if st.button("ğŸ“‹ æ—¥å¿—", key=f"log_{idx}", use_container_width=True, help="æŸ¥çœ‹æ›¿æ¢æ—¥å¿—"):
                st.write(file.log)

        with col_download:
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½æ–‡ä»¶",
                data=file.data,
                file_name=file.filename,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                key=f"download_{idx}",
                disabled=not is_valid,
                use_container_width=True,
                help="ä¸‹è½½æ­¤æ–‡ä»¶"
            )

else:
    st.info("ğŸ’¡ ä¸Šä¼ æ–‡ä»¶ã€æ·»åŠ è§„åˆ™åç‚¹å‡»'å¼€å§‹æ›¿æ¢'", icon="â„¹ï¸")

# ==================== åº•éƒ¨å¸®åŠ© ====================
st.markdown("---")

with st.expander("â“ å¸®åŠ©æŒ‡å—", expanded=False):
    col_help1, col_help2 = st.columns(2, gap="medium")

    with col_help1:
        st.markdown("""
        **å¿«é€Ÿå¼€å§‹**
        1. ğŸ“¤ ä¸Šä¼ Wordå’ŒExcelæ–‡ä»¶
        2. ğŸ“‹ æ·»åŠ æ›¿æ¢è§„åˆ™
        3. â–¶ï¸ ç‚¹å‡»"å¼€å§‹æ›¿æ¢"
        4. ğŸ’¾ ä¸‹è½½ç»“æœ

        **æ”¯æŒæ ¼å¼**
        â€¢ Wordï¼š.docxï¼ˆä¸æ”¯æŒ.docï¼‰
        â€¢ Excelï¼š.xlsx/.xls
        â€¢ æ‹¬å·ï¼šã€ã€‘ï¼ˆï¼‰()ã€”ã€•

        **æ–‡ä»¶é™åˆ¶**
        â€¢ Wordæœ€å¤§50MB
        â€¢ Excelæœ€å¤§50MB
        â€¢ å»ºè®®è¡Œæ•°<1000
        """)

    with col_help2:
        st.markdown("""
        **å¸¸è§é—®é¢˜**

        â“ **Wordæ–‡ä»¶ä¸æ”¯æŒ.docï¼Ÿ**
        ç”¨Wordæ‰“å¼€æ–‡ä»¶ â†’ å¦å­˜ä¸º.docxæ ¼å¼

        â“ **æ€æ ·ä¿ç•™æ ¼å¼ï¼Ÿ**
        æ‰€æœ‰æ ¼å¼è‡ªåŠ¨ä¿ç•™ï¼šå­—ä½“ã€é¢œè‰²ã€è¡¨æ ¼ç­‰

        â“ **å¦‚ä½•åˆå¹¶æ–‡æ¡£ï¼Ÿ**
        é€‰æ‹©"åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£"å¯¼å‡ºæ–¹å¼

        â“ **èƒ½å¦æ’¤é”€æ“ä½œï¼Ÿ**
        ç‚¹å‡»"â†¶ æ’¤é”€"æŒ‰é’®æ’¤é”€æœ€åä¸€æ¬¡è§„åˆ™æ“ä½œ

        â“ **å¦‚ä½•åŠ å¿«é€Ÿåº¦ï¼Ÿ**
        â€¢ åˆ†æ‰¹å¤„ç†ï¼ˆæ¯æ‰¹100-200è¡Œï¼‰
        â€¢ ä½¿ç”¨SSDç¡¬ç›˜
        â€¢ å…³é—­å…¶ä»–ç¨‹åº
        """)

st.caption(f"Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…· {VERSION} Â© 2026")