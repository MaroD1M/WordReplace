# å¯¼å…¥æ ‡å‡†åº“
import os
import sys
import tempfile
from tempfile import NamedTemporaryFile
import warnings
import shutil
import json
import io
import zipfile
import re
import unicodedata
import copy
from datetime import datetime
import hashlib
import base64

# å¯¼å…¥ç¬¬ä¸‰æ–¹åº“
import streamlit as st
import pandas as pd
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple, Set
from collections import defaultdict
from decimal import Decimal, ROUND_HALF_UP

# é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯
VERSION = "v1.5.0"

# é…ç½®å¸¸é‡
PAGE_SIZE = 10
WIDGET_HEIGHT = 250
PREVIEW_ROWS = 20
MAX_FILENAME_LENGTH = 200
MAX_WORD_FILE_SIZE = 50 * 1024 * 1024
MAX_EXCEL_FILE_SIZE = 50 * 1024 * 1024
CACHE_DIR = ".replace_cache"
HISTORY_FILE = ".replace_history.json"
MAX_HISTORY_ITEMS = 30

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

# ç¯å¢ƒå˜é‡
os.environ["STREAMLIT_VERSION"] = "1.51.0"
os.environ["STREAMLIT_SERVER_HEADLESS"] = "true"
os.environ["STREAMLIT_BROWSER_GATHER_USAGE_STATS"] = "false"

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å…¨å±€æ ·å¼ä¼˜åŒ– - ç´§å‡‘å¸ƒå±€
st.markdown("""
<style>
    /* å…¨å±€é—´è·ä¼˜åŒ– */
    .main {
        padding: 0.5rem 1rem !important;
    }

    [data-testid="stMainBlockContainer"] {
        padding-top: 0.5rem !important;
        padding-bottom: 0.5rem !important;
    }

    /* å—å®¹å™¨ç´§å‡‘ */
    .stContainer {
        padding: 0.75rem !important;
        margin-bottom: 0.5rem !important;
        border-radius: 6px;
        background-color: #ffffff;
    }

    /* åˆ é™¤å…ƒç´ é—´å¤šä½™é—´è· */
    .element-container {
        margin-bottom: 0.3rem !important;
    }

    .stColumn {
        gap: 0.5rem !important;
    }

    /* æŒ‰é’®ç´§å‡‘ */
    .stButton > button {
        border-radius: 5px;
        font-weight: 500;
        padding: 0.4rem 0.8rem !important;
        font-size: 13px !important;
        margin-bottom: 0.2rem !important;
    }

    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 2px 8px rgba(0,0,0,0.12);
    }

    /* è¾“å…¥æ¡†ç´§å‡‘ */
    .stTextInput, .stTextArea, .stSelectbox, .stNumberInput {
        margin-bottom: 0.3rem !important;
    }

    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea,
    .stSelectbox > div > div > select,
    .stNumberInput > div > div > input {
        border-radius: 5px;
        border: 1px solid #e0e0e0;
        font-size: 13px;
        padding: 0.5rem !important;
    }

    /* æ ‡é¢˜ç´§å‡‘ */
    h1 {
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #1f77b4;
        margin-bottom: 0.5rem;
    }

    h2 {
        margin-top: 0.5rem;
        margin-bottom: 0.3rem;
        color: #1f77b4;
        font-size: 1.2rem;
    }

    h3 {
        margin-top: 0.3rem;
        margin-bottom: 0.2rem;
        color: #333;
        font-size: 1.05rem;
    }

    .stSubheader {
        margin-bottom: 0.5rem !important;
        padding-bottom: 0.3rem;
        border-bottom: 1.5px solid #e0e0e0;
        font-size: 1.1rem !important;
    }

    /* å±•å¼€å™¨ç´§å‡‘ */
    .streamlit-expander {
        margin-bottom: 0.3rem !important;
        border-radius: 5px;
    }

    /* æ ‡ç­¾é¡µç´§å‡‘ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 1px;
        margin-bottom: 0.5rem;
    }

    .stTabs [data-baseweb="tab"] {
        height: 40px;
        padding-top: 8px;
        border-radius: 5px 5px 0 0;
        font-size: 13px;
    }

    /* æ•°æ®æ¡†ç´§å‡‘ */
    div[data-testid="stDataFrame"] {
        border-radius: 5px;
        border: 1px solid #e0e0e0;
        font-size: 12px;
    }

    /* æŒ‡æ ‡å¡ç´§å‡‘ */
    .metric-container {
        background-color: #f8f9fa;
        padding: 0.5rem !important;
        border-radius: 5px;
        border-left: 3px solid #1f77b4;
        margin-bottom: 0.3rem;
    }

    /* ä¿¡æ¯æ¡†ç´§å‡‘ */
    .stats-box, .success-box, .warning-box, .error-box {
        padding: 0.6rem !important;
        margin: 0.3rem 0 !important;
        border-radius: 5px;
        border-left-width: 3px;
        font-size: 13px;
    }

    .stats-box {
        background-color: #f0f9ff;
        border-left-color: #0ea5e9;
    }

    .success-box {
        background-color: #f0fdf4;
        border-left-color: #22c55e;
    }

    .warning-box {
        background-color: #fffbeb;
        border-left-color: #f59e0b;
    }

    .error-box {
        background-color: #fef2f2;
        border-left-color: #ef4444;
    }

    /* åˆ†éš”çº¿ */
    hr {
        margin: 0.5rem 0 !important;
        border: none;
        border-top: 1px solid #e0e0e0;
    }

    /* æ— çº¿ç”µå’Œå¤é€‰æ¡†ç´§å‡‘ */
    .stRadio, .stCheckbox {
        margin-bottom: 0.2rem !important;
    }

    .stRadio > label, .stCheckbox > label {
        margin-bottom: 0.2rem !important;
        font-size: 13px;
    }

    /* æ–‡ä»¶ä¸Šä¼ å™¨ç´§å‡‘ */
    .stFileUploader {
        margin-bottom: 0.3rem !important;
    }

    /* è¿›åº¦æ¡ */
    .stProgress {
        margin-bottom: 0.3rem !important;
    }

    /* è¡¨æ ¼ç´§å‡‘ */
    table {
        font-size: 12px !important;
    }

    td, th {
        padding: 0.4rem !important;
    }

    /* å“åº”å¼ */
    @media (max-width: 768px) {
        .main {
            padding: 0.3rem 0.5rem;
        }
        .stContainer {
            padding: 0.5rem;
        }
    }
</style>
""", unsafe_allow_html=True)


# ---------------------- æ•°æ®ç»“æ„ä¸åˆå§‹åŒ– ----------------------

@dataclass
class ReplacedFile:
    """å­˜å‚¨æ›¿æ¢åçš„æ–‡ä»¶æ•°æ®ç»“æ„"""
    filename: str
    data: io.BytesIO
    row_idx: int
    log: str
    replace_count: int = 0


@dataclass
class HistoryRecord:
    """å†å²è®°å½•æ•°æ®ç»“æ„"""
    timestamp: str
    word_file: str
    excel_file: str
    rules_count: int
    files_generated: int
    status: str


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self):
        self.cache_dir = CACHE_DIR
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)

    def save_rules(self, rules: List[Tuple[str, str]], filename: str):
        """ä¿å­˜è§„åˆ™åˆ°ç¼“å­˜"""
        try:
            rules_data = [{"keyword": old, "excel_column": col} for old, col in rules]
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(rules_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥", icon="âš ï¸")

    def load_rules(self, filename: str) -> List[Tuple[str, str]]:
        """åŠ è½½ç¼“å­˜çš„è§„åˆ™"""
        try:
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    rules_data = json.load(f)
                    return [(r["keyword"], r["excel_column"]) for r in rules_data]
        except:
            pass
        return []

    def get_cached_rules_list(self) -> List[str]:
        """è·å–æ‰€æœ‰ç¼“å­˜çš„è§„åˆ™æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_dir):
                files = [f.replace('.json', '') for f in os.listdir(self.cache_dir) if f.endswith('.json')]
                return sorted(files, reverse=True)[:10]  # åªè¿”å›æœ€è¿‘10ä¸ª
        except:
            pass
        return []


class HistoryManager:
    """å†å²è®°å½•ç®¡ç†å™¨"""

    def __init__(self):
        self.history_file = HISTORY_FILE

    def add_record(self, record: HistoryRecord):
        """æ·»åŠ å†å²è®°å½•"""
        try:
            history = self.load_history()
            history.insert(0, {
                "timestamp": record.timestamp,
                "word_file": record.word_file,
                "excel_file": record.excel_file,
                "rules_count": record.rules_count,
                "files_generated": record.files_generated,
                "status": record.status
            })
            history = history[:MAX_HISTORY_ITEMS]
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except:
            pass

    def load_history(self) -> List[Dict]:
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return []

    def clear_history(self):
        """æ¸…é™¤å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                os.remove(self.history_file)
                st.success("âœ… å†å²å·²æ¸…é™¤", icon="âœ…")
        except:
            pass


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    required_states = {
        "replace_rules": [],
        "replaced_files": [],
        "replace_log": [],
        "is_replacing": False,
        "replace_params": {},
        "replace_scope": "æ›¿æ¢å®Œæ•´å…³é”®è¯",
        "export_mode_radio": "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰",
        "undo_stack": [],
        "rule_filter": "",
        "show_advanced": False,
    }

    for key, default in required_states.items():
        if key not in st.session_state:
            st.session_state[key] = default


init_session_state()


# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------

def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬"""
    if not isinstance(text, str):
        return ""
    text = text.strip()
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r'[\u00A0\u2002-\u200B]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text


def clean_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åéæ³•å­—ç¬¦"""
    return re.sub(r'[\\/:*?"<>|]', "_", str(filename))


def generate_safe_filename(
        excel_row: pd.Series,
        file_name_col: str,
        file_prefix: str = "",
        file_suffix: str = "",
        row_idx: int = 0,
        max_length: int = MAX_FILENAME_LENGTH
) -> str:
    """å®‰å…¨ç”Ÿæˆæ–‡ä»¶å"""
    try:
        if file_name_col and file_name_col in excel_row.index:
            base_name = clean_text(str(excel_row[file_name_col]))
        else:
            base_name = f"æ–‡ä»¶_{row_idx + 1}"

        if not base_name or base_name.isspace():
            base_name = f"æ–‡ä»¶_{row_idx + 1}"

        if file_prefix and file_suffix:
            filename = f"{file_prefix}{base_name}{file_suffix}.docx"
        elif file_prefix:
            filename = f"{file_prefix}{base_name}.docx"
        elif file_suffix:
            filename = f"{base_name}{file_suffix}.docx"
        else:
            filename = f"{base_name}.docx"

        filename = clean_filename(filename)

        filename_bytes = filename.encode('utf-8')
        if len(filename_bytes) > max_length:
            truncated_base = base_name
            while len(f"{file_prefix}{truncated_base}{file_suffix}.docx".encode('utf-8')) > max_length:
                truncated_base = truncated_base[:-1]

            if file_prefix and file_suffix:
                filename = f"{file_prefix}{truncated_base}{file_suffix}.docx"
            elif file_prefix:
                filename = f"{file_prefix}{truncated_base}.docx"
            elif file_suffix:
                filename = f"{truncated_base}{file_suffix}.docx"
            else:
                filename = f"{truncated_base}.docx"

            filename = clean_filename(filename)

        return filename

    except:
        return f"æ–‡ä»¶_{row_idx + 1}.docx"


def precompute_replace_patterns(
        replace_rules: List[Tuple[str, str]],
        excel_row: pd.Series
) -> List[Tuple[str, str, str, str]]:
    """é¢„è®¡ç®—æ›¿æ¢æ¨¡å¼"""
    replace_patterns = []

    for old_text, col_name in replace_rules:
        if col_name in excel_row.index:
            replacement = str(excel_row[col_name]).strip()
        else:
            replacement = ""

        cleaned_text = clean_text(old_text)

        if not cleaned_text:
            continue

        if st.session_state.replace_scope == "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹":
            if cleaned_text.startswith("ã€") and cleaned_text.endswith("ã€‘"):
                new_format = f"ã€{replacement}ã€‘"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ï¼ˆ") and cleaned_text.endswith("ï¼‰"):
                new_format = f"ï¼ˆ{replacement}ï¼‰"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("(") and cleaned_text.endswith(")"):
                new_format = f"({replacement})"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ã€”") and cleaned_text.endswith("ã€•"):
                new_format = f"ã€”{replacement}ã€•"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            else:
                replace_patterns.append((old_text, col_name, cleaned_text, replacement))
        else:
            replace_patterns.append((old_text, col_name, cleaned_text, replacement))

    return replace_patterns


def process_paragraph(
        paragraph,
        replace_patterns: List[Tuple[str, str, str, str]],
        cleaned_para: str = None
) -> Dict:
    """å¤„ç†æ®µè½æ›¿æ¢"""
    para_text = paragraph.text
    if cleaned_para is None:
        cleaned_para = clean_text(para_text)
    replace_count = defaultdict(int)

    if not para_text or not replace_patterns:
        return replace_count

    has_keyword = False

    for old_text, col_name, format_keyword, replacement in replace_patterns:
        if format_keyword and format_keyword in cleaned_para:
            has_keyword = True
            break

    if has_keyword:
        new_text = para_text
        for old_text, col_name, format_keyword, replacement in replace_patterns:
            if format_keyword and format_keyword in cleaned_para:
                count = new_text.count(format_keyword)
                if count > 0:
                    new_text = new_text.replace(format_keyword, replacement)
                    replace_count[(old_text, col_name)] += count

        if len(paragraph.runs) > 0:
            paragraph.runs[0].text = new_text
            for i in range(1, len(paragraph.runs)):
                paragraph.runs[i].text = ''

    return replace_count


def replace_word_with_format(
        word_file: st.runtime.uploaded_file_manager.UploadedFile,
        excel_row: pd.Series,
        replace_rules: List[Tuple[str, str]]
) -> Tuple[io.BytesIO, str, int]:
    """æ›¿æ¢Wordæ–‡ä»¶"""
    replace_count = defaultdict(int)
    total_replace = 0

    try:
        file_size = len(word_file.getvalue())
        if file_size > MAX_WORD_FILE_SIZE:
            raise ValueError(f"æ–‡ä»¶è¿‡å¤§")

        doc = Document(io.BytesIO(word_file.getvalue()))

        replace_patterns = precompute_replace_patterns(replace_rules, excel_row)

        if not replace_patterns:
            output_file = io.BytesIO()
            doc.save(output_file)
            output_file.seek(0)
            return output_file, "âš  æœªæ‰¾åˆ°åŒ¹é…è§„åˆ™", 0

        for paragraph in doc.paragraphs:
            para_count = process_paragraph(paragraph, replace_patterns)
            for key, count in para_count.items():
                replace_count[key] += count
                total_replace += count

        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        para_count = process_paragraph(paragraph, replace_patterns)
                        for key, count in para_count.items():
                            replace_count[key] += count
                            total_replace += count

        output_file = io.BytesIO()
        doc.save(output_file)
        output_file.seek(0)

        if replace_count:
            log_lines = [f"âœ“ {old}" for old, _ in replace_count.keys()]
            replace_log = ", ".join(log_lines[:3])
            if len(replace_count) > 3:
                replace_log += f" ç­‰{len(replace_count) - 3}ä¸ª"
        else:
            replace_log = "âš  æ— æ›¿æ¢"

        return output_file, replace_log, total_replace

    except Exception as e:
        return io.BytesIO(), f"âŒ å¤±è´¥", 0


def merge_word_documents(
        replaced_files: List[ReplacedFile]
) -> io.BytesIO:
    """åˆå¹¶Wordæ–‡æ¡£"""
    if not replaced_files:
        raise ValueError("æ²¡æœ‰æ–‡ä»¶")

    try:
        main_doc = Document(io.BytesIO(replaced_files[0].data.getvalue()))
        main_body = main_doc._body._element

        for idx in range(1, len(replaced_files)):
            try:
                file = replaced_files[idx]

                if not file.data or len(file.data.getvalue()) == 0:
                    continue

                sub_doc = Document(io.BytesIO(file.data.getvalue()))
                sub_body = sub_doc._body._element

                page_break_para = OxmlElement('w:p')
                page_break_pPr = OxmlElement('w:pPr')

                page_break_element = OxmlElement('w:pageBreakBefore')
                page_break_element.set(qn('w:val'), '1')

                page_break_pPr.append(page_break_element)
                page_break_para.append(page_break_pPr)
                main_body.append(page_break_para)

                for element in sub_body:
                    main_body.append(copy.deepcopy(element))

            except:
                continue

        output = io.BytesIO()
        main_doc.save(output)
        output.seek(0)
        return output

    except Exception as e:
        raise


def get_replace_params(
        word_file: Optional[st.runtime.uploaded_file_manager.UploadedFile],
        excel_df: Optional[pd.DataFrame],
        start_row: int,
        end_row: int,
        file_name_col: str,
        file_prefix: str,
        file_suffix: str
) -> Dict:
    """è·å–æ›¿æ¢å‚æ•°"""
    return {
        "word_filename": word_file.name if word_file else "",
        "excel_rows": len(excel_df) if excel_df is not None else 0,
        "start_row": start_row,
        "end_row": end_row,
        "file_name_col": file_name_col,
        "rule_count": len(st.session_state.replace_rules),
        "rule_hash": hash(tuple(st.session_state.replace_rules))
    }


def fix_float_precision(x: str, column_name: Optional[str] = None) -> str:
    """ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦"""
    if not x or not isinstance(x, str):
        return x

    x = x.strip()
    if not x:
        return ""

    try:
        if x.replace('.', '', 1).replace('-', '', 1).isdigit():
            pass
        else:
            return x
    except:
        return x

    float_pattern = r'^\s*[-+]?\d*\.?\d+\s*$'
    if not re.match(float_pattern, x):
        return x

    try:
        dec_value = Decimal(x)

        if dec_value.as_tuple().exponent >= 0:
            return str(int(dec_value))

        float_val = float(dec_value)
        float_str = str(float_val)

        if '999999' in float_str or '000000' in float_str:
            if '.' in x:
                orig_dec_part = x.split('.')[1]
                orig_dec_places = len(orig_dec_part.rstrip('0'))

                if orig_dec_places > 0:
                    try:
                        quantized = dec_value.quantize(
                            Decimal('1.' + '0' * orig_dec_places),
                            rounding=ROUND_HALF_UP
                        )
                        result = format(quantized, f'.{orig_dec_places}f')
                        return result.rstrip('0').rstrip('.')
                    except:
                        pass

        return x
    except:
        return x


def clean_excel_types(df: pd.DataFrame) -> pd.DataFrame:
    """æ¸…ç†Excelæ•°æ®ç±»å‹"""
    df_clean = df.copy()

    for col in df_clean.columns:
        try:
            col_name = str(col)
            if col_name != col:
                df_clean = df_clean.rename(columns={col: col_name})
                col = col_name

            df_clean[col] = df_clean[col].fillna("")
            df_clean[col] = df_clean[col].astype(str).str.strip()
            df_clean[col] = df_clean[col].apply(lambda x: fix_float_precision(x, col))

        except:
            try:
                df_clean[col] = df_clean[col].astype(str).str.strip()
            except:
                pass

    return df_clean


def get_file_hash(file_data: bytes) -> str:
    """è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
    return hashlib.md5(file_data).hexdigest()[:6]


def export_statistics_to_csv(replaced_files: List[ReplacedFile]) -> str:
    """å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°CSV"""
    try:
        data = []
        for idx, file in enumerate(replaced_files, 1):
            data.append({
                "åºå·": idx,
                "æ–‡ä»¶å": file.filename,
                "è¡Œå·": file.row_idx + 1,
                "æ›¿æ¢æ¬¡æ•°": file.replace_count,
                "çŠ¶æ€": "âœ…" if file.data and len(file.data.getvalue()) > 0 else "âŒ"
            })

        df = pd.DataFrame(data)
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        return csv_buffer.getvalue()
    except:
        return ""


def get_keyword_statistics(replace_rules: List[Tuple[str, str]],
                           replaced_files: List[ReplacedFile]) -> Dict:
    """è·å–å…³é”®å­—æ›¿æ¢ç»Ÿè®¡"""
    stats = {}
    for keyword, _ in replace_rules:
        stats[keyword] = 0

    for file in replaced_files:
        for keyword, _ in replace_rules:
            if f"âœ“ {keyword}" in file.log:
                pattern = f"âœ“ {re.escape(keyword)}.*?\((\d+)æ¬¡\)"
                matches = re.findall(pattern, file.log)
                if matches:
                    stats[keyword] += int(matches[0])

    return stats


# åˆ›å»ºç®¡ç†å™¨
cache_manager = CacheManager()
history_manager = HistoryManager()

# ===================== ä¾§æ  =====================
with st.sidebar:
    st.title("ğŸ“š å¿«é€Ÿå¯¼èˆª")

    # ç»Ÿè®¡ä¿¡æ¯
    if st.session_state.replaced_files:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“„ æ–‡ä»¶æ•°", len(st.session_state.replaced_files), delta=None)
        with col2:
            st.metric("ğŸ“‹ è§„åˆ™æ•°", len(st.session_state.replace_rules), delta=None)

    st.markdown("---")

    # å¿«é€ŸåŠŸèƒ½
    st.subheader("âš¡ å¿«é€ŸåŠŸèƒ½")

    cached = cache_manager.get_cached_rules_list()
    if cached:
        selected = st.selectbox("ğŸ“‚ åŠ è½½è§„åˆ™", ["é€‰æ‹©..."] + cached, key="sidebar_cache")
        if selected and selected != "é€‰æ‹©...":
            if st.button("âœ… åŠ è½½", key="sidebar_load", use_container_width=True):
                loaded = cache_manager.load_rules(selected)
                if loaded:
                    st.session_state.replace_rules = loaded
                    st.success(f"âœ… åŠ è½½{len(loaded)}æ¡", icon="âœ…")
                    st.rerun()

    # å†å²è®°å½•
    history = history_manager.load_history()
    if history:
        st.subheader("ğŸ“œ æœ€è¿‘æ“ä½œ")
        for h in history[:3]:
            status = "âœ…" if h["status"] == "success" else "âŒ"
            st.caption(f"{status} {h['timestamp']}\n{h['word_file'][:15]}...")

    st.markdown("---")

    # å·¥å…·
    st.subheader("ğŸ”§ å·¥å…·")

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰", key="sidebar_clear", use_container_width=True):
        st.session_state.replace_rules = []
        st.session_state.replaced_files = []
        st.success("âœ… å·²æ¸…ç©º", icon="âœ…")
        st.rerun()

    if history:
        if st.button("ğŸ“œ æ¸…é™¤å†å²", key="sidebar_clear_hist", use_container_width=True):
            history_manager.clear_history()
            st.rerun()

# ===================== ä¸»é¡µé¢ =====================
st.title("ğŸ“‹ Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·")

# è¿›åº¦æ˜¾ç¤ºï¼ˆå¦‚æœæœ‰æ›¿æ¢ä»»åŠ¡ï¼‰
if st.session_state.replaced_files and st.session_state.replace_params:
    progress_col, status_col = st.columns([3, 1])
    with progress_col:
        success_count = len([f for f in st.session_state.replaced_files
                             if f.data and len(f.data.getvalue()) > 0])
        total_count = len(st.session_state.replaced_files)
        st.progress(success_count / total_count if total_count > 0 else 0)
    with status_col:
        st.metric("æˆåŠŸç‡", f"{int(success_count / total_count * 100) if total_count > 0 else 0}%")

st.markdown("---")

# ==================== ä¸»å·¥ä½œåŒº ====================
col_main_left, col_main_right = st.columns([2, 1], gap="medium")

# ==================== å·¦ä¾§ï¼šæ–‡ä»¶ä¸Šä¼ å’Œé¢„è§ˆ ====================
with col_main_left:
    st.subheader("ğŸ“¤ æ–‡ä»¶ä¸Šä¼ ")

    # ä¸Šä¼ åŒºåŸŸ - ä¸¤åˆ—å¹¶æ’
    col_upload1, col_upload2 = st.columns(2, gap="small")

    with col_upload1:
        st.markdown("**Word**")
        word_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=["docx"],
            key="word",
            label_visibility="collapsed",
            help="ä»…æ”¯æŒ.docx"
        )
        if word_file:
            file_size_mb = len(word_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_WORD_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ è¿‡å¤§", icon="âŒ")
                word_file = None
            else:
                st.caption(f"âœ… {file_size_mb:.1f}MB")

    with col_upload2:
        st.markdown("**Excel**")
        excel_file = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=["xlsx", "xls"],
            key="excel",
            label_visibility="collapsed",
            help="æ”¯æŒ.xlsx/.xls"
        )
        if excel_file:
            file_size_mb = len(excel_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_EXCEL_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ è¿‡å¤§", icon="âŒ")
                excel_file = None
            else:
                st.caption(f"âœ… {file_size_mb:.1f}MB")

    st.markdown("---")

    # æ–‡ä»¶é¢„è§ˆ - å¯æŠ˜å 
    with st.expander("ğŸ‘€ æ–‡ä»¶é¢„è§ˆ", expanded=True):
        col_prev1, col_prev2 = st.columns(2, gap="small")

        excel_df = None
        excel_cols = []

        with col_prev1:
            st.markdown("**Wordå†…å®¹**")
            if word_file:
                try:
                    doc = Document(io.BytesIO(word_file.getvalue()))
                    preview_text = ""
                    para_count = 0

                    for paragraph in doc.paragraphs:
                        if para_count >= 10:
                            preview_text += "\n... (å†…å®¹å·²æˆªæ–­)"
                            break
                        if paragraph.text.strip():
                            preview_text += paragraph.text[:50] + "\n"
                            para_count += 1

                    st.text_area(
                        "é¢„è§ˆ",
                        value=preview_text[:500] if preview_text else "ç©ºæ–‡æ¡£",
                        height=120,
                        disabled=True,
                        label_visibility="collapsed"
                    )
                    st.caption(f"ğŸ“„ {len(doc.paragraphs)}æ®µè½ï¼Œ{len(doc.tables)}è¡¨æ ¼")
                except:
                    st.warning("âŒ é¢„è§ˆå¤±è´¥", icon="âš ï¸")
            else:
                st.info("è¯·ä¸Šä¼ Wordæ–‡ä»¶", icon="â„¹ï¸")

        with col_prev2:
            st.markdown("**Excelå†…å®¹**")
            if excel_file:
                try:
                    with NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_excel:
                        temp_excel.write(excel_file.getvalue())
                        excel_path = temp_excel.name

                    try:
                        with pd.ExcelFile(excel_path, engine="openpyxl") as excel_wb:
                            sheet_names = excel_wb.sheet_names
                            selected_sheet = sheet_names[0]

                            excel_df = pd.read_excel(
                                excel_wb,
                                sheet_name=selected_sheet,
                                dtype=str,
                                keep_default_na=False,
                                na_values=[]
                            )

                            if excel_df.empty:
                                st.warning("âš ï¸ è¡¨æ ¼ä¸ºç©º", icon="âš ï¸")
                            else:
                                excel_df = clean_excel_types(excel_df)
                                excel_cols = excel_df.columns.tolist()

                                # æ˜¾ç¤ºæ‘˜è¦
                                preview_df = excel_df.head(5)
                                st.dataframe(
                                    preview_df,
                                    use_container_width=True,
                                    hide_index=True,
                                    height=120
                                )

                                col_s1, col_s2 = st.columns(2)
                                with col_s1:
                                    st.metric("è¡Œæ•°", len(excel_df))
                                with col_s2:
                                    st.metric("åˆ—æ•°", len(excel_cols))

                    finally:
                        try:
                            os.unlink(excel_path)
                        except:
                            pass

                except Exception as e:
                    st.warning("âŒ è¯»å–å¤±è´¥", icon="âš ï¸")
            else:
                st.info("è¯·ä¸Šä¼ Excelæ–‡ä»¶", icon="â„¹ï¸")

# ==================== å³ä¾§ï¼šè§„åˆ™ç®¡ç† ====================
with col_main_right:
    st.subheader("ğŸ“‹ è§„åˆ™ç®¡ç†")

    # æ›¿æ¢èŒƒå›´ - ç´§å‡‘æ˜¾ç¤º
    st.markdown("**æ›¿æ¢èŒƒå›´**")
    replace_scope = st.radio(
        "æ¨¡å¼",
        options=["å®Œæ•´å…³é”®è¯", "æ‹¬å·å†…å®¹"],
        key="replace_scope_compact",
        horizontal=True,
        label_visibility="collapsed"
    )
    st.session_state.replace_scope = ["æ›¿æ¢å®Œæ•´å…³é”®è¯", "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹"][
        ["å®Œæ•´å…³é”®è¯", "æ‹¬å·å†…å®¹"].index(replace_scope)]

    st.markdown("---")

    # è§„åˆ™åˆ—è¡¨ - ç´§å‡‘æ˜¾ç¤º
    st.markdown(f"**è§„åˆ™åˆ—è¡¨** ({len(st.session_state.replace_rules)})")

    if st.session_state.replace_rules:
        # è§„åˆ™å¿«é€Ÿæ˜¾ç¤º
        with st.container(height=200, border=True):
            for idx, (old, col) in enumerate(st.session_state.replace_rules):
                col_del, col_rule = st.columns([0.5, 3], gap="small")
                with col_del:
                    if st.button("âŒ", key=f"del_{idx}", use_container_width=True,
                                 help="åˆ é™¤æ­¤è§„åˆ™"):
                        st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                        st.session_state.replace_rules.pop(idx)
                        st.session_state.replaced_files = []
                        st.rerun()
                with col_rule:
                    st.caption(f"**{old[:15]}** â†’ {col[:15]}")

        # è§„åˆ™æ“ä½œæŒ‰é’®
        col_undo, col_clear = st.columns(2, gap="small")
        with col_undo:
            if st.session_state.undo_stack:
                if st.button("â†¶ æ’¤é”€", key="undo", use_container_width=True):
                    st.session_state.replace_rules = st.session_state.undo_stack.pop()
                    st.success("âœ… å·²æ’¤é”€", icon="âœ…")
                    st.rerun()
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", key="clear_rules", use_container_width=True):
                st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                st.session_state.replace_rules.clear()
                st.session_state.replaced_files = []
                st.rerun()
    else:
        st.info("ğŸ“ æš‚æ— è§„åˆ™", icon="â„¹ï¸")

    st.markdown("---")

    # æ·»åŠ è§„åˆ™ - ç´§å‡‘
    st.markdown("**æ–°å¢è§„åˆ™**")
    new_keyword = st.text_input(
        "å…³é”®å­—",
        placeholder="å¦‚ï¼šã€å§“åã€‘",
        key="new_keyword",
        label_visibility="collapsed"
    )

    if excel_cols:
        new_column = st.selectbox(
            "åˆ—",
            options=excel_cols,
            key="new_column",
            label_visibility="collapsed"
        )
    else:
        new_column = None

    if st.button(
            "â• æ·»åŠ è§„åˆ™",
            key="add_rule",
            type="primary",
            disabled=not (new_keyword and new_column),
            use_container_width=True
    ):
        rule = (new_keyword.strip(), new_column)
        if rule in st.session_state.replace_rules:
            st.warning("âš ï¸ å·²å­˜åœ¨", icon="âš ï¸")
        else:
            st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
            st.session_state.replace_rules.append(rule)
            st.success("âœ… å·²æ·»åŠ ", icon="âœ…")
            st.rerun()

    st.markdown("---")

    # è§„åˆ™å¯¼å…¥å¯¼å‡º - æŠ˜å æ˜¾ç¤º
    with st.expander("ğŸ’¾ å¯¼å…¥/å¯¼å‡º/ç¼“å­˜", expanded=False):
        # å¯¼å…¥
        import_file = st.file_uploader(
            "å¯¼å…¥JSON",
            type=["json"],
            key="import_rules",
            label_visibility="collapsed"
        )

        if import_file:
            try:
                rules_data = json.load(import_file)
                valid_rules = []
                for rule in rules_data:
                    if isinstance(rule, dict) and "keyword" in rule and "excel_column" in rule:
                        keyword = str(rule["keyword"]).strip()
                        excel_col = str(rule["excel_column"]).strip()
                        if keyword and excel_col:
                            valid_rules.append((keyword, excel_col))

                st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                for rule in valid_rules:
                    if rule not in st.session_state.replace_rules:
                        st.session_state.replace_rules.append(rule)

                st.success(f"âœ… å¯¼å…¥{len(valid_rules)}æ¡", icon="âœ…")
                st.rerun()
            except:
                st.error("âŒ æ ¼å¼é”™è¯¯", icon="âŒ")

        # å¯¼å‡º
        if st.session_state.replace_rules:
            rules_data = [
                {"keyword": old, "excel_column": col}
                for old, col in st.session_state.replace_rules
            ]
            rules_json = json.dumps(rules_data, ensure_ascii=False, indent=2)

            col_exp1, col_exp2 = st.columns(2, gap="small")
            with col_exp1:
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºJSON",
                    data=rules_json,
                    file_name="rules.json",
                    mime="application/json",
                    key="export_rules",
                    use_container_width=True
                )
            with col_exp2:
                if st.button("ğŸ’¾ ä¿å­˜ç¼“å­˜", key="save_cache", use_container_width=True):
                    cache_name = f"rules_{datetime.now().strftime('%m%d_%H%M')}"
                    cache_manager.save_rules(st.session_state.replace_rules, cache_name)
                    st.success("âœ… å·²ä¿å­˜", icon="âœ…")

st.markdown("---")

# ==================== åº•éƒ¨ï¼šæ‰§è¡Œæ›¿æ¢å’Œå‚æ•°é…ç½® ====================
st.subheader("âš™ï¸ æ›¿æ¢å‚æ•°é…ç½®")

col_config1, col_config2, col_config3, col_config4 = st.columns(4, gap="small")

with col_config1:
    st.markdown("**æ ¸å¿ƒå­—æ®µ**")
    file_name_col = st.selectbox(
        "ç”¨äºæ–‡ä»¶å",
        options=excel_cols if excel_cols else ["æœªé€‰æ‹©"],
        key="file_name_col",
        disabled=not excel_cols,
        label_visibility="collapsed"
    )

with col_config2:
    st.markdown("**èµ·å§‹è¡Œ**")
    start_row = st.number_input(
        "å¼€å§‹",
        min_value=1,
        max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
        value=1,
        key="start_row",
        disabled=excel_df is None or len(excel_df) == 0,
        label_visibility="collapsed"
    )

with col_config3:
    st.markdown("**ç»“æŸè¡Œ**")
    end_row = st.number_input(
        "ç»“æŸ",
        min_value=1,
        max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
        value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
        key="end_row",
        disabled=excel_df is None or len(excel_df) == 0,
        label_visibility="collapsed"
    )

with col_config4:
    st.markdown("**æ–‡ä»¶å‰ç¼€**")
    file_prefix = st.text_input(
        "å‰ç¼€",
        value="",
        key="file_prefix",
        placeholder="å¯é€‰",
        max_chars=15,
        label_visibility="collapsed"
    ).strip()

if start_row > end_row:
    st.error("âŒ èµ·å§‹è¡Œä¸èƒ½å¤§äºç»“æŸè¡Œ", icon="âŒ")

st.markdown("---")

# ==================== æ‰§è¡Œæ›¿æ¢ ====================
can_replace = word_file and excel_df is not None and len(excel_df) > 0 and len(st.session_state.replace_rules) > 0

current_params = get_replace_params(
    word_file, excel_df, start_row, end_row, file_name_col, file_prefix, ""
)

need_replace = (
        len(st.session_state.replaced_files) == 0 or
        st.session_state.replace_params != current_params
)

col_exec1, col_exec2, col_exec3, col_exec4 = st.columns([2, 1.5, 1.5, 1], gap="small")

with col_exec1:
    replace_btn = st.button(
        "â–¶ï¸ å¼€å§‹æ›¿æ¢",
        key="replace",
        disabled=not can_replace or st.session_state.is_replacing or start_row > end_row,
        type="primary",
        use_container_width=True
    )

with col_exec2:
    if st.session_state.is_replacing:
        st.info("ğŸ”„ è¿›è¡Œä¸­", icon="ğŸ”„")
    elif len(st.session_state.replaced_files) > 0 and not need_replace:
        st.success(f"âœ… {len(st.session_state.replaced_files)}ä¸ª", icon="âœ…")

with col_exec3:
    pass

with col_exec4:
    pass

# æ‰§è¡Œæ›¿æ¢é€»è¾‘
if replace_btn and not st.session_state.is_replacing:
    st.session_state.is_replacing = True
    st.session_state.replaced_files = []
    st.session_state.replace_log = []

    progress_bar = st.progress(0)
    progress_text = st.empty()

    try:
        actual_end_row = min(end_row, len(excel_df))
        if start_row > actual_end_row:
            st.error("âŒ è¡Œå·è¶…å‡ºèŒƒå›´", icon="âŒ")
        else:
            total_rows = actual_end_row - start_row + 1

            for idx, row_idx in enumerate(range(start_row - 1, actual_end_row)):
                try:
                    excel_row = excel_df.iloc[row_idx]

                    replaced_file, replace_log, replace_cnt = replace_word_with_format(
                        word_file, excel_row, st.session_state.replace_rules
                    )

                    filename = generate_safe_filename(
                        excel_row,
                        file_name_col if file_name_col != "æœªé€‰æ‹©" else "",
                        file_prefix,
                        "",
                        row_idx
                    )

                    st.session_state.replaced_files.append(ReplacedFile(
                        filename=filename,
                        data=replaced_file,
                        row_idx=row_idx,
                        log=replace_log,
                        replace_count=replace_cnt
                    ))

                    st.session_state.replace_log.append(f"ã€{row_idx + 1}ã€‘{replace_log}")

                    progress = (idx + 1) / total_rows
                    progress_bar.progress(progress)
                    progress_text.text(f"{idx + 1}/{total_rows}")

                except Exception as e:
                    st.session_state.replace_log.append(f"ã€{row_idx + 1}ã€‘âŒ å¤±è´¥")
                    continue

            st.session_state.replace_params = current_params
            st.success(f"ğŸ‰ å®Œæˆï¼{len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶", icon="âœ…")

            history_record = HistoryRecord(
                timestamp=datetime.now().strftime("%m-%d %H:%M"),
                word_file=word_file.name[:20],
                excel_file=excel_file.name[:20],
                rules_count=len(st.session_state.replace_rules),
                files_generated=len(st.session_state.replaced_files),
                status="success"
            )
            history_manager.add_record(history_record)

    except Exception as e:
        st.error(f"âŒ å‡ºé”™", icon="âŒ")
    finally:
        st.session_state.is_replacing = False
        progress_bar.empty()
        progress_text.empty()

st.markdown("---")

# ==================== ä¸‹è½½ç»“æœåŒº ====================
if len(st.session_state.replaced_files) > 0:
    st.subheader("ğŸ’¾ ä¸‹è½½ç»“æœ")

    # é€‰é¡¹å¡ï¼šå¯¼å‡ºæ–¹å¼
    col_export_opt1, col_export_opt2, col_export_opt3 = st.columns([2, 2, 2], gap="small")

    with col_export_opt1:
        st.markdown("**å¯¼å‡ºæ–¹å¼**")

    export_mode = st.radio(
        "æ–¹å¼",
        options=["ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPï¼‰", "åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£"],
        key="export_mode_radio",
        horizontal=True,
        label_visibility="collapsed"
    )

    st.markdown("---")

    # ç»Ÿè®¡ä¿¡æ¯ - ç´§å‡‘æ˜¾ç¤º
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4, gap="small")

    with col_stat1:
        st.metric("ğŸ“„ æ€»æ•°", len(st.session_state.replaced_files))

    with col_stat2:
        success_count = len([f for f in st.session_state.replaced_files
                             if f.data and len(f.data.getvalue()) > 0])
        st.metric("âœ… æˆåŠŸ", success_count)

    with col_stat3:
        total_replace = sum(f.replace_count for f in st.session_state.replaced_files)
        st.metric("ğŸ”„ æ›¿æ¢æ¬¡æ•°", total_replace)

    with col_stat4:
        st.metric("ğŸ“‹ è§„åˆ™æ•°", len(st.session_state.replace_rules))

    st.markdown("---")

    # å¯¼å‡ºæŒ‰é’®
    col_down1, col_down2, col_down3 = st.columns(3, gap="small")

    with col_down1:
        if export_mode == "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPï¼‰":
            try:
                valid_files = [f for f in st.session_state.replaced_files
                               if f.data and len(f.data.getvalue()) > 0]

                if valid_files:
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        for file in valid_files:
                            zipf.writestr(file.filename, file.data.getvalue())

                    zip_buffer.seek(0)
                    zip_filename = f"æ‰¹é‡æ›¿æ¢_{len(valid_files)}ä¸ª.zip"

                    st.download_button(
                        label=f"ğŸ“¦ ä¸‹è½½ZIP",
                        data=zip_buffer,
                        file_name=zip_filename,
                        mime="application/zip",
                        key="download_all_zip",
                        use_container_width=True,
                        type="primary"
                    )
            except:
                st.error("âŒ åˆ›å»ºZIPå¤±è´¥", icon="âŒ")
        else:
            valid_files = [f for f in st.session_state.replaced_files
                           if f.data and len(f.data.getvalue()) > 0]

            if valid_files:
                try:
                    merged_data = merge_word_documents(valid_files)

                    st.download_button(
                        label=f"ğŸ“‹ ä¸‹è½½åˆå¹¶æ–‡æ¡£",
                        data=merged_data,
                        file_name="åˆå¹¶ç»“æœ.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_merged",
                        use_container_width=True,
                        type="primary"
                    )
                except:
                    st.error("âŒ åˆå¹¶å¤±è´¥", icon="âŒ")

    with col_down2:
        # å¯¼å‡ºç»Ÿè®¡
        if st.button("ğŸ“Š å¯¼å‡ºç»Ÿè®¡", key="export_stats", use_container_width=True):
            csv_data = export_statistics_to_csv(st.session_state.replaced_files)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSV",
                data=csv_data,
                file_name="ç»Ÿè®¡.csv",
                mime="text/csv",
                key="download_stats",
                use_container_width=True
            )

    with col_down3:
        # æ—¥å¿—å¯¼å‡º
        if st.session_state.replace_log:
            log_text = "\n".join(st.session_state.replace_log)
            st.download_button(
                label="ğŸ“ å¯¼å‡ºæ—¥å¿—",
                data=log_text,
                file_name="æ›¿æ¢æ—¥å¿—.txt",
                mime="text/plain",
                key="download_log",
                use_container_width=True
            )

    st.markdown("---")

    # æ–‡ä»¶åˆ—è¡¨ - ç´§å‡‘æ˜¾ç¤º
    st.markdown(f"**æ–‡ä»¶åˆ—è¡¨** ({len(st.session_state.replaced_files)})")

    # åˆ†é¡µ
    total_pages = (len(st.session_state.replaced_files) + PAGE_SIZE - 1) // PAGE_SIZE

    col_page1, col_page2, col_page3 = st.columns([2, 1, 2])

    with col_page2:
        current_page = st.number_input(
            "é¡µ",
            min_value=1,
            max_value=total_pages,
            value=1,
            key="current_page",
            label_visibility="collapsed"
        )

    start_idx = (current_page - 1) * PAGE_SIZE
    end_idx = min(start_idx + PAGE_SIZE, len(st.session_state.replaced_files))
    current_files = st.session_state.replaced_files[start_idx:end_idx]

    st.caption(f"ç¬¬ {current_page}/{total_pages} é¡µ")

    # æ–‡ä»¶è¡¨æ ¼æ˜¾ç¤º
    file_data = []
    for idx, file in enumerate(current_files, start=start_idx + 1):
        is_valid = file.data and len(file.data.getvalue()) > 0
        status = "âœ…" if is_valid else "âŒ"
        file_data.append({
            "çŠ¶æ€": status,
            "åºå·": idx,
            "æ–‡ä»¶å": file.filename[:25] + "..." if len(file.filename) > 25 else file.filename,
            "è¡Œå·": file.row_idx + 1,
            "æ›¿æ¢": file.replace_count
        })

    if file_data:
        file_df = pd.DataFrame(file_data)
        st.dataframe(file_df, use_container_width=True, hide_index=True)

    # å•ä¸ªæ–‡ä»¶ä¸‹è½½
    st.markdown("**å•ä¸ªæ–‡ä»¶ä¸‹è½½**")

    for idx, file in enumerate(current_files, start=start_idx + 1):
        is_valid = file.data and len(file.data.getvalue()) > 0

        col_name, col_log, col_btn = st.columns([2, 1, 1], gap="small")

        with col_name:
            st.caption(f"#{idx} {file.filename}")

        with col_log:
            with st.expander("ğŸ“‹", expanded=False):
                st.text(file.log)

        with col_btn:
            st.download_button(
                label="â¬‡ï¸",
                data=file.data,
                file_name=file.filename,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                key=f"download_{idx}",
                disabled=not is_valid,
                use_container_width=True
            )

else:
    st.info("ğŸ’¡ ä¸Šä¼ æ–‡ä»¶ã€æ·»åŠ è§„åˆ™åç‚¹å‡»'å¼€å§‹æ›¿æ¢'", icon="â„¹ï¸")

# ==================== åº•éƒ¨å¸®åŠ© ====================
st.markdown("---")

with st.expander("â“ å¸®åŠ©", expanded=False):
    col_help1, col_help2 = st.columns(2, gap="medium")

    with col_help1:
        st.markdown("""
        **å¿«é€Ÿå¼€å§‹**
        1. ä¸Šä¼ Wordå’ŒExcelæ–‡ä»¶
        2. æ·»åŠ æ›¿æ¢è§„åˆ™
        3. ç‚¹å‡»"å¼€å§‹æ›¿æ¢"
        4. ä¸‹è½½ç»“æœ

        **æ”¯æŒæ ¼å¼**
        â€¢ Wordï¼š.docx
        â€¢ Excelï¼š.xlsx/.xls
        â€¢ æ‹¬å·ï¼šã€ã€‘ï¼ˆï¼‰()ã€”ã€•
        """)

    with col_help2:
        st.markdown("""
        **å¸¸è§é—®é¢˜**
        â€¢ .docæ–‡ä»¶ï¼šè½¬æ¢ä¸º.docx
        â€¢ æ ¼å¼ä¸¢å¤±ï¼šå·¥å…·ä¿ç•™æ‰€æœ‰æ ¼å¼
        â€¢ å¤§æ–‡ä»¶ï¼šå»ºè®®åˆ†æ‰¹å¤„ç†
        â€¢ é”™è¯¯æ¢å¤ï¼šä½¿ç”¨"æ’¤é”€"åŠŸèƒ½
        """)

st.caption(f"v{VERSION} Â© 2024 Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·")