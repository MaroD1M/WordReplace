# å¯¼å…¥æ ‡å‡†åº“
import os
import sys
import tempfile
from tempfile import NamedTemporaryFile
import warnings
import shutil
import json
import io
import zipfile
import re
import unicodedata
import copy
from datetime import datetime
import hashlib
import base64

# å¯¼å…¥ç¬¬ä¸‰æ–¹åº“
import streamlit as st
import pandas as pd
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple, Set
from collections import defaultdict
from decimal import Decimal, ROUND_HALF_UP

# é¡¹ç›®ç‰ˆæœ¬ä¿¡æ¯
VERSION = "v1.4.0"

# é…ç½®å¸¸é‡
PAGE_SIZE = 10
WIDGET_HEIGHT = 300
PREVIEW_ROWS = 30
MAX_FILENAME_LENGTH = 200
MAX_WORD_FILE_SIZE = 50 * 1024 * 1024
MAX_EXCEL_FILE_SIZE = 50 * 1024 * 1024
CACHE_DIR = ".replace_cache"
HISTORY_FILE = ".replace_history.json"
MAX_HISTORY_ITEMS = 20

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

# ç¯å¢ƒå˜é‡
os.environ["STREAMLIT_VERSION"] = "1.51.0"
os.environ["STREAMLIT_SERVER_HEADLESS"] = "true"
os.environ["STREAMLIT_BROWSER_GATHER_USAGE_STATS"] = "false"

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"  # æ”¹ä¸ºå±•å¼€ä¾§æ 
)

# å…¨å±€æ ·å¼ä¼˜åŒ–
st.markdown("""
<style>
    .stContainer {
        margin-bottom: 20px;
    }

    .stButton > button {
        border-radius: 4px;
        font-weight: 500;
    }

    .stSubheader {
        margin-bottom: 15px;
    }

    .stTextInput > div > div > input, .stSelectbox > div > div > select {
        border-radius: 4px;
    }

    div[data-testid="stDataFrame"] {
        border-radius: 4px;
    }

    .streamlit-expander {
        margin-bottom: 15px;
    }

    .data-row-item {
        padding: 8px;
        border-radius: 4px;
        transition: background-color 0.2s;
        cursor: pointer;
        display: flex;
        align-items: center;
        height: 100%;
    }
    .data-row-item:hover {
        background-color: #f0f2f6;
    }

    .stats-box {
        background-color: #f8f9fa;
        border-left: 4px solid #1f77b4;
        padding: 12px;
        border-radius: 4px;
        margin: 8px 0;
    }

    .success-box {
        background-color: #f0fdf4;
        border-left: 4px solid #22c55e;
        padding: 12px;
        border-radius: 4px;
        margin: 8px 0;
    }

    .warning-box {
        background-color: #fffbeb;
        border-left: 4px solid #f59e0b;
        padding: 12px;
        border-radius: 4px;
        margin: 8px 0;
    }

    .info-box {
        background-color: #f0f9ff;
        border-left: 4px solid #0ea5e9;
        padding: 12px;
        border-radius: 4px;
        margin: 8px 0;
    }
</style>
""", unsafe_allow_html=True)


# ---------------------- æ•°æ®ç»“æ„ä¸åˆå§‹åŒ– ----------------------

@dataclass
class ReplacedFile:
    """å­˜å‚¨æ›¿æ¢åçš„æ–‡ä»¶æ•°æ®ç»“æ„"""
    filename: str
    data: io.BytesIO
    row_idx: int
    log: str


@dataclass
class HistoryRecord:
    """å†å²è®°å½•æ•°æ®ç»“æ„"""
    timestamp: str
    word_file: str
    excel_file: str
    rules_count: int
    files_generated: int
    status: str  # success/failed


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self):
        self.cache_dir = CACHE_DIR
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)

    def save_rules(self, rules: List[Tuple[str, str]], filename: str):
        """ä¿å­˜è§„åˆ™åˆ°ç¼“å­˜"""
        try:
            rules_data = [{"keyword": old, "excel_column": col} for old, col in rules]
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(rules_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")

    def load_rules(self, filename: str) -> List[Tuple[str, str]]:
        """åŠ è½½ç¼“å­˜çš„è§„åˆ™"""
        try:
            cache_file = os.path.join(self.cache_dir, f"{filename}.json")
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    rules_data = json.load(f)
                    return [(r["keyword"], r["excel_column"]) for r in rules_data]
        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")
        return []

    def get_cached_rules_list(self) -> List[str]:
        """è·å–æ‰€æœ‰ç¼“å­˜çš„è§„åˆ™æ–‡ä»¶"""
        try:
            if os.path.exists(self.cache_dir):
                files = [f.replace('.json', '') for f in os.listdir(self.cache_dir) if f.endswith('.json')]
                return sorted(files)
        except:
            pass
        return []


class HistoryManager:
    """å†å²è®°å½•ç®¡ç†å™¨"""

    def __init__(self):
        self.history_file = HISTORY_FILE

    def add_record(self, record: HistoryRecord):
        """æ·»åŠ å†å²è®°å½•"""
        try:
            history = self.load_history()
            history.insert(0, {
                "timestamp": record.timestamp,
                "word_file": record.word_file,
                "excel_file": record.excel_file,
                "rules_count": record.rules_count,
                "files_generated": record.files_generated,
                "status": record.status
            })
            # åªä¿ç•™æœ€è¿‘çš„è®°å½•
            history = history[:MAX_HISTORY_ITEMS]
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜å†å²è®°å½•å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")

    def load_history(self) -> List[Dict]:
        """åŠ è½½å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return []

    def clear_history(self):
        """æ¸…é™¤å†å²è®°å½•"""
        try:
            if os.path.exists(self.history_file):
                os.remove(self.history_file)
                st.success("âœ… å†å²è®°å½•å·²æ¸…é™¤", icon="âœ…")
        except Exception as e:
            st.error(f"âŒ æ¸…é™¤å†å²è®°å½•å¤±è´¥ï¼š{str(e)}", icon="âŒ")


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    required_states = {
        "replace_rules": [],
        "replaced_files": [],
        "replace_log": [],
        "is_replacing": False,
        "replace_params": {},
        "replace_scope": "æ›¿æ¢å®Œæ•´å…³é”®è¯",
        "export_mode_radio": "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰",
        "show_statistics": False,
        "undo_stack": [],
    }

    for key, default in required_states.items():
        if key not in st.session_state:
            st.session_state[key] = default


init_session_state()


# ---------------------- æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------

def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬"""
    if not isinstance(text, str):
        return ""
    text = text.strip()
    text = unicodedata.normalize("NFKC", text)
    text = re.sub(r'[\u00A0\u2002-\u200B]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text


def clean_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åéæ³•å­—ç¬¦"""
    return re.sub(r'[\\/:*?"<>|]', "_", str(filename))


def generate_safe_filename(
        excel_row: pd.Series,
        file_name_col: str,
        file_prefix: str = "",
        file_suffix: str = "",
        row_idx: int = 0,
        max_length: int = MAX_FILENAME_LENGTH
) -> str:
    """å®‰å…¨ç”Ÿæˆæ–‡ä»¶å"""
    try:
        if file_name_col and file_name_col in excel_row.index:
            base_name = clean_text(str(excel_row[file_name_col]))
        else:
            base_name = f"æ›¿æ¢ç»“æœ_{row_idx + 1}"

        if not base_name or base_name.isspace():
            base_name = f"æ›¿æ¢ç»“æœ_{row_idx + 1}"

        if file_prefix and file_suffix:
            filename = f"{file_prefix}{base_name}{file_suffix}.docx"
        elif file_prefix:
            filename = f"{file_prefix}{base_name}.docx"
        elif file_suffix:
            filename = f"{base_name}{file_suffix}.docx"
        else:
            filename = f"{base_name}.docx"

        filename = clean_filename(filename)

        filename_bytes = filename.encode('utf-8')
        if len(filename_bytes) > max_length:
            suffix_len = len(f"{file_prefix}{file_suffix}.docx".encode('utf-8'))
            max_base_bytes = max_length - suffix_len - 10

            truncated_base = base_name
            while len(f"{file_prefix}{truncated_base}{file_suffix}.docx".encode('utf-8')) > max_length:
                truncated_base = truncated_base[:-1]

            if file_prefix and file_suffix:
                filename = f"{file_prefix}{truncated_base}{file_suffix}.docx"
            elif file_prefix:
                filename = f"{file_prefix}{truncated_base}.docx"
            elif file_suffix:
                filename = f"{truncated_base}{file_suffix}.docx"
            else:
                filename = f"{truncated_base}.docx"

            filename = clean_filename(filename)

        return filename

    except Exception as e:
        return f"æ›¿æ¢ç»“æœ_{row_idx + 1}.docx"


def precompute_replace_patterns(
        replace_rules: List[Tuple[str, str]],
        excel_row: pd.Series
) -> List[Tuple[str, str, str, str]]:
    """é¢„è®¡ç®—æ›¿æ¢æ¨¡å¼"""
    replace_patterns = []

    for old_text, col_name in replace_rules:
        if col_name in excel_row.index:
            replacement = str(excel_row[col_name]).strip()
        else:
            replacement = ""

        cleaned_text = clean_text(old_text)

        if not cleaned_text:
            continue

        if st.session_state.replace_scope == "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹":
            if cleaned_text.startswith("ã€") and cleaned_text.endswith("ã€‘"):
                new_format = f"ã€{replacement}ã€‘"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ï¼ˆ") and cleaned_text.endswith("ï¼‰"):
                new_format = f"ï¼ˆ{replacement}ï¼‰"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("(") and cleaned_text.endswith(")"):
                new_format = f"({replacement})"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            elif cleaned_text.startswith("ã€”") and cleaned_text.endswith("ã€•"):
                new_format = f"ã€”{replacement}ã€•"
                replace_patterns.append((old_text, col_name, cleaned_text, new_format))
            else:
                replace_patterns.append((old_text, col_name, cleaned_text, replacement))
        else:
            replace_patterns.append((old_text, col_name, cleaned_text, replacement))

    return replace_patterns


def process_paragraph(
        paragraph,
        replace_patterns: List[Tuple[str, str, str, str]],
        cleaned_para: str = None
) -> Dict:
    """å¤„ç†æ®µè½æ›¿æ¢"""
    para_text = paragraph.text
    if cleaned_para is None:
        cleaned_para = clean_text(para_text)
    replace_count = defaultdict(int)

    if not para_text or not replace_patterns:
        return replace_count

    has_keyword = False

    for old_text, col_name, format_keyword, replacement in replace_patterns:
        if format_keyword and format_keyword in cleaned_para:
            has_keyword = True
            break

    if has_keyword:
        new_text = para_text
        for old_text, col_name, format_keyword, replacement in replace_patterns:
            if format_keyword and format_keyword in cleaned_para:
                count = new_text.count(format_keyword)
                if count > 0:
                    new_text = new_text.replace(format_keyword, replacement)
                    replace_count[(old_text, col_name)] += count

        if len(paragraph.runs) > 0:
            paragraph.runs[0].text = new_text
            for i in range(1, len(paragraph.runs)):
                paragraph.runs[i].text = ''

    return replace_count


def replace_word_with_format(
        word_file: st.runtime.uploaded_file_manager.UploadedFile,
        excel_row: pd.Series,
        replace_rules: List[Tuple[str, str]]
) -> Tuple[io.BytesIO, str]:
    """æ›¿æ¢Wordæ–‡ä»¶"""
    replace_count = defaultdict(int)

    try:
        file_size = len(word_file.getvalue())
        if file_size > MAX_WORD_FILE_SIZE:
            raise ValueError(f"Wordæ–‡ä»¶è¿‡å¤§ï¼š{file_size / 1024 / 1024:.2f}MB > {MAX_WORD_FILE_SIZE / 1024 / 1024:.2f}MB")

        doc = Document(io.BytesIO(word_file.getvalue()))

        replace_patterns = precompute_replace_patterns(replace_rules, excel_row)

        if not replace_patterns:
            output_file = io.BytesIO()
            doc.save(output_file)
            output_file.seek(0)
            return output_file, "âš  æœªè®¾ç½®æœ‰æ•ˆçš„æ›¿æ¢è§„åˆ™"

        # å¤„ç†æ®µè½
        for paragraph in doc.paragraphs:
            para_count = process_paragraph(paragraph, replace_patterns)
            for key, count in para_count.items():
                replace_count[key] += count

        # å¤„ç†è¡¨æ ¼
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        para_count = process_paragraph(paragraph, replace_patterns)
                        for key, count in para_count.items():
                            replace_count[key] += count

        output_file = io.BytesIO()
        doc.save(output_file)
        output_file.seek(0)

        if replace_count:
            log_lines = []
            for (old, col_name), count in replace_count.items():
                try:
                    replacement_value = excel_row[col_name]
                except:
                    replacement_value = "N/A"
                log_lines.append(f"âœ“ {old} â†’ {replacement_value} ({count}æ¬¡)")
            replace_log = "\n".join(log_lines)
        else:
            replace_log = "âš  æœªæ‰¾åˆ°éœ€è¦æ›¿æ¢çš„å…³é”®å­—"

        return output_file, replace_log

    except Exception as e:
        import traceback
        error_log = f"âŒ æ›¿æ¢å¤±è´¥ï¼š{str(e)}"
        return io.BytesIO(), error_log


def merge_word_documents(
        replaced_files: List[ReplacedFile]
) -> io.BytesIO:
    """åˆå¹¶Wordæ–‡æ¡£ï¼ˆä¿ç•™æ ¼å¼ï¼‰"""
    if not replaced_files:
        raise ValueError("æ²¡æœ‰è¦åˆå¹¶çš„æ–‡ä»¶")

    try:
        if len(replaced_files) == 0:
            raise ValueError("æ›¿æ¢æ–‡ä»¶åˆ—è¡¨ä¸ºç©º")

        try:
            main_doc = Document(io.BytesIO(replaced_files[0].data.getvalue()))
        except Exception as e:
            raise ValueError(f"æ— æ³•åŠ è½½ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼š{str(e)}")

        main_body = main_doc._body._element

        for idx in range(1, len(replaced_files)):
            try:
                file = replaced_files[idx]

                if not file.data or len(file.data.getvalue()) == 0:
                    st.warning(f"âš ï¸ æ–‡ä»¶ {file.filename} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡", icon="âš ï¸")
                    continue

                sub_doc = Document(io.BytesIO(file.data.getvalue()))
                sub_body = sub_doc._body._element

                # æ·»åŠ åˆ†é¡µç¬¦
                page_break_para = OxmlElement('w:p')
                page_break_pPr = OxmlElement('w:pPr')

                page_break_element = OxmlElement('w:pageBreakBefore')
                page_break_element.set(qn('w:val'), '1')

                page_break_pPr.append(page_break_element)
                page_break_para.append(page_break_pPr)
                main_body.append(page_break_para)

                # æ·±æ‹·è´æ‰€æœ‰å…ƒç´ 
                for element in sub_body:
                    main_body.append(copy.deepcopy(element))

            except Exception as e:
                st.warning(f"âš ï¸ å¤„ç†æ–‡ä»¶ {file.filename} å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")
                continue

        output = io.BytesIO()
        main_doc.save(output)
        output.seek(0)
        return output

    except Exception as e:
        st.error(f"âŒ åˆå¹¶æ–‡æ¡£å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        raise


def get_replace_params(
        word_file: Optional[st.runtime.uploaded_file_manager.UploadedFile],
        excel_df: Optional[pd.DataFrame],
        start_row: int,
        end_row: int,
        file_name_col: str,
        file_prefix: str,
        file_suffix: str
) -> Dict:
    """è·å–æ›¿æ¢å‚æ•°"""
    return {
        "word_filename": word_file.name if word_file else "",
        "word_size": len(word_file.getvalue()) if word_file else 0,
        "excel_rows": len(excel_df) if excel_df is not None else 0,
        "start_row": start_row,
        "end_row": end_row,
        "file_name_col": file_name_col,
        "file_prefix": file_prefix,
        "file_suffix": file_suffix,
        "rule_count": len(st.session_state.replace_rules),
        "rule_hash": hash(tuple(st.session_state.replace_rules))
    }


def fix_float_precision(x: str, column_name: Optional[str] = None) -> str:
    """ä¿®å¤æµ®ç‚¹æ•°ç²¾åº¦"""
    if not x or not isinstance(x, str):
        return x

    x = x.strip()

    if not x:
        return ""

    try:
        if x.replace('.', '', 1).replace('-', '', 1).isdigit():
            pass
        else:
            return x
    except:
        return x

    float_pattern = r'^\s*[-+]?\d*\.?\d+\s*$'
    if not re.match(float_pattern, x):
        return x

    try:
        dec_value = Decimal(x)

        if dec_value.as_tuple().exponent >= 0:
            return str(int(dec_value))

        float_val = float(dec_value)
        float_str = str(float_val)

        if column_name and ("åˆè®¡" in column_name or "total" in column_name.lower()):
            for dec_places in range(2, 7):
                try:
                    quantized = dec_value.quantize(
                        Decimal('1.' + '0' * dec_places),
                        rounding=ROUND_HALF_UP
                    )

                    if abs(quantized - dec_value) < 1e-9:
                        result = format(quantized, f'.{dec_places}f')
                        return result.rstrip('0').rstrip('.')
                except:
                    continue

        if '999999' in float_str or '000000' in float_str:
            if '.' in x:
                orig_dec_part = x.split('.')[1]
                orig_dec_places = len(orig_dec_part.rstrip('0'))

                if orig_dec_places > 0:
                    try:
                        quantized = dec_value.quantize(
                            Decimal('1.' + '0' * orig_dec_places),
                            rounding=ROUND_HALF_UP
                        )
                        result = format(quantized, f'.{orig_dec_places}f')
                        return result.rstrip('0').rstrip('.')
                    except:
                        pass

            for dec_places in range(1, 10):
                try:
                    formatted = format(float_val, f'.{dec_places}f')
                    if abs(float(formatted) - float_val) < 1e-9:
                        return formatted.rstrip('0').rstrip('.')
                except:
                    continue

        return x
    except:
        return x


def clean_excel_types(df: pd.DataFrame) -> pd.DataFrame:
    """æ¸…ç†Excelæ•°æ®ç±»å‹"""
    df_clean = df.copy()

    for col in df_clean.columns:
        try:
            col_name = str(col)
            if col_name != col:
                df_clean = df_clean.rename(columns={col: col_name})
                col = col_name

            df_clean[col] = df_clean[col].fillna("")
            df_clean[col] = df_clean[col].astype(str).str.strip()

            df_clean[col] = df_clean[col].apply(lambda x: fix_float_precision(x, col))

        except Exception as e:
            try:
                df_clean[col] = df_clean[col].astype(str).str.strip()
            except:
                pass

    return df_clean


def get_file_hash(file_data: bytes) -> str:
    """è·å–æ–‡ä»¶å“ˆå¸Œå€¼"""
    return hashlib.md5(file_data).hexdigest()[:8]


def export_statistics_to_csv(replaced_files: List[ReplacedFile]) -> str:
    """å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°CSV"""
    try:
        data = []
        for idx, file in enumerate(replaced_files, 1):
            data.append({
                "åºå·": idx,
                "æ–‡ä»¶å": file.filename,
                "Excelè¡Œå·": file.row_idx + 1,
                "æ›¿æ¢æ—¥å¿—": file.log.replace("\n", "; ")
            })

        df = pd.DataFrame(data)
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        return csv_buffer.getvalue()
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºç»Ÿè®¡å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        return ""


def get_keyword_statistics(replace_rules: List[Tuple[str, str]],
                           replaced_files: List[ReplacedFile]) -> Dict:
    """è·å–å…³é”®å­—æ›¿æ¢ç»Ÿè®¡"""
    stats = {}
    for keyword, _ in replace_rules:
        stats[keyword] = 0

    for file in replaced_files:
        for keyword, _ in replace_rules:
            if f"âœ“ {keyword}" in file.log:
                # æå–æ›¿æ¢æ¬¡æ•°
                pattern = f"âœ“ {re.escape(keyword)}.*?\((\d+)æ¬¡\)"
                matches = re.findall(pattern, file.log)
                if matches:
                    stats[keyword] += int(matches[0])

    return stats


# ---------------------- ä¾§æ åŠŸèƒ½ ----------------------

# åˆ›å»ºç¼“å­˜å’Œå†å²ç®¡ç†å™¨
cache_manager = CacheManager()
history_manager = HistoryManager()

with st.sidebar:
    st.title("âš™ï¸ å·¥å…·é€‰é¡¹")
    st.markdown("---")

    # åŠŸèƒ½é€‰é¡¹å¡
    sidebar_tab = st.radio(
        "é€‰æ‹©åŠŸèƒ½",
        options=["ä¸»ç¨‹åº", "å¿«é€ŸåŠ è½½", "å†å²è®°å½•", "å…³äºå·¥å…·"],
        label_visibility="collapsed"
    )

    if sidebar_tab == "å¿«é€ŸåŠ è½½":
        st.subheader("ğŸ’¾ å¿«é€ŸåŠ è½½ç¼“å­˜è§„åˆ™")
        cached_rules = cache_manager.get_cached_rules_list()

        if cached_rules:
            selected_cache = st.selectbox(
                "é€‰æ‹©å·²ä¿å­˜çš„è§„åˆ™",
                options=cached_rules,
                key="select_cache"
            )

            if st.button("ğŸ“‚ åŠ è½½è§„åˆ™", key="load_cache", use_container_width=True):
                loaded_rules = cache_manager.load_rules(selected_cache)
                if loaded_rules:
                    st.session_state.replace_rules = loaded_rules
                    st.success(f"âœ… æˆåŠŸåŠ è½½ {len(loaded_rules)} æ¡è§„åˆ™", icon="âœ…")
                    st.rerun()

            if st.button("ğŸ—‘ï¸ åˆ é™¤æ­¤è§„åˆ™", key="delete_cache", use_container_width=True):
                try:
                    cache_file = os.path.join(cache_manager.cache_dir, f"{selected_cache}.json")
                    if os.path.exists(cache_file):
                        os.remove(cache_file)
                        st.success("âœ… è§„åˆ™å·²åˆ é™¤", icon="âœ…")
                        st.rerun()
                except Exception as e:
                    st.error(f"âŒ åˆ é™¤å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        else:
            st.info("ğŸ“ æš‚æ— ç¼“å­˜è§„åˆ™", icon="â„¹ï¸")

        st.markdown("---")
        st.subheader("ğŸ’¡ è§„åˆ™æç¤º")
        st.markdown("""
        **å¦‚ä½•ä½¿ç”¨å¿«é€ŸåŠ è½½ï¼š**
        1. åœ¨ä¸»ç¨‹åºä¸­è®¾ç½®å¥½æ›¿æ¢è§„åˆ™
        2. ä½¿ç”¨"å¯¼å‡ºè§„åˆ™"åŠŸèƒ½å¯¼å‡ºJSON
        3. åœ¨æ­¤å¤„åŠ è½½å·²ä¿å­˜çš„è§„åˆ™
        4. å¿«é€Ÿå¼€å§‹æ–°çš„æ›¿æ¢ä»»åŠ¡
        """)

    elif sidebar_tab == "å†å²è®°å½•":
        st.subheader("ğŸ“œ æ“ä½œå†å²")
        history = history_manager.load_history()

        if history:
            st.markdown(f"**æœ€è¿‘ {len(history)} æ¬¡æ“ä½œï¼š**")
            for i, record in enumerate(history[:10], 1):
                status_emoji = "âœ…" if record["status"] == "success" else "âŒ"
                st.markdown(f"""
                **{i}. {status_emoji} {record['timestamp']}**
                - Word: `{record['word_file']}`
                - Excel: `{record['excel_file']}`
                - è§„åˆ™æ•°: {record['rules_count']} | ç”Ÿæˆæ–‡ä»¶: {record['files_generated']}
                """)

            if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²è®°å½•", key="clear_history", use_container_width=True):
                history_manager.clear_history()
                st.rerun()
        else:
            st.info("ğŸ“ æš‚æ— æ“ä½œå†å²", icon="â„¹ï¸")

    elif sidebar_tab == "å…³äºå·¥å…·":
        st.subheader("â„¹ï¸ å…³äºæ­¤å·¥å…·")
        st.markdown(f"""
        **ç‰ˆæœ¬ï¼š** {VERSION}

        **åŠŸèƒ½ç‰¹æ€§ï¼š**
        - âœ… Wordæ–‡æ¡£ä¸Excelæ•°æ®æ‰¹é‡æ›¿æ¢
        - âœ… ä¿ç•™æ‰€æœ‰æ–‡æ¡£æ ¼å¼å’Œç»“æ„
        - âœ… æ”¯æŒåˆå¹¶å¯¼å‡ºä¸ºå•ä¸ªæ–‡æ¡£
        - âœ… è§„åˆ™å¯¼å…¥/å¯¼å‡ºå’Œå¿«é€ŸåŠ è½½
        - âœ… æ“ä½œå†å²è®°å½•
        - âœ… æ›¿æ¢ç»Ÿè®¡åˆ†æ
        - âœ… æ”¯æŒå¤šç§æ‹¬å·æ ¼å¼

        **å¿«æ·é”®è¯´æ˜ï¼š**
        - `Ctrl+C` - å¤åˆ¶é€‰ä¸­æ–‡æœ¬
        - `Ctrl+Z` - æ’¤é”€æ“ä½œï¼ˆæ”¯æŒè§„åˆ™ï¼‰

        **æŠ€æœ¯æ ˆï¼š**
        - Streamlit - Webæ¡†æ¶
        - python-docx - Wordæ–‡æ¡£å¤„ç†
        - Pandas - Excelæ•°æ®å¤„ç†

        **ç‰ˆæƒä¿¡æ¯ï¼š**
        Â© 2024 Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·
        """)

        st.markdown("---")
        st.subheader("ğŸš€ æ›´æ–°æ—¥å¿—")
        st.markdown("""
        **v1.4.0** (æœ€æ–°)
        - æ–°å¢å¿«é€ŸåŠ è½½ç¼“å­˜è§„åˆ™
        - æ–°å¢æ“ä½œå†å²è®°å½•
        - æ–°å¢å…³é”®å­—æ›¿æ¢ç»Ÿè®¡
        - æ–°å¢å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°CSV
        - æ–°å¢è§„åˆ™æ’¤é”€åŠŸèƒ½
        - ä¼˜åŒ–ç”¨æˆ·ç•Œé¢

        **v1.3.2**
        - ä¿®å¤å¤šä¸ªbugï¼Œä¼˜åŒ–åˆå¹¶æ–‡æ¡£æ ¼å¼ä¿ç•™

        **v1.3.0**
        - æ·»åŠ åˆå¹¶æ–‡æ¡£åŠŸèƒ½
        """)

    st.markdown("---")
    st.subheader("ğŸ¯ å¿«é€Ÿç»Ÿè®¡")
    if st.session_state.replaced_files:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ç”Ÿæˆæ–‡ä»¶", len(st.session_state.replaced_files))
        with col2:
            st.metric("æ›¿æ¢è§„åˆ™", len(st.session_state.replace_rules))

# ---------------------- é¡µé¢æ ‡é¢˜ä¸ç®€ä»‹ ----------------------
st.title("ğŸ“‹ Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·")
st.markdown("""
å¿«é€Ÿå®ç°Wordæ¨¡æ¿ä¸Excelæ•°æ®çš„æ‰¹é‡æ›¿æ¢ï¼Œæ”¯æŒè¡¨æ ¼å†…æ–‡å­—æ›¿æ¢ï¼Œä¿ç•™åŸæ ¼å¼ï¼Œæ“ä½œç®€å•é«˜æ•ˆã€‚

**âœ¨ åŠŸèƒ½ç‰¹æ€§ï¼š**
- æ”¯æŒåˆå¹¶å¯¼å‡ºæ‰€æœ‰æ›¿æ¢åçš„æ–‡æ¡£ä¸ºå•ä¸ªWordæ–‡ä»¶
- ä¿ç•™æ‰€æœ‰åŸæ–‡æ¡£æ ¼å¼ï¼ˆè¡¨æ ¼ã€æ ·å¼ã€é¢œè‰²ç­‰ï¼‰
- æ”¯æŒå¯¼å…¥/å¯¼å‡ºæ›¿æ¢è§„åˆ™å’Œå¿«é€ŸåŠ è½½
- å®Œæ•´çš„æ“ä½œå†å²è®°å½•
- å…³é”®å­—æ›¿æ¢ç»Ÿè®¡åˆ†æ
- æ”¯æŒå¤§æ‰¹é‡å¤„ç†æ•°æ®

**ä½¿ç”¨æ­¥éª¤ï¼š**
1. ä¸Šä¼ Wordæ¨¡æ¿æ–‡ä»¶å’ŒExcelæ•°æ®æ–‡ä»¶
2. é¢„è§ˆæ–‡æ¡£å†…å®¹ï¼Œå¤åˆ¶éœ€è¦æ›¿æ¢çš„å…³é”®å­—
3. è®¾ç½®æ›¿æ¢è§„åˆ™å’Œæ›¿æ¢èŒƒå›´
4. æ‰§è¡Œæ›¿æ¢å¹¶é€‰æ‹©ä¸‹è½½æ–¹å¼
5. æ”¯æŒç‹¬ç«‹ä¸‹è½½æˆ–åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£å¯¼å‡º
""", unsafe_allow_html=True)
st.markdown("---")

# ---------------------- 1. æ–‡ä»¶ä¸Šä¼ åŒº ----------------------
with st.container(border=True):
    st.subheader("ğŸ” ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ–‡ä»¶")
    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        word_file = st.file_uploader(
            "Wordæ¨¡æ¿",
            type=["docx"],
            key="word",
            help="ä»…æ”¯æŒ.docxæ ¼å¼ï¼Œ.docéœ€å…ˆè½¬æ¢ä¸º.docx"
        )
        if word_file:
            file_size_mb = len(word_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_WORD_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ Wordæ–‡ä»¶è¿‡å¤§ï¼š{file_size_mb:.2f}MB > {MAX_WORD_FILE_SIZE / 1024 / 1024:.2f}MB", icon="âŒ")
                word_file = None
            else:
                file_hash = get_file_hash(word_file.getvalue())
                st.success(f"âœ… å·²ä¸Šä¼ ï¼š{word_file.name}ï¼ˆ{file_size_mb:.2f}MBï¼Œå“ˆå¸Œï¼š{file_hash}ï¼‰")

    with col2:
        excel_file = st.file_uploader(
            "Excelæ•°æ®",
            type=["xlsx", "xls"],
            key="excel",
            help="æ”¯æŒ.xlsx/.xlsæ ¼å¼ï¼Œç¡®ä¿æ•°æ®åˆ—åæ¸…æ™°"
        )
        if excel_file:
            file_size_mb = len(excel_file.getvalue()) / 1024 / 1024
            if file_size_mb > MAX_EXCEL_FILE_SIZE / 1024 / 1024:
                st.error(f"âŒ Excelæ–‡ä»¶è¿‡å¤§ï¼š{file_size_mb:.2f}MB > {MAX_EXCEL_FILE_SIZE / 1024 / 1024:.2f}MB", icon="âŒ")
                excel_file = None
            else:
                file_hash = get_file_hash(excel_file.getvalue())
                st.success(f"âœ… å·²ä¸Šä¼ ï¼š{excel_file.name}ï¼ˆ{file_size_mb:.2f}MBï¼Œå“ˆå¸Œï¼š{file_hash}ï¼‰")

st.markdown("---")

# ---------------------- 2. æ–‡æ¡£é¢„è§ˆåŒº ----------------------
excel_df = None
excel_cols = []
word_preview_loaded = False

with st.container(border=True):
    st.subheader("ğŸ“„ ç¬¬äºŒæ­¥ï¼šæ–‡æ¡£é¢„è§ˆä¸å…³é”®å­—å¤åˆ¶")
    col1, col2 = st.columns([1, 1], gap="large")

    with col1:
        st.markdown("#### Wordé¢„è§ˆï¼ˆå«è¡¨æ ¼ï¼‰")
        if word_file:
            try:
                doc = Document(io.BytesIO(word_file.getvalue()))
                word_html = "<div style='height: 280px; overflow-y: auto; padding: 8px; border: 1px solid #eee; font-size: 13px; line-height: 1.5;'>"

                para_count = 0
                max_para_preview = 100

                for paragraph in doc.paragraphs:
                    if para_count >= max_para_preview:
                        word_html += "<p style='color: #999;'><em>...ï¼ˆè¿˜æœ‰æ›´å¤šå†…å®¹ï¼Œä¸å…¨éƒ¨æ˜¾ç¤ºï¼‰</em></p>"
                        break

                    if paragraph.text.strip():
                        para_html = "<p style='margin: 3px 0;'>"
                        for run in paragraph.runs:
                            style = ""
                            if run.bold:
                                style += "font-weight: bold;"
                            if run.italic:
                                style += "font-style: italic;"
                            try:
                                if run.font.color and run.font.color.rgb:
                                    style += f"color: #{run.font.color.rgb:06X}; "
                            except:
                                pass
                            para_html += f"<span style='{style}'>{run.text}</span>" if style else run.text
                        para_html += "</p>"
                        word_html += para_html
                        para_count += 1

                table_count = 0
                max_table_preview = 5

                for table_idx, table in enumerate(doc.tables):
                    if table_count >= max_table_preview:
                        word_html += f"<p style='color: #999;'><em>...ï¼ˆè¿˜æœ‰ {len(doc.tables) - table_count} ä¸ªè¡¨æ ¼ï¼Œä¸å…¨éƒ¨æ˜¾ç¤ºï¼‰</em></p>"
                        break

                    word_html += f"<div style='margin: 8px 0; font-weight: bold;'>è¡¨æ ¼{table_idx + 1}ï¼š</div>"
                    word_html += "<table border='1' style='border-collapse: collapse; width: 100%; border: 1px solid #ccc; font-size: 12px;'>"

                    for row_idx, row in enumerate(table.rows):
                        if row_idx >= 20:
                            word_html += "<tr><td colspan='100%' style='text-align:center; color:#999;'>...ï¼ˆè¿˜æœ‰æ›´å¤šè¡Œï¼‰</td></tr>"
                            break

                        word_html += "<tr>"
                        for cell in row.cells:
                            cell_html = "<td style='padding: 6px; vertical-align: top; font-size: 11px; max-width: 100px; overflow: hidden;'>"
                            for para in cell.paragraphs:
                                for run in para.runs:
                                    style = ""
                                    if run.bold:
                                        style += "font-weight: bold;"
                                    cell_html += f"<span style='{style}'>{run.text}</span>" if style else run.text
                            cell_html += "</td>"
                            word_html += cell_html
                        word_html += "</tr>"
                    word_html += "</table>"
                    table_count += 1

                word_html += "</div>"

                st.components.v1.html(word_html, height=300)
                st.info("ğŸ’¡ é€‰ä¸­éœ€è¦æ›¿æ¢çš„å…³é”®å­—ï¼ˆæ”¯æŒè¡¨æ ¼å†…æ–‡å­—ï¼‰ï¼ŒæŒ‰Ctrl+Cå¤åˆ¶", icon="â„¹ï¸")
                word_preview_loaded = True

            except Exception as e:
                st.error(f"âŒ Wordé¢„è§ˆå¤±è´¥ï¼š{str(e)}", icon="âŒ")
        else:
            st.info("è¯·å…ˆä¸Šä¼ Wordæ¨¡æ¿æ–‡ä»¶", icon="â„¹ï¸")
            st.markdown(
                "<div style='height: 280px; border: 1px dashed #ccc; display: flex; align-items: center; justify-content: center; color: #999;'>Wordé¢„è§ˆåŒºåŸŸ</div>",
                unsafe_allow_html=True)

    with col2:
        st.markdown("#### Excelæ•°æ®é¢„è§ˆ")
        if excel_file:
            try:
                with NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_excel:
                    temp_excel.write(excel_file.getvalue())
                    excel_path = temp_excel.name

                try:
                    with pd.ExcelFile(excel_path, engine="openpyxl") as excel_wb:
                        sheet_names = excel_wb.sheet_names
                        selected_sheet = sheet_names[0]
                        st.markdown(f"âš ï¸ å½“å‰ä½¿ç”¨å·¥ä½œè¡¨ï¼š**{selected_sheet}**", unsafe_allow_html=True)

                        excel_df = pd.read_excel(
                            excel_wb,
                            sheet_name=selected_sheet,
                            dtype=str,
                            keep_default_na=False,
                            na_values=[]
                        )

                        if excel_df.empty:
                            st.warning("âš ï¸ Excelè¡¨æ ¼ä¸ºç©º", icon="âš ï¸")
                        else:
                            excel_df = clean_excel_types(excel_df)
                            excel_cols = excel_df.columns.tolist()

                            preview_df = excel_df.head(PREVIEW_ROWS)
                            st.dataframe(
                                preview_df,
                                width='stretch',
                                height=250,
                                hide_index=True
                            )

                            st.markdown(f"""
                            <div class='stats-box'>
                            ğŸ“Š <strong>æ•°æ®ç»Ÿè®¡</strong><br>
                            æ€»è¡Œæ•°ï¼š<strong>{len(excel_df)}</strong> | æ€»åˆ—æ•°ï¼š<strong>{len(excel_cols)}</strong><br>
                            åˆ—åï¼š{', '.join(excel_cols[:5])}{'...' if len(excel_cols) > 5 else ''}
                            </div>
                            """, unsafe_allow_html=True)

                finally:
                    try:
                        if 'excel_path' in locals() and os.path.exists(excel_path):
                            os.unlink(excel_path)
                    except:
                        pass

            except Exception as e:
                st.error(f"âŒ Excelè¯»å–å¤±è´¥ï¼š{str(e)}", icon="âŒ")
                excel_df = None
                excel_cols = []
        else:
            st.info("è¯·å…ˆä¸Šä¼ Excelæ•°æ®æ–‡ä»¶", icon="â„¹ï¸")
            st.markdown(
                "<div style='height: 250px; border: 1px dashed #ccc; display: flex; align-items: center; justify-content: center; color: #999;'>Excelé¢„è§ˆåŒºåŸŸ</div>",
                unsafe_allow_html=True)

st.markdown("---")

# ---------------------- 3. æ›¿æ¢è§„åˆ™è®¾ç½® ----------------------
with st.container(border=True):
    st.subheader("ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šè®¾ç½®æ›¿æ¢è§„åˆ™")

    st.markdown(
        "<div style='font-size: 15px; font-weight: bold; margin-top: 10px; margin-bottom: 8px;'>æ›¿æ¢èŒƒå›´è®¾ç½®</div>",
        unsafe_allow_html=True)
    st.radio(
        "æ›¿æ¢èŒƒå›´",
        options=["æ›¿æ¢å®Œæ•´å…³é”®è¯", "ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹"],
        key="replace_scope",
        index=0,
        horizontal=True,
        help="æ›¿æ¢å®Œæ•´å…³é”®è¯ï¼šæ›¿æ¢æ‚¨è¾“å…¥çš„ç²¾ç¡®å…³é”®è¯ï¼›ä»…æ›¿æ¢æ‹¬å·å†…å†…å®¹ï¼šä¿ç•™æ‹¬å·ç»“æ„ï¼Œåªæ›¿æ¢æ‹¬å·å†…çš„æ–‡å­—"
    )

    st.markdown(
        "<div style='font-size: 15px; font-weight: bold; margin-top: 15px; margin-bottom: 8px;'>æ›¿æ¢è§„åˆ™å¯¼å…¥/å¯¼å‡º/åŠ è½½</div>",
        unsafe_allow_html=True)
    col_import, col_export, col_load = st.columns([1, 1, 1], gap="medium")

    with col_import:
        import_rules = st.file_uploader(
            "å¯¼å…¥è§„åˆ™ï¼ˆJSONï¼‰",
            type=["json"],
            key="import_rules",
            help="ä»JSONæ–‡ä»¶å¯¼å…¥æ›¿æ¢è§„åˆ™"
        )

        if import_rules:
            try:
                rules_data = json.load(import_rules)

                if not isinstance(rules_data, list):
                    st.error("âŒ JSONæ ¼å¼é”™è¯¯ï¼šåº”ä¸ºæ•°ç»„æ ¼å¼", icon="âŒ")
                else:
                    valid_rules = []
                    for rule in rules_data:
                        if isinstance(rule, dict) and "keyword" in rule and "excel_column" in rule:
                            keyword = str(rule["keyword"]).strip()
                            excel_col = str(rule["excel_column"]).strip()
                            if keyword and excel_col:
                                valid_rules.append((keyword, excel_col))

                    # ä¿å­˜åˆ°æ’¤é”€æ ˆ
                    st.session_state.undo_stack.append(st.session_state.replace_rules.copy())

                    for rule in valid_rules:
                        if rule not in st.session_state.replace_rules:
                            st.session_state.replace_rules.append(rule)

                    st.success(f"âœ… æˆåŠŸå¯¼å…¥ {len(valid_rules)} æ¡è§„åˆ™", icon="âœ…")
                    st.rerun()
            except json.JSONDecodeError as e:
                st.error(f"âŒ JSONæ ¼å¼é”™è¯¯ï¼š{str(e)}", icon="âŒ")
            except Exception as e:
                st.error(f"âŒ å¯¼å…¥å¤±è´¥ï¼š{str(e)}", icon="âŒ")

    with col_export:
        if st.session_state.replace_rules:
            rules_data = [
                {"keyword": old, "excel_column": col}
                for old, col in st.session_state.replace_rules
            ]
            rules_json = json.dumps(rules_data, ensure_ascii=False, indent=2)

            col_exp1, col_exp2 = st.columns([1, 1], gap="small")
            with col_exp1:
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºè§„åˆ™",
                    data=rules_json,
                    file_name="replace_rules.json",
                    mime="application/json",
                    key="export_rules",
                    help="å°†å½“å‰æ›¿æ¢è§„åˆ™å¯¼å‡ºä¸ºJSONæ–‡ä»¶",
                    use_container_width=True
                )

            with col_exp2:
                # ä¿å­˜è§„åˆ™åˆ°ç¼“å­˜
                cache_name = f"rules_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                if st.button("ğŸ’¾ ä¿å­˜ä¸ºç¼“å­˜", key="save_cache", use_container_width=True,
                             help="ä¿å­˜å½“å‰è§„åˆ™ä»¥ä¾¿å¿«é€ŸåŠ è½½"):
                    cache_manager.save_rules(st.session_state.replace_rules, cache_name)
                    st.success("âœ… è§„åˆ™å·²ä¿å­˜åˆ°ç¼“å­˜", icon="âœ…")

    with col_load:
        cached = cache_manager.get_cached_rules_list()
        if cached:
            st.markdown("**å¿«é€ŸåŠ è½½ç¼“å­˜**")
            st.info(f"ğŸ“ æœ‰ {len(cached)} æ¡ç¼“å­˜è§„åˆ™å¯ç”¨", icon="â„¹ï¸")

    st.markdown(
        "<div style='font-size: 15px; font-weight: bold; margin-top: 15px; margin-bottom: 8px;'>è§„åˆ™æ·»åŠ åŒºåŸŸ</div>",
        unsafe_allow_html=True)
    col_keyword, col_column, col_add = st.columns([3, 3, 1], gap="small")

    with col_keyword:
        keyword_input = st.text_input(
            "å…³é”®å­—",
            placeholder="è¯·è¾“å…¥è¦æ›¿æ¢çš„å…³é”®å­—ï¼ˆå¦‚ï¼šã€å§“åã€‘ï¼‰",
            key="keyword_input",
            help="ä»Wordæ–‡æ¡£ä¸­å¤åˆ¶éœ€è¦æ›¿æ¢çš„å…³é”®å­—"
        )

    with col_column:
        column_select = st.selectbox(
            "Excelæ•°æ®åˆ—",
            options=excel_cols if excel_cols else ["è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶"],
            key="column_select",
            disabled=not excel_cols,
            help="é€‰æ‹©Excelä¸­å¯¹åº”çš„æ•°æ®åˆ—"
        )

    with col_add:
        add_rule_btn = st.button(
            "â• æ·»åŠ ",
            key="add_rule",
            type="primary",
            disabled=not (
                        keyword_input and keyword_input.strip() and column_select and column_select != "è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶"),
            help="ç‚¹å‡»æ·»åŠ æ›¿æ¢è§„åˆ™",
            use_container_width=True
        )

    if add_rule_btn:
        rule = (keyword_input.strip(), column_select)
        if rule in st.session_state.replace_rules:
            st.warning("âš ï¸ è¯¥è§„åˆ™å·²å­˜åœ¨", icon="âš ï¸")
        else:
            st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
            st.session_state.replace_rules.append(rule)
            st.success("âœ… è§„åˆ™æ·»åŠ æˆåŠŸ", icon="âœ…")
            st.rerun()

    # è§„åˆ™åˆ—è¡¨æ˜¾ç¤º
    if st.session_state.replace_rules:
        with st.expander("ğŸ“‹ æ›¿æ¢è§„åˆ™åˆ—è¡¨", expanded=True):
            col_actions = st.columns([1, 1, 1], gap="small")

            with col_actions[0]:
                # æ’¤é”€æŒ‰é’®
                if st.session_state.undo_stack:
                    if st.button("â†¶ æ’¤é”€", key="undo", use_container_width=True):
                        st.session_state.replace_rules = st.session_state.undo_stack.pop()
                        st.success("âœ… å·²æ’¤é”€", icon="âœ…")
                        st.rerun()

            with col_actions[1]:
                pass

            with col_actions[2]:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰", key="clear_rules", type="secondary", use_container_width=True):
                    st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                    st.session_state.replace_rules.clear()
                    st.session_state.replaced_files = []
                    st.success("âœ… æ‰€æœ‰è§„åˆ™å·²æ¸…ç©º", icon="âœ…")
                    st.rerun()

            st.markdown("<div style='font-size: 14px;'><strong>å½“å‰è§„åˆ™ï¼š</strong></div>", unsafe_allow_html=True)

            scrollable_container = st.container(height=WIDGET_HEIGHT, border=True)

            with scrollable_container:
                for idx, (old, col) in enumerate(st.session_state.replace_rules):
                    col1, col2, col3, col4, col5 = st.columns([0.5, 3, 0.5, 3, 1], gap="small")

                    with col1:
                        st.write(f"<div class='data-row-item'><strong>{idx + 1}.</strong></div>",
                                 unsafe_allow_html=True)

                    with col2:
                        st.write(f"<div class='data-row-item'><strong>{old}</strong></div>", unsafe_allow_html=True)

                    with col3:
                        st.write(f"<div class='data-row-item'>â†’</div>", unsafe_allow_html=True)

                    with col4:
                        st.write(f"<div class='data-row-item'>{col}</div>", unsafe_allow_html=True)

                    with col5:
                        if st.button("âŒ", key=f"delete_{idx}", use_container_width=True):
                            st.session_state.undo_stack.append(st.session_state.replace_rules.copy())
                            st.session_state.replace_rules.pop(idx)
                            st.session_state.replaced_files = []
                            st.success(f"âœ… å·²åˆ é™¤è§„åˆ™ {idx + 1}", icon="âœ…")
                            st.rerun()

st.markdown("---")

# ---------------------- 4. æ‰§è¡Œæ›¿æ¢ ----------------------
with st.container(border=True):
    st.subheader("ğŸš€ ç¬¬å››æ­¥ï¼šæ‰§è¡Œæ›¿æ¢")

    st.markdown("#### æ–‡ä»¶åè®¾ç½®")
    col_name1, col_name2, col_name3 = st.columns([1, 1, 1], gap="medium")

    with col_name1:
        file_name_col = st.selectbox(
            "æ ¸å¿ƒå­—æ®µï¼ˆç”¨äºæ–‡ä»¶åï¼‰",
            options=excel_cols if excel_cols else ["è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶"],
            key="file_name_col",
            disabled=not excel_cols,
            help="é€‰æ‹©ä¸€ä¸ªExcelåˆ—ä½œä¸ºç”Ÿæˆæ–‡ä»¶åçš„æ ¸å¿ƒå­—æ®µ"
        )

    with col_name2:
        file_prefix = st.text_input(
            "æ–‡ä»¶å‰ç¼€ï¼ˆå¯é€‰ï¼‰",
            value="",
            key="file_prefix",
            help="ä¸ºç”Ÿæˆçš„æ–‡ä»¶åæ·»åŠ å‰ç¼€"
        ).strip()

    with col_name3:
        file_suffix = st.text_input(
            "æ–‡ä»¶åç¼€ï¼ˆå¯é€‰ï¼‰",
            value="",
            key="file_suffix",
            help="ä¸ºç”Ÿæˆçš„æ–‡ä»¶åæ·»åŠ åç¼€"
        ).strip()

    st.markdown("#### æ›¿æ¢èŒƒå›´è®¾ç½®")
    col_range1, col_range2 = st.columns([1, 1], gap="medium")

    with col_range1:
        start_row = st.number_input(
            "èµ·å§‹è¡Œ",
            min_value=1,
            max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
            value=1,
            key="start_row",
            disabled=excel_df is None or len(excel_df) == 0,
            help="è®¾ç½®å¼€å§‹å¤„ç†çš„Excelè¡Œå·"
        )

    with col_range2:
        end_row = st.number_input(
            "ç»“æŸè¡Œ",
            min_value=1,
            max_value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
            value=len(excel_df) if excel_df is not None and len(excel_df) > 0 else 1,
            key="end_row",
            disabled=excel_df is None or len(excel_df) == 0,
            help="è®¾ç½®ç»“æŸå¤„ç†çš„Excelè¡Œå·"
        )

    if start_row > end_row:
        st.error("âŒ èµ·å§‹è¡Œä¸èƒ½å¤§äºç»“æŸè¡Œ", icon="âŒ")

    can_replace = word_file and excel_df is not None and len(excel_df) > 0 and len(st.session_state.replace_rules) > 0

    current_params = get_replace_params(
        word_file, excel_df, start_row, end_row, file_name_col, file_prefix, file_suffix
    )

    need_replace = (
            len(st.session_state.replaced_files) == 0 or
            st.session_state.replace_params != current_params
    )

    col_replace, col_preview = st.columns([1, 1], gap="medium")

    with col_replace:
        replace_btn = st.button(
            "â–¶ï¸ å¼€å§‹æ›¿æ¢",
            key="replace",
            disabled=not can_replace or st.session_state.is_replacing or start_row > end_row,
            type="primary",
            help="ç‚¹å‡»å¼€å§‹æ‰§è¡Œæ‰¹é‡æ›¿æ¢æ“ä½œ",
            use_container_width=True
        )

    with col_preview:
        if st.session_state.is_replacing:
            st.info("ğŸ”„ æ­£åœ¨æ‰§è¡Œæ›¿æ¢ï¼Œè¯·ç¨å€™...", icon="ğŸ”„")
        elif len(st.session_state.replaced_files) > 0 and not need_replace:
            st.success(f"âœ… å·²å®Œæˆæ›¿æ¢ï¼å…±ç”Ÿæˆ {len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶", icon="âœ…")

    # æ‰§è¡Œæ›¿æ¢é€»è¾‘
    if replace_btn and not st.session_state.is_replacing:
        st.session_state.is_replacing = True
        st.session_state.replaced_files = []
        st.session_state.replace_log = []

        progress_bar = st.progress(0)
        progress_text = st.empty()

        try:
            actual_end_row = min(end_row, len(excel_df))
            if start_row > actual_end_row:
                st.error("âŒ èµ·å§‹è¡Œè¶…å‡ºæ•°æ®èŒƒå›´", icon="âŒ")
            else:
                total_rows = actual_end_row - start_row + 1

                for idx, row_idx in enumerate(range(start_row - 1, actual_end_row)):
                    try:
                        excel_row = excel_df.iloc[row_idx]

                        replaced_file, replace_log = replace_word_with_format(
                            word_file, excel_row, st.session_state.replace_rules
                        )

                        filename = generate_safe_filename(
                            excel_row,
                            file_name_col if file_name_col != "è¯·å…ˆä¸Šä¼ Excelæ–‡ä»¶" else "",
                            file_prefix,
                            file_suffix,
                            row_idx
                        )

                        st.session_state.replaced_files.append(ReplacedFile(
                            filename=filename,
                            data=replaced_file,
                            row_idx=row_idx,
                            log=replace_log
                        ))

                        st.session_state.replace_log.append(f"ã€ç¬¬{row_idx + 1}è¡Œã€‘{replace_log}")

                        progress = (idx + 1) / total_rows
                        progress_bar.progress(progress)
                        progress_text.text(f"å¤„ç†è¿›åº¦ï¼š{idx + 1}/{total_rows}")

                    except Exception as e:
                        st.session_state.replace_log.append(f"ã€ç¬¬{row_idx + 1}è¡Œã€‘âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")
                        continue

                st.session_state.replace_params = current_params
                st.success(f"ğŸ‰ æ›¿æ¢å®Œæˆï¼å…±ç”Ÿæˆ {len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶", icon="âœ…")

                # è®°å½•åˆ°å†å²
                history_record = HistoryRecord(
                    timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    word_file=word_file.name,
                    excel_file=excel_file.name,
                    rules_count=len(st.session_state.replace_rules),
                    files_generated=len(st.session_state.replaced_files),
                    status="success"
                )
                history_manager.add_record(history_record)

        except Exception as e:
            st.error(f"âŒ æ›¿æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}", icon="âŒ")
            history_record = HistoryRecord(
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                word_file=word_file.name if word_file else "N/A",
                excel_file=excel_file.name if excel_file else "N/A",
                rules_count=len(st.session_state.replace_rules),
                files_generated=0,
                status="failed"
            )
            history_manager.add_record(history_record)
        finally:
            st.session_state.is_replacing = False
            progress_bar.empty()
            progress_text.empty()

# ---------------------- 5. ä¸‹è½½ç»“æœ ----------------------
if len(st.session_state.replaced_files) > 0:
    st.markdown("---")
    with st.container(border=True):
        st.subheader("ğŸ’¾ ç¬¬äº”æ­¥ï¼šä¸‹è½½ç»“æœ")

        st.markdown("#### ğŸ“¥ å¯¼å‡ºé€‰é¡¹")
        export_mode = st.radio(
            "é€‰æ‹©å¯¼å‡ºæ–¹å¼",
            options=["ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰", "åˆå¹¶ä¸ºå•ä¸ªæ–‡æ¡£"],
            key="export_mode_radio",
            horizontal=True,
            help="ç‹¬ç«‹ï¼šä¸‹è½½æ‰€æœ‰æ–‡ä»¶ä¸ºZIPï¼›åˆå¹¶ï¼šå°†æ‰€æœ‰æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªWordæ–‡æ¡£"
        )

        st.markdown("---")

        st.markdown("#### ğŸ“Š æ›¿æ¢ç»Ÿè®¡")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        col_stat1, col_stat2, col_stat3 = st.columns(3)

        with col_stat1:
            st.metric("ç”Ÿæˆæ–‡ä»¶æ•°", len(st.session_state.replaced_files))

        with col_stat2:
            st.metric("æ›¿æ¢è§„åˆ™æ•°", len(st.session_state.replace_rules))

        with col_stat3:
            success_count = len([f for f in st.session_state.replaced_files
                                 if f.data and len(f.data.getvalue()) > 0])
            st.metric("æˆåŠŸæ–‡ä»¶æ•°", success_count)

        # å…³é”®å­—æ›¿æ¢ç»Ÿè®¡
        keyword_stats = get_keyword_statistics(st.session_state.replace_rules,
                                               st.session_state.replaced_files)
        if keyword_stats:
            st.markdown("**å…³é”®å­—æ›¿æ¢ç»Ÿè®¡ï¼š**")
            stat_df = pd.DataFrame([
                {"å…³é”®å­—": k, "æ€»æ›¿æ¢æ¬¡æ•°": v}
                for k, v in keyword_stats.items() if v > 0
            ])
            if not stat_df.empty:
                st.dataframe(stat_df, use_container_width=True, hide_index=True)

            # å¯¼å‡ºç»Ÿè®¡æ•°æ®
            if st.button("ğŸ“Š å¯¼å‡ºç»Ÿè®¡æ•°æ®", key="export_stats", use_container_width=True):
                csv_data = export_statistics_to_csv(st.session_state.replaced_files)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»Ÿè®¡CSV",
                    data=csv_data,
                    file_name="æ›¿æ¢ç»Ÿè®¡.csv",
                    mime="text/csv",
                    key="download_stats"
                )

        st.markdown("---")
        st.markdown("#### ğŸ“¦ æ‰¹é‡å¯¼å‡º")

        if export_mode == "ç‹¬ç«‹æ–‡ä»¶ï¼ˆZIPå‹ç¼©ï¼‰":
            try:
                valid_files = [f for f in st.session_state.replaced_files
                               if f.data and len(f.data.getvalue()) > 0]

                if not valid_files:
                    st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯ä»¥ä¸‹è½½", icon="âŒ")
                else:
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        for file in valid_files:
                            zipf.writestr(file.filename, file.data.getvalue())

                    zip_buffer.seek(0)
                    zip_filename = f"{file_prefix}æ‰¹é‡æ›¿æ¢_{len(valid_files)}ä¸ªæ–‡ä»¶.zip" if file_prefix else f"æ‰¹é‡æ›¿æ¢_{len(valid_files)}ä¸ªæ–‡ä»¶.zip"
                    zip_filename = clean_filename(zip_filename)

                    st.download_button(
                        label=f"ğŸ“¦ ä¸‹è½½å…¨éƒ¨æ–‡ä»¶ï¼ˆZIPï¼‰- {len(valid_files)} ä¸ªæ–‡ä»¶",
                        data=zip_buffer,
                        file_name=zip_filename,
                        mime="application/zip",
                        key="download_all_zip",
                        use_container_width=True
                    )
            except Exception as e:
                st.error(f"âŒ åˆ›å»ºZIPæ–‡ä»¶å¤±è´¥ï¼š{str(e)}", icon="âŒ")
        else:
            valid_files = [f for f in st.session_state.replaced_files
                           if f.data and len(f.data.getvalue()) > 0]

            if not valid_files:
                st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶å¯ä»¥åˆå¹¶", icon="âŒ")
            else:
                try:
                    merged_data = merge_word_documents(valid_files)
                    merged_filename = f"{file_prefix}åˆå¹¶ç»“æœ.docx" if file_prefix else "åˆå¹¶ç»“æœ.docx"
                    merged_filename = clean_filename(merged_filename)

                    st.download_button(
                        label=f"ğŸ“‹ ä¸‹è½½åˆå¹¶æ–‡æ¡£ - 1 ä¸ªæ–‡ä»¶ï¼ˆåŒ…å« {len(valid_files)} ä¸ªæ–‡æ¡£ï¼‰",
                        data=merged_data,
                        file_name=merged_filename,
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        key="download_merged",
                        use_container_width=True
                    )
                except Exception as e:
                    st.error(f"âŒ åˆå¹¶å¤±è´¥ï¼š{str(e)}", icon="âŒ")

        st.markdown("---")

        st.markdown("#### ğŸ“‹ æ–‡ä»¶åˆ—è¡¨è¯¦æƒ…")

        total_pages = (len(st.session_state.replaced_files) + PAGE_SIZE - 1) // PAGE_SIZE

        col_page = st.columns([1])[0]
        with col_page:
            current_page = st.number_input(
                "é¡µç ",
                min_value=1,
                max_value=total_pages,
                value=1,
                key="current_page"
            )

        start_idx = (current_page - 1) * PAGE_SIZE
        end_idx = min(start_idx + PAGE_SIZE, len(st.session_state.replaced_files))
        current_files = st.session_state.replaced_files[start_idx:end_idx]

        st.markdown(f"**å½“å‰é¡µï¼š{current_page}/{total_pages}ï¼ˆå…± {len(st.session_state.replaced_files)} ä¸ªæ–‡ä»¶ï¼‰**")

        for idx, file in enumerate(current_files, start=start_idx + 1):
            is_valid = file.data and len(file.data.getvalue()) > 0
            status_icon = "âœ…" if is_valid else "âŒ"

            col_file, col_log, col_download = st.columns([2, 1.5, 1], gap="small")

            with col_file:
                st.write(f"<div class='data-row-item'><strong>{status_icon} #{idx}. {file.filename}</strong></div>",
                         unsafe_allow_html=True)

            with col_log:
                with st.expander("ğŸ“‹ æŸ¥çœ‹æ—¥å¿—", expanded=False):
                    st.code(file.log, language="text")

            with col_download:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½",
                    data=file.data,
                    file_name=file.filename,
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    key=f"download_{idx}",
                    disabled=not is_valid,
                    use_container_width=True
                )

# ---------------------- æ›¿æ¢æ—¥å¿— ----------------------
if st.session_state.replace_log:
    st.markdown("---")
    with st.container(border=True):
        st.subheader("ğŸ“Š æ›¿æ¢æ—¥å¿—è¯¦æƒ…")

        log_content = "\n".join(st.session_state.replace_log)

        with st.expander("ğŸ“ å®Œæ•´æ—¥å¿—", expanded=True):
            st.text_area(
                "æ›¿æ¢è¯¦ç»†æ—¥å¿—",
                value=log_content,
                height=250,
                key="log_area",
                disabled=True
            )

# ---------------------- æœªæ»¡è¶³æ‰§è¡Œæ¡ä»¶çš„æç¤º ----------------------
if not can_replace:
    st.markdown("---")
    with st.container(border=True):
        st.info("ğŸ’¡ è¯·å®Œæˆä»¥ä¸‹æ“ä½œï¼š", icon="â„¹ï¸")
        if not word_file:
            st.markdown("â€¢ ä¸Šä¼ Wordæ¨¡æ¿æ–‡ä»¶")
        if excel_df is None or excel_df.empty:
            st.markdown("â€¢ ä¸Šä¼ Excelæ•°æ®æ–‡ä»¶")
        if len(st.session_state.replace_rules) == 0:
            st.markdown("â€¢ è®¾ç½®æ›¿æ¢è§„åˆ™")

# ---------------------- åº•éƒ¨è¯´æ˜ ----------------------
st.markdown("---")
st.markdown(f"""
### ğŸ“ æ³¨æ„äº‹é¡¹
- ä»…æ”¯æŒ.docxæ ¼å¼çš„Wordæ–‡ä»¶ï¼ˆ.docéœ€è½¬æ¢ä¸º.docxï¼‰
- æ”¯æŒè¡¨æ ¼å†…æ–‡å­—æ›¿æ¢ï¼Œè¡¨æ ¼æ ¼å¼å®Œå…¨ä¿ç•™
- æ›¿æ¢æ—¶ä¼šä¿ç•™åŸæ–‡æ¡£çš„æ‰€æœ‰æ ¼å¼ï¼ˆæ ·å¼ã€é¢œè‰²ã€å­—ä½“ç­‰ï¼‰
- æ”¯æŒåˆå¹¶å¤šä¸ªæ›¿æ¢åçš„æ–‡æ¡£ä¸ºä¸€ä¸ªWordæ–‡ä»¶ï¼Œä¿ç•™æ‰€æœ‰æ ¼å¼
- å»ºè®®Wordæ–‡æ¡£ä¸è¶…è¿‡50MBï¼ŒExcelæ•°æ®ä¸è¶…è¿‡50MB
- å¯¹äºå¤§é‡æ•°æ®ï¼ˆ>1000è¡Œï¼‰ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†

### ğŸ¯ æ”¯æŒçš„æ›¿æ¢æ ¼å¼
- æ™®é€šæ–‡å­—ï¼šå¦‚ `å¼ ä¸‰`
- æ–¹æ‹¬å·ï¼šå¦‚ `ã€å¼ ä¸‰ã€‘`
- ä¸­æ–‡åœ†æ‹¬å·ï¼šå¦‚ `ï¼ˆå¼ ä¸‰ï¼‰`
- è‹±æ–‡åœ†æ‹¬å·ï¼šå¦‚ `(å¼ ä¸‰)`
- å…­è§’æ‹¬å·ï¼šå¦‚ `ã€”å¼ ä¸‰ã€•`

### âœ¨ æ–°å¢åŠŸèƒ½ï¼ˆv1.4.0ï¼‰
1. **å¿«é€ŸåŠ è½½ç¼“å­˜è§„åˆ™** - å¿«é€Ÿå¤ç”¨ä¹‹å‰ä¿å­˜çš„æ›¿æ¢è§„åˆ™
2. **æ“ä½œå†å²è®°å½•** - è®°å½•æ‰€æœ‰æ›¿æ¢æ“ä½œï¼Œä¾¿äºè¿½è¸ª
3. **å…³é”®å­—æ›¿æ¢ç»Ÿè®¡** - ç»Ÿè®¡æ¯ä¸ªå…³é”®å­—çš„æ›¿æ¢æ¬¡æ•°
4. **å¯¼å‡ºç»Ÿè®¡æ•°æ®** - å°†ç»Ÿè®¡ç»“æœå¯¼å‡ºä¸ºCSV
5. **è§„åˆ™æ’¤é”€åŠŸèƒ½** - æ”¯æŒæ’¤é”€è§„åˆ™ä¿®æ”¹
6. **ä¾§æ åŠŸèƒ½é¢æ¿** - æ›´å¥½çš„åŠŸèƒ½ç»„ç»‡å’Œä½“éªŒ

**ç‰ˆæœ¬å·ï¼š** {VERSION}

**ç‰ˆæƒæ‰€æœ‰ Â© 2024 Word+Excelæ‰¹é‡æ›¿æ¢å·¥å…·**
""", unsafe_allow_html=True)